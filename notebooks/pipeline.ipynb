{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from helpers import *\n",
    "from implementations import (\n",
    "    mean_squared_error_gd,\n",
    "    mean_squared_error_sgd,\n",
    "    cross_validation,\n",
    "    logistic_regression,\n",
    "    ridge_regression,\n",
    "    least_squares,\n",
    "    reg_logistic_regression,\n",
    ")\n",
    "from feature_processing import (\n",
    "    build_k_indices,\n",
    "    mean_imputation,\n",
    "    standardize,\n",
    "    drop_columns,\n",
    "    build_poly\n",
    ")\n",
    "\n",
    "from implementations_utils import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict with models\n",
    "models = {\n",
    "    \"least_squares\": least_squares,\n",
    "    \"ridge_regression\": ridge_regression,\n",
    "    \"logistic_regression\": logistic_regression,\n",
    "    \"reg_logistic_regression\": reg_logistic_regression,\n",
    "    \"linear_regression_gradient_descent\": mean_squared_error_gd,\n",
    "    \"linear_regression_stochastic_gradient_descent\": mean_squared_error_sgd,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data('../../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[np.where(y_train == -1)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = drop_columns(x_train, 0.8)\n",
    "x_test = drop_columns(x_test, 0.8)  # if column has 80% missing and above, we drop it\n",
    "# TODO: maybe thiss drops different columns in x_train and x_test. Check it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (328135, 205)\n",
      "x_test shape:  (109379, 205)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mean_imputation(x_train)  # median_imputation(x_train)\n",
    "x_test = mean_imputation(x_test)  # median_imputation(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = standardize(x_train)\n",
    "x_test = standardize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = build_poly(x_train, 2)\n",
    "# x_test = build_poly(x_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation: 1/5\n",
      "Training loss: 0.08609884828981772\n",
      "Testing loss: 0.08630576980178555\n",
      "Training f1 score: 0.2994228148655494\n",
      "Testing f1 score: 0.2951280360164024\n",
      "\n",
      "Cross validation: 2/5\n",
      "Training loss: 0.08612242491566459\n",
      "Testing loss: 0.08622474741297086\n",
      "Training f1 score: 0.29933676809655296\n",
      "Testing f1 score: 0.2944873303297271\n",
      "\n",
      "Cross validation: 3/5\n",
      "Training loss: 0.08638833309210706\n",
      "Testing loss: 0.08611272219594807\n",
      "Training f1 score: 0.29800074364328005\n",
      "Testing f1 score: 0.29968257567169254\n",
      "\n",
      "Cross validation: 4/5\n",
      "Training loss: 0.08519104285162\n",
      "Testing loss: 0.085077084658862\n",
      "Training f1 score: 0.29810908935283925\n",
      "Testing f1 score: 0.3006891030223315\n",
      "\n",
      "Cross validation: 5/5\n",
      "Training loss: 0.08655264442691356\n",
      "Testing loss: 0.08708844563292753\n",
      "Training f1 score: 0.29781692509140867\n",
      "Testing f1 score: 0.3017148678476428\n",
      "\n",
      "________________________________________________________\n",
      "Overall train accuracy:  0.6256350282658053\n",
      "Overall test accuracy:  0.6251268532768525\n",
      "Overall train f1:  0.2985372682099261\n",
      "Overall test f1:  0.2983403825775593\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "mod='reg_logistic'\n",
    "max_iters=50\n",
    "gamma=0.1\n",
    "lambda_=0.01\n",
    "\n",
    "k_indices = build_k_indices(y_train, num_folds, 42)\n",
    "train_loss, test_loss, train_accuracy, test_accuracy, train_f1, test_f1, weights = cross_validation(\n",
    "    y_train, x_train, k_indices, num_folds, lambda_=lambda_, max_iters=max_iters, gamma=gamma, mod=mod)\n",
    "\n",
    "print(\"________________________________________________________\")\n",
    "print(\"Overall train accuracy: \", np.mean(train_accuracy))\n",
    "print(\"Overall test accuracy: \", np.mean(test_accuracy))\n",
    "print(\"Overall train f1: \", np.mean(train_f1))\n",
    "print(\"Overall test f1: \", np.mean(test_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  1]), array([60806, 48573]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make predictions\n",
    "y_pred = np.dot(x_test, weights)\n",
    "if mod=='reg_logistic' or mod=='logistic':\n",
    "    y_pred=sigmoid(y_pred)\n",
    "\n",
    "y_pred=np.where(y_pred>0.5, 1, 0)\n",
    "y_pred[np.where(y_pred == 0)] = -1\n",
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids, y_pred, \"reg_logistic_1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
