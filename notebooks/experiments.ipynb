{
   "cells": [
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Experiment pipeline"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "%load_ext autoreload\n",
            "%autoreload 2\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "import sys\n",
            "\n",
            "sys.path.append(\"../\")\n",
            "# add ../ to path"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "import numpy as np\n",
            "from helpers import load_csv_data\n",
            "from feature_processing import (\n",
            "    drop_columns,\n",
            "    drop_correlated_columns,\n",
            "    drop_single_value_columns,\n",
            "    median_imputation,\n",
            "    mean_imputation,\n",
            "    standardize,\n",
            "    build_poly,\n",
            "    build_k_indices,\n",
            "    build_log,\n",
            "    build_ratios,\n",
            ")\n",
            "from cross_validation import (\n",
            "    predict_mse,\n",
            "    predict_logistic,\n",
            "    accuracy,\n",
            "    f1_score,\n",
            "    print_results,\n",
            "    cross_validation,\n",
            ")\n",
            "from implementations import (\n",
            "    mean_squared_error_gd,\n",
            "    mean_squared_error_sgd,\n",
            "    least_squares,\n",
            "    ridge_regression,\n",
            "    logistic_regression,\n",
            "    reg_logistic_regression,\n",
            ")\n",
            "from implementations_utils import compute_loss_mse, compute_loss_logistic\n",
            "import csv\n",
            "from pipeline import execute_pipeline\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Loading data...\n",
                  "Data loaded...\n"
               ]
            }
         ],
         "source": [
            "print(\"Loading data...\")\n",
            "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"../../data/\")\n",
            "print(\"Data loaded...\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "x_train.shape = (328135, 321)\n",
                  "x_test.shape = (109379, 321)\n",
                  "y_train.shape = (328135,)\n",
                  "train_ids.shape = (328135,)\n",
                  "test_ids.shape = (109379,)\n"
               ]
            }
         ],
         "source": [
            "print(\"x_train.shape =\", x_train.shape)\n",
            "print(\"x_test.shape =\", x_test.shape)\n",
            "print(\"y_train.shape =\", y_train.shape)\n",
            "print(\"train_ids.shape =\", train_ids.shape)\n",
            "print(\"test_ids.shape =\", test_ids.shape)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "# replace -1 with 0 in y_train\n",
            "y_train[np.where(y_train == -1)] = 0"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []\n",
            "# Example\n",
            "# new_result = {\n",
            "#     \"Drop Threshold\": 0.5,\n",
            "#     \"Drop corr thresh.\": 0.6,\n",
            "#     \"Imputation\": \"mean\",\n",
            "#     \"Standardization\": \"z-score\",\n",
            "#     \"Build Poly\": True,\n",
            "#     \"Build Log\": False,\n",
            "#     \"Build Ratios\": True,\n",
            "#     \"Model\": \"Logistic\",\n",
            "#     \"Initial W\": 0.5,\n",
            "#     \"Max Iters\": 100,\n",
            "#     \"Gamma\": 0.01,\n",
            "#     \"Lambda\": 0.1,\n",
            "#     \"CV F1\": 0.9,\n",
            "#     \"CV Accuracy\": 95\n",
            "# }\n",
            "# results.append(new_result)\n"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Experiments using different drop NaN threshold"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 58,
         "metadata": {},
         "outputs": [],
         "source": [
            "#### BASELINE ####\n",
            "\n",
            "### Column dropping and imputation ###\n",
            "# threshold for drop_columns function\n",
            "DROP_NAN_THRESHOLD = 1  # 1 = keep everything, 0 = drop everything that contains nan\n",
            "# threshold for categorical/numerical (categorical are imputated with median, numerical with mean)\n",
            "CAT_NUM_THRESHOLD = 30\n",
            "# flag for drop_single_value_columns function\n",
            "# Should always be True, otherwise it is messing up with the correlation coefficient.\n",
            "DROP_SINGLE = True\n",
            "# threshold for drop_correlated_columns function\n",
            "DROP_CORR_THRESHOLD = 0.9\n",
            "\n",
            "### Feature processing ###\n",
            "# flag for build_poly function\n",
            "BUILD_POLY = False\n",
            "# degree for build_poly function\n",
            "DEGREE = 2\n",
            "# flag for build_log function\n",
            "BUILD_LOG = False  # TODO: TO BE IMPLEMENTED\n",
            "# flag for build_x\n",
            "BUILD_RATIOS = False  # TODO: TO BE IMPLEMENTED\n",
            "# flag for standardize function\n",
            "STANDARDIZE = True\n",
            "\n",
            "NUM_FOLDS = 5\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 59,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 60,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.0...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67452\n",
                  "Test loss: 0.67480\n",
                  "Train accuracy: 0.61024\n",
                  "Train f1_score: 0.28764\n",
                  "Test accuracy: 0.61060\n",
                  "Test f1_score: 0.28343\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67456\n",
                  "Test loss: 0.67457\n",
                  "Train accuracy: 0.60903\n",
                  "Train f1_score: 0.28751\n",
                  "Test accuracy: 0.60900\n",
                  "Test f1_score: 0.28268\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67455\n",
                  "Test loss: 0.67467\n",
                  "Train accuracy: 0.60862\n",
                  "Train f1_score: 0.28531\n",
                  "Test accuracy: 0.60663\n",
                  "Test f1_score: 0.28803\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67468\n",
                  "Test loss: 0.67413\n",
                  "Train accuracy: 0.60989\n",
                  "Train f1_score: 0.28649\n",
                  "Test accuracy: 0.61136\n",
                  "Test f1_score: 0.28854\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67434\n",
                  "Test loss: 0.67551\n",
                  "Train accuracy: 0.60960\n",
                  "Train f1_score: 0.28579\n",
                  "Test accuracy: 0.60722\n",
                  "Test f1_score: 0.28838\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.609476 ± 0.000583\n",
                  "f1_score : 0.286549 ± 0.000922\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.608963 ± 0.001842\n",
                  "f1_score : 0.286213 ± 0.002595\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67649\n",
                  "Test loss: 0.67657\n",
                  "Train accuracy: 0.60459\n",
                  "Train f1_score: 0.28378\n",
                  "Test accuracy: 0.60559\n",
                  "Test f1_score: 0.28016\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67654\n",
                  "Test loss: 0.67644\n",
                  "Train accuracy: 0.60418\n",
                  "Train f1_score: 0.28399\n",
                  "Test accuracy: 0.60480\n",
                  "Test f1_score: 0.27928\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67649\n",
                  "Test loss: 0.67667\n",
                  "Train accuracy: 0.60470\n",
                  "Train f1_score: 0.28190\n",
                  "Test accuracy: 0.60286\n",
                  "Test f1_score: 0.28518\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67664\n",
                  "Test loss: 0.67612\n",
                  "Train accuracy: 0.60442\n",
                  "Train f1_score: 0.28251\n",
                  "Test accuracy: 0.60652\n",
                  "Test f1_score: 0.28526\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67631\n",
                  "Test loss: 0.67712\n",
                  "Train accuracy: 0.60488\n",
                  "Train f1_score: 0.28254\n",
                  "Test accuracy: 0.60251\n",
                  "Test f1_score: 0.28426\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.604552 ± 0.000241\n",
                  "f1_score : 0.282942 ± 0.000804\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.604455 ± 0.001548\n",
                  "f1_score : 0.282826 ± 0.002577\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.1...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67064\n",
                  "Test loss: 0.67152\n",
                  "Train accuracy: 0.62613\n",
                  "Train f1_score: 0.29748\n",
                  "Test accuracy: 0.62547\n",
                  "Test f1_score: 0.29287\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67071\n",
                  "Test loss: 0.67122\n",
                  "Train accuracy: 0.62427\n",
                  "Train f1_score: 0.29692\n",
                  "Test accuracy: 0.62409\n",
                  "Test f1_score: 0.29182\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67068\n",
                  "Test loss: 0.67137\n",
                  "Train accuracy: 0.62526\n",
                  "Train f1_score: 0.29573\n",
                  "Test accuracy: 0.62166\n",
                  "Test f1_score: 0.29721\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67106\n",
                  "Test loss: 0.66982\n",
                  "Train accuracy: 0.62463\n",
                  "Train f1_score: 0.29581\n",
                  "Test accuracy: 0.62764\n",
                  "Test f1_score: 0.29845\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67057\n",
                  "Test loss: 0.67180\n",
                  "Train accuracy: 0.62571\n",
                  "Train f1_score: 0.29549\n",
                  "Test accuracy: 0.62447\n",
                  "Test f1_score: 0.29908\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.625200 ± 0.000680\n",
                  "f1_score : 0.296285 ± 0.000774\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.624667 ± 0.001942\n",
                  "f1_score : 0.295888 ± 0.002970\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67212\n",
                  "Test loss: 0.67250\n",
                  "Train accuracy: 0.62154\n",
                  "Train f1_score: 0.29562\n",
                  "Test accuracy: 0.62195\n",
                  "Test f1_score: 0.29179\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67218\n",
                  "Test loss: 0.67237\n",
                  "Train accuracy: 0.62037\n",
                  "Train f1_score: 0.29571\n",
                  "Test accuracy: 0.61999\n",
                  "Test f1_score: 0.28999\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67213\n",
                  "Test loss: 0.67260\n",
                  "Train accuracy: 0.62136\n",
                  "Train f1_score: 0.29413\n",
                  "Test accuracy: 0.61924\n",
                  "Test f1_score: 0.29631\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67246\n",
                  "Test loss: 0.67153\n",
                  "Train accuracy: 0.62050\n",
                  "Train f1_score: 0.29431\n",
                  "Test accuracy: 0.62206\n",
                  "Test f1_score: 0.29671\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67203\n",
                  "Test loss: 0.67283\n",
                  "Train accuracy: 0.62133\n",
                  "Train f1_score: 0.29388\n",
                  "Test accuracy: 0.62045\n",
                  "Test f1_score: 0.29772\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.621021 ± 0.000485\n",
                  "f1_score : 0.294731 ± 0.000777\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.620738 ± 0.001106\n",
                  "f1_score : 0.294505 ± 0.003040\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.2...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66972\n",
                  "Test loss: 0.67080\n",
                  "Train accuracy: 0.62413\n",
                  "Train f1_score: 0.29869\n",
                  "Test accuracy: 0.62357\n",
                  "Test f1_score: 0.29417\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66983\n",
                  "Test loss: 0.67035\n",
                  "Train accuracy: 0.62288\n",
                  "Train f1_score: 0.29838\n",
                  "Test accuracy: 0.62253\n",
                  "Test f1_score: 0.29296\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66984\n",
                  "Test loss: 0.67038\n",
                  "Train accuracy: 0.62374\n",
                  "Train f1_score: 0.29709\n",
                  "Test accuracy: 0.62138\n",
                  "Test f1_score: 0.29887\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67022\n",
                  "Test loss: 0.66879\n",
                  "Train accuracy: 0.62320\n",
                  "Train f1_score: 0.29692\n",
                  "Test accuracy: 0.62621\n",
                  "Test f1_score: 0.30021\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66964\n",
                  "Test loss: 0.67113\n",
                  "Train accuracy: 0.62418\n",
                  "Train f1_score: 0.29673\n",
                  "Test accuracy: 0.62188\n",
                  "Test f1_score: 0.30049\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.623626 ± 0.000511\n",
                  "f1_score : 0.297559 ± 0.000808\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.623112 ± 0.001712\n",
                  "f1_score : 0.297341 ± 0.003156\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67129\n",
                  "Test loss: 0.67177\n",
                  "Train accuracy: 0.62049\n",
                  "Train f1_score: 0.29697\n",
                  "Test accuracy: 0.62051\n",
                  "Test f1_score: 0.29245\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67137\n",
                  "Test loss: 0.67158\n",
                  "Train accuracy: 0.61945\n",
                  "Train f1_score: 0.29683\n",
                  "Test accuracy: 0.61898\n",
                  "Test f1_score: 0.29138\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67136\n",
                  "Test loss: 0.67173\n",
                  "Train accuracy: 0.62036\n",
                  "Train f1_score: 0.29529\n",
                  "Test accuracy: 0.61882\n",
                  "Test f1_score: 0.29730\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67169\n",
                  "Test loss: 0.67064\n",
                  "Train accuracy: 0.61923\n",
                  "Train f1_score: 0.29505\n",
                  "Test accuracy: 0.62227\n",
                  "Test f1_score: 0.29909\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67119\n",
                  "Test loss: 0.67214\n",
                  "Train accuracy: 0.62014\n",
                  "Train f1_score: 0.29508\n",
                  "Test accuracy: 0.61833\n",
                  "Test f1_score: 0.29873\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.619934 ± 0.000501\n",
                  "f1_score : 0.295845 ± 0.000868\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.619781 ± 0.001444\n",
                  "f1_score : 0.295792 ± 0.003238\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.30000000000000004...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66972\n",
                  "Test loss: 0.67081\n",
                  "Train accuracy: 0.62416\n",
                  "Train f1_score: 0.29874\n",
                  "Test accuracy: 0.62343\n",
                  "Test f1_score: 0.29402\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66983\n",
                  "Test loss: 0.67035\n",
                  "Train accuracy: 0.62290\n",
                  "Train f1_score: 0.29837\n",
                  "Test accuracy: 0.62247\n",
                  "Test f1_score: 0.29288\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66984\n",
                  "Test loss: 0.67040\n",
                  "Train accuracy: 0.62368\n",
                  "Train f1_score: 0.29706\n",
                  "Test accuracy: 0.62160\n",
                  "Test f1_score: 0.29900\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67022\n",
                  "Test loss: 0.66879\n",
                  "Train accuracy: 0.62321\n",
                  "Train f1_score: 0.29688\n",
                  "Test accuracy: 0.62622\n",
                  "Test f1_score: 0.30018\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66964\n",
                  "Test loss: 0.67113\n",
                  "Train accuracy: 0.62421\n",
                  "Train f1_score: 0.29672\n",
                  "Test accuracy: 0.62170\n",
                  "Test f1_score: 0.30035\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.623631 ± 0.000517\n",
                  "f1_score : 0.297554 ± 0.000833\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.623085 ± 0.001700\n",
                  "f1_score : 0.297286 ± 0.003188\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67129\n",
                  "Test loss: 0.67179\n",
                  "Train accuracy: 0.62027\n",
                  "Train f1_score: 0.29690\n",
                  "Test accuracy: 0.62010\n",
                  "Test f1_score: 0.29227\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67138\n",
                  "Test loss: 0.67159\n",
                  "Train accuracy: 0.61930\n",
                  "Train f1_score: 0.29686\n",
                  "Test accuracy: 0.61885\n",
                  "Test f1_score: 0.29143\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67136\n",
                  "Test loss: 0.67173\n",
                  "Train accuracy: 0.62037\n",
                  "Train f1_score: 0.29529\n",
                  "Test accuracy: 0.61872\n",
                  "Test f1_score: 0.29721\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67169\n",
                  "Test loss: 0.67064\n",
                  "Train accuracy: 0.61918\n",
                  "Train f1_score: 0.29504\n",
                  "Test accuracy: 0.62203\n",
                  "Test f1_score: 0.29892\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67119\n",
                  "Test loss: 0.67214\n",
                  "Train accuracy: 0.62006\n",
                  "Train f1_score: 0.29506\n",
                  "Test accuracy: 0.61836\n",
                  "Test f1_score: 0.29878\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.619836 ± 0.000499\n",
                  "f1_score : 0.295829 ± 0.000863\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.619611 ± 0.001344\n",
                  "f1_score : 0.295722 ± 0.003231\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.4...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66968\n",
                  "Test loss: 0.67080\n",
                  "Train accuracy: 0.62437\n",
                  "Train f1_score: 0.29874\n",
                  "Test accuracy: 0.62406\n",
                  "Test f1_score: 0.29424\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66978\n",
                  "Test loss: 0.67034\n",
                  "Train accuracy: 0.62341\n",
                  "Train f1_score: 0.29869\n",
                  "Test accuracy: 0.62230\n",
                  "Test f1_score: 0.29275\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66978\n",
                  "Test loss: 0.67045\n",
                  "Train accuracy: 0.62409\n",
                  "Train f1_score: 0.29737\n",
                  "Test accuracy: 0.62205\n",
                  "Test f1_score: 0.29908\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67018\n",
                  "Test loss: 0.66876\n",
                  "Train accuracy: 0.62375\n",
                  "Train f1_score: 0.29734\n",
                  "Test accuracy: 0.62659\n",
                  "Test f1_score: 0.30075\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66959\n",
                  "Test loss: 0.67112\n",
                  "Train accuracy: 0.62466\n",
                  "Train f1_score: 0.29702\n",
                  "Test accuracy: 0.62227\n",
                  "Test f1_score: 0.30067\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.624057 ± 0.000441\n",
                  "f1_score : 0.297833 ± 0.000732\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.623454 ± 0.001725\n",
                  "f1_score : 0.297499 ± 0.003357\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67124\n",
                  "Test loss: 0.67177\n",
                  "Train accuracy: 0.61989\n",
                  "Train f1_score: 0.29676\n",
                  "Test accuracy: 0.62061\n",
                  "Test f1_score: 0.29251\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67133\n",
                  "Test loss: 0.67156\n",
                  "Train accuracy: 0.61889\n",
                  "Train f1_score: 0.29667\n",
                  "Test accuracy: 0.61811\n",
                  "Test f1_score: 0.29095\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67130\n",
                  "Test loss: 0.67174\n",
                  "Train accuracy: 0.62011\n",
                  "Train f1_score: 0.29537\n",
                  "Test accuracy: 0.61827\n",
                  "Test f1_score: 0.29724\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67165\n",
                  "Test loss: 0.67058\n",
                  "Train accuracy: 0.61884\n",
                  "Train f1_score: 0.29494\n",
                  "Test accuracy: 0.62171\n",
                  "Test f1_score: 0.29894\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67114\n",
                  "Test loss: 0.67211\n",
                  "Train accuracy: 0.61998\n",
                  "Train f1_score: 0.29511\n",
                  "Test accuracy: 0.61781\n",
                  "Test f1_score: 0.29848\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.619543 ± 0.000558\n",
                  "f1_score : 0.295768 ± 0.000784\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.619303 ± 0.001564\n",
                  "f1_score : 0.295625 ± 0.003265\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.5...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66964\n",
                  "Test loss: 0.67081\n",
                  "Train accuracy: 0.62469\n",
                  "Train f1_score: 0.29876\n",
                  "Test accuracy: 0.62515\n",
                  "Test f1_score: 0.29464\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66975\n",
                  "Test loss: 0.67033\n",
                  "Train accuracy: 0.62398\n",
                  "Train f1_score: 0.29906\n",
                  "Test accuracy: 0.62272\n",
                  "Test f1_score: 0.29302\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66974\n",
                  "Test loss: 0.67047\n",
                  "Train accuracy: 0.62480\n",
                  "Train f1_score: 0.29770\n",
                  "Test accuracy: 0.62238\n",
                  "Test f1_score: 0.29923\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67015\n",
                  "Test loss: 0.66878\n",
                  "Train accuracy: 0.62414\n",
                  "Train f1_score: 0.29751\n",
                  "Test accuracy: 0.62720\n",
                  "Test f1_score: 0.30093\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66956\n",
                  "Test loss: 0.67109\n",
                  "Train accuracy: 0.62513\n",
                  "Train f1_score: 0.29720\n",
                  "Test accuracy: 0.62234\n",
                  "Test f1_score: 0.30067\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.624548 ± 0.000426\n",
                  "f1_score : 0.298044 ± 0.000729\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.623957 ± 0.001928\n",
                  "f1_score : 0.297698 ± 0.003252\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67119\n",
                  "Test loss: 0.67176\n",
                  "Train accuracy: 0.62039\n",
                  "Train f1_score: 0.29706\n",
                  "Test accuracy: 0.62064\n",
                  "Test f1_score: 0.29228\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67129\n",
                  "Test loss: 0.67154\n",
                  "Train accuracy: 0.61929\n",
                  "Train f1_score: 0.29697\n",
                  "Test accuracy: 0.61894\n",
                  "Test f1_score: 0.29132\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67125\n",
                  "Test loss: 0.67173\n",
                  "Train accuracy: 0.62043\n",
                  "Train f1_score: 0.29547\n",
                  "Test accuracy: 0.61836\n",
                  "Test f1_score: 0.29780\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67161\n",
                  "Test loss: 0.67055\n",
                  "Train accuracy: 0.61935\n",
                  "Train f1_score: 0.29533\n",
                  "Test accuracy: 0.62229\n",
                  "Test f1_score: 0.29906\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67111\n",
                  "Test loss: 0.67206\n",
                  "Train accuracy: 0.62019\n",
                  "Train f1_score: 0.29511\n",
                  "Test accuracy: 0.61857\n",
                  "Test f1_score: 0.29882\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.619930 ± 0.000504\n",
                  "f1_score : 0.295988 ± 0.000848\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.619760 ± 0.001499\n",
                  "f1_score : 0.295858 ± 0.003353\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.6000000000000001...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66936\n",
                  "Test loss: 0.67054\n",
                  "Train accuracy: 0.62848\n",
                  "Train f1_score: 0.30047\n",
                  "Test accuracy: 0.62880\n",
                  "Test f1_score: 0.29672\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66946\n",
                  "Test loss: 0.67011\n",
                  "Train accuracy: 0.62771\n",
                  "Train f1_score: 0.30078\n",
                  "Test accuracy: 0.62630\n",
                  "Test f1_score: 0.29435\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66947\n",
                  "Test loss: 0.67017\n",
                  "Train accuracy: 0.62829\n",
                  "Train f1_score: 0.29934\n",
                  "Test accuracy: 0.62596\n",
                  "Test f1_score: 0.30072\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66984\n",
                  "Test loss: 0.66859\n",
                  "Train accuracy: 0.62807\n",
                  "Train f1_score: 0.29917\n",
                  "Test accuracy: 0.63094\n",
                  "Test f1_score: 0.30262\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66927\n",
                  "Test loss: 0.67089\n",
                  "Train accuracy: 0.62885\n",
                  "Train f1_score: 0.29903\n",
                  "Test accuracy: 0.62602\n",
                  "Test f1_score: 0.30190\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.628280 ± 0.000386\n",
                  "f1_score : 0.299757 ± 0.000722\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.627604 ± 0.001974\n",
                  "f1_score : 0.299260 ± 0.003194\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67107\n",
                  "Test loss: 0.67168\n",
                  "Train accuracy: 0.62225\n",
                  "Train f1_score: 0.29802\n",
                  "Test accuracy: 0.62202\n",
                  "Test f1_score: 0.29324\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67117\n",
                  "Test loss: 0.67144\n",
                  "Train accuracy: 0.62133\n",
                  "Train f1_score: 0.29803\n",
                  "Test accuracy: 0.62090\n",
                  "Test f1_score: 0.29235\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67115\n",
                  "Test loss: 0.67161\n",
                  "Train accuracy: 0.62256\n",
                  "Train f1_score: 0.29674\n",
                  "Test accuracy: 0.62020\n",
                  "Test f1_score: 0.29862\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67148\n",
                  "Test loss: 0.67045\n",
                  "Train accuracy: 0.62135\n",
                  "Train f1_score: 0.29636\n",
                  "Test accuracy: 0.62476\n",
                  "Test f1_score: 0.30048\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67098\n",
                  "Test loss: 0.67198\n",
                  "Train accuracy: 0.62235\n",
                  "Train f1_score: 0.29637\n",
                  "Test accuracy: 0.62031\n",
                  "Test f1_score: 0.29970\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.621969 ± 0.000522\n",
                  "f1_score : 0.297104 ± 0.000761\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.621637 ± 0.001688\n",
                  "f1_score : 0.296876 ± 0.003399\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.7000000000000001...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66928\n",
                  "Test loss: 0.67049\n",
                  "Train accuracy: 0.62999\n",
                  "Train f1_score: 0.30113\n",
                  "Test accuracy: 0.62979\n",
                  "Test f1_score: 0.29650\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66939\n",
                  "Test loss: 0.67005\n",
                  "Train accuracy: 0.62893\n",
                  "Train f1_score: 0.30106\n",
                  "Test accuracy: 0.62816\n",
                  "Test f1_score: 0.29514\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66937\n",
                  "Test loss: 0.67019\n",
                  "Train accuracy: 0.62995\n",
                  "Train f1_score: 0.29976\n",
                  "Test accuracy: 0.62723\n",
                  "Test f1_score: 0.30123\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66978\n",
                  "Test loss: 0.66851\n",
                  "Train accuracy: 0.62936\n",
                  "Train f1_score: 0.29973\n",
                  "Test accuracy: 0.63186\n",
                  "Test f1_score: 0.30282\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66919\n",
                  "Test loss: 0.67081\n",
                  "Train accuracy: 0.63027\n",
                  "Train f1_score: 0.29956\n",
                  "Test accuracy: 0.62785\n",
                  "Test f1_score: 0.30274\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629700 ± 0.000486\n",
                  "f1_score : 0.300249 ± 0.000696\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628976 ± 0.001671\n",
                  "f1_score : 0.299686 ± 0.003235\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67100\n",
                  "Test loss: 0.67162\n",
                  "Train accuracy: 0.62373\n",
                  "Train f1_score: 0.29859\n",
                  "Test accuracy: 0.62342\n",
                  "Test f1_score: 0.29405\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67110\n",
                  "Test loss: 0.67138\n",
                  "Train accuracy: 0.62313\n",
                  "Train f1_score: 0.29868\n",
                  "Test accuracy: 0.62238\n",
                  "Test f1_score: 0.29315\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67107\n",
                  "Test loss: 0.67157\n",
                  "Train accuracy: 0.62423\n",
                  "Train f1_score: 0.29742\n",
                  "Test accuracy: 0.62148\n",
                  "Test f1_score: 0.29909\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67142\n",
                  "Test loss: 0.67040\n",
                  "Train accuracy: 0.62281\n",
                  "Train f1_score: 0.29707\n",
                  "Test accuracy: 0.62628\n",
                  "Test f1_score: 0.30109\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67091\n",
                  "Test loss: 0.67192\n",
                  "Train accuracy: 0.62387\n",
                  "Train f1_score: 0.29706\n",
                  "Test accuracy: 0.62209\n",
                  "Test f1_score: 0.30018\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.623554 ± 0.000513\n",
                  "f1_score : 0.297764 ± 0.000722\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.623131 ± 0.001695\n",
                  "f1_score : 0.297512 ± 0.003269\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.8...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66926\n",
                  "Test loss: 0.67048\n",
                  "Train accuracy: 0.63008\n",
                  "Train f1_score: 0.30113\n",
                  "Test accuracy: 0.62986\n",
                  "Test f1_score: 0.29663\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66938\n",
                  "Test loss: 0.67002\n",
                  "Train accuracy: 0.62904\n",
                  "Train f1_score: 0.30109\n",
                  "Test accuracy: 0.62826\n",
                  "Test f1_score: 0.29524\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66935\n",
                  "Test loss: 0.67019\n",
                  "Train accuracy: 0.63025\n",
                  "Train f1_score: 0.29991\n",
                  "Test accuracy: 0.62723\n",
                  "Test f1_score: 0.30115\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66975\n",
                  "Test loss: 0.66853\n",
                  "Train accuracy: 0.62969\n",
                  "Train f1_score: 0.29993\n",
                  "Test accuracy: 0.63178\n",
                  "Test f1_score: 0.30270\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66917\n",
                  "Test loss: 0.67082\n",
                  "Train accuracy: 0.63034\n",
                  "Train f1_score: 0.29946\n",
                  "Test accuracy: 0.62814\n",
                  "Test f1_score: 0.30290\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629879 ± 0.000474\n",
                  "f1_score : 0.300306 ± 0.000679\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.629055 ± 0.001606\n",
                  "f1_score : 0.299723 ± 0.003184\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67098\n",
                  "Test loss: 0.67160\n",
                  "Train accuracy: 0.62387\n",
                  "Train f1_score: 0.29867\n",
                  "Test accuracy: 0.62365\n",
                  "Test f1_score: 0.29413\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67109\n",
                  "Test loss: 0.67134\n",
                  "Train accuracy: 0.62312\n",
                  "Train f1_score: 0.29866\n",
                  "Test accuracy: 0.62241\n",
                  "Test f1_score: 0.29297\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67105\n",
                  "Test loss: 0.67157\n",
                  "Train accuracy: 0.62432\n",
                  "Train f1_score: 0.29737\n",
                  "Test accuracy: 0.62174\n",
                  "Test f1_score: 0.29911\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67139\n",
                  "Test loss: 0.67040\n",
                  "Train accuracy: 0.62307\n",
                  "Train f1_score: 0.29723\n",
                  "Test accuracy: 0.62643\n",
                  "Test f1_score: 0.30106\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67089\n",
                  "Test loss: 0.67192\n",
                  "Train accuracy: 0.62399\n",
                  "Train f1_score: 0.29701\n",
                  "Test accuracy: 0.62223\n",
                  "Test f1_score: 0.30025\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.623675 ± 0.000496\n",
                  "f1_score : 0.297788 ± 0.000724\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.623292 ± 0.001692\n",
                  "f1_score : 0.297506 ± 0.003308\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.9...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66921\n",
                  "Test loss: 0.67050\n",
                  "Train accuracy: 0.63067\n",
                  "Train f1_score: 0.30164\n",
                  "Test accuracy: 0.62962\n",
                  "Test f1_score: 0.29641\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66934\n",
                  "Test loss: 0.66998\n",
                  "Train accuracy: 0.62922\n",
                  "Train f1_score: 0.30117\n",
                  "Test accuracy: 0.62912\n",
                  "Test f1_score: 0.29588\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66929\n",
                  "Test loss: 0.67021\n",
                  "Train accuracy: 0.63022\n",
                  "Train f1_score: 0.30001\n",
                  "Test accuracy: 0.62787\n",
                  "Test f1_score: 0.30175\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66969\n",
                  "Test loss: 0.66858\n",
                  "Train accuracy: 0.63001\n",
                  "Train f1_score: 0.30009\n",
                  "Test accuracy: 0.63155\n",
                  "Test f1_score: 0.30241\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66911\n",
                  "Test loss: 0.67087\n",
                  "Train accuracy: 0.63055\n",
                  "Train f1_score: 0.29950\n",
                  "Test accuracy: 0.62817\n",
                  "Test f1_score: 0.30312\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.630134 ± 0.000516\n",
                  "f1_score : 0.300483 ± 0.000795\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.629265 ± 0.001307\n",
                  "f1_score : 0.299913 ± 0.003112\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67095\n",
                  "Test loss: 0.67161\n",
                  "Train accuracy: 0.62439\n",
                  "Train f1_score: 0.29894\n",
                  "Test accuracy: 0.62442\n",
                  "Test f1_score: 0.29472\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67106\n",
                  "Test loss: 0.67131\n",
                  "Train accuracy: 0.62358\n",
                  "Train f1_score: 0.29900\n",
                  "Test accuracy: 0.62339\n",
                  "Test f1_score: 0.29371\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67101\n",
                  "Test loss: 0.67157\n",
                  "Train accuracy: 0.62465\n",
                  "Train f1_score: 0.29757\n",
                  "Test accuracy: 0.62179\n",
                  "Test f1_score: 0.29926\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67135\n",
                  "Test loss: 0.67041\n",
                  "Train accuracy: 0.62378\n",
                  "Train f1_score: 0.29765\n",
                  "Test accuracy: 0.62650\n",
                  "Test f1_score: 0.30086\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67085\n",
                  "Test loss: 0.67193\n",
                  "Train accuracy: 0.62428\n",
                  "Train f1_score: 0.29720\n",
                  "Test accuracy: 0.62287\n",
                  "Test f1_score: 0.30049\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.624134 ± 0.000398\n",
                  "f1_score : 0.298072 ± 0.000750\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.623792 ± 0.001596\n",
                  "f1_score : 0.297807 ± 0.002997\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 1.0...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66826\n",
                  "Test loss: 0.67004\n",
                  "Train accuracy: 0.63552\n",
                  "Train f1_score: 0.30401\n",
                  "Test accuracy: 0.63413\n",
                  "Test f1_score: 0.29815\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66845\n",
                  "Test loss: 0.66926\n",
                  "Train accuracy: 0.63366\n",
                  "Train f1_score: 0.30324\n",
                  "Test accuracy: 0.63367\n",
                  "Test f1_score: 0.29818\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66837\n",
                  "Test loss: 0.66965\n",
                  "Train accuracy: 0.63484\n",
                  "Train f1_score: 0.30214\n",
                  "Test accuracy: 0.63207\n",
                  "Test f1_score: 0.30347\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66866\n",
                  "Test loss: 0.66845\n",
                  "Train accuracy: 0.63530\n",
                  "Train f1_score: 0.30267\n",
                  "Test accuracy: 0.63555\n",
                  "Test f1_score: 0.30443\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66818\n",
                  "Test loss: 0.67042\n",
                  "Train accuracy: 0.63515\n",
                  "Train f1_score: 0.30178\n",
                  "Test accuracy: 0.63172\n",
                  "Test f1_score: 0.30455\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.634893 ± 0.000653\n",
                  "f1_score : 0.302769 ± 0.000793\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.633428 ± 0.001399\n",
                  "f1_score : 0.301754 ± 0.002956\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67025\n",
                  "Test loss: 0.67115\n",
                  "Train accuracy: 0.62914\n",
                  "Train f1_score: 0.30135\n",
                  "Test accuracy: 0.62901\n",
                  "Test f1_score: 0.29692\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67041\n",
                  "Test loss: 0.67072\n",
                  "Train accuracy: 0.62756\n",
                  "Train f1_score: 0.30086\n",
                  "Test accuracy: 0.62778\n",
                  "Test f1_score: 0.29586\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67032\n",
                  "Test loss: 0.67110\n",
                  "Train accuracy: 0.62904\n",
                  "Train f1_score: 0.29990\n",
                  "Test accuracy: 0.62593\n",
                  "Test f1_score: 0.30042\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67062\n",
                  "Test loss: 0.67005\n",
                  "Train accuracy: 0.62811\n",
                  "Train f1_score: 0.29965\n",
                  "Test accuracy: 0.63020\n",
                  "Test f1_score: 0.30231\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67016\n",
                  "Test loss: 0.67147\n",
                  "Train accuracy: 0.62884\n",
                  "Train f1_score: 0.29942\n",
                  "Test accuracy: 0.62639\n",
                  "Test f1_score: 0.30294\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.628539 ± 0.000608\n",
                  "f1_score : 0.300235 ± 0.000741\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.627860 ± 0.001592\n",
                  "f1_score : 0.299691 ± 0.002840\n"
               ]
            }
         ],
         "source": [
            "# Test different drop thresholds, 0 to 1 with 0.1 step\n",
            "thresholds = np.arange(0, 1.1, 0.1)\n",
            "\n",
            "for threshold in thresholds:\n",
            "    DROP_NAN_THRESHOLD = threshold\n",
            "    results = execute_pipeline(\n",
            "        x_train,\n",
            "        x_test,\n",
            "        y_train,\n",
            "        DROP_NAN_THRESHOLD,\n",
            "        DROP_CORR_THRESHOLD,\n",
            "        CAT_NUM_THRESHOLD,\n",
            "        DROP_SINGLE,\n",
            "        BUILD_RATIOS,\n",
            "        BUILD_LOG,\n",
            "        BUILD_POLY,\n",
            "        DEGREE,\n",
            "        STANDARDIZE,\n",
            "        NUM_FOLDS,\n",
            "        results,\n",
            "    )\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 61,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Saving to csv...\n"
               ]
            }
         ],
         "source": [
            "print(\"Saving to csv...\")\n",
            "\n",
            "with open(\"../results/results_drop_nan.csv\", \"w\") as csvfile:\n",
            "    writer = csv.DictWriter(\n",
            "        csvfile,\n",
            "        fieldnames=[\n",
            "            \"Drop Threshold\",\n",
            "            \"Drop corr thresh.\",\n",
            "            \"Imputation\",\n",
            "            \"Standardization\",\n",
            "            \"Build Poly\",\n",
            "            \"Degree\",\n",
            "            \"Build Log\",\n",
            "            \"Build Ratios\",\n",
            "            \"Model\",\n",
            "            \"Initial W\",\n",
            "            \"Max Iters\",\n",
            "            \"Gamma\",\n",
            "            \"Lambda\",\n",
            "            \"CV F1\",\n",
            "            \"CV Accuracy\",\n",
            "        ],\n",
            "    )\n",
            "\n",
            "    writer.writeheader()\n",
            "    for result in results:\n",
            "        writer.writerow(result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 62,
         "metadata": {},
         "outputs": [],
         "source": [
            "results_drop_nan = []\n",
            "with open(\"../results/results_drop_nan.csv\", \"r\") as csvfile:\n",
            "    reader = csv.DictReader(csvfile)\n",
            "    for row in reader:\n",
            "        results_drop_nan.append(row)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 63,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Best result for Logistic Regression: \n",
                  "0.3017536017318743\n",
                  "With Drop Threshold: \n",
                  "1.0\n",
                  "Best result for Reg Logistic Regression:\n",
                  "0.299691008421669\n",
                  "With Drop Threshold: \n",
                  "1.0\n"
               ]
            }
         ],
         "source": [
            "# determine the best results for Logistic Regression drop nan threshold and for Reg Logistic Regression drop nan threshold\n",
            "best_result_logistic = max(\n",
            "    results_drop_nan,\n",
            "    key=lambda x: float(\n",
            "        x[\"CV F1\"]) if x[\"Model\"] == \"Logistic_Regression\" else 0.0,\n",
            ")\n",
            "best_result_reg_logistic = max(\n",
            "    results_drop_nan,\n",
            "    key=lambda x: float(\n",
            "        x[\"CV F1\"]) if x[\"Model\"] == \"Reg_Logistic_Regression\" else 0.0,\n",
            ")\n",
            "\n",
            "print(\"Best result for Logistic Regression: \")\n",
            "print(best_result_logistic[\"CV F1\"])\n",
            "print(\"With Drop Threshold: \")\n",
            "print(best_result_logistic[\"Drop Threshold\"])\n",
            "\n",
            "\n",
            "print(\"Best result for Reg Logistic Regression:\")\n",
            "print(best_result_reg_logistic[\"CV F1\"])\n",
            "print(\"With Drop Threshold: \")\n",
            "print(best_result_reg_logistic[\"Drop Threshold\"])\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Experiment using BUILD POLY"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "#### BASELINE ####\n",
            "\n",
            "### Column dropping and imputation ###\n",
            "# threshold for drop_columns function\n",
            "DROP_NAN_THRESHOLD = 1  # 1 = keep everything, 0 = drop everything that contains nan\n",
            "# threshold for categorical/numerical (categorical are imputated with median, numerical with mean)\n",
            "CAT_NUM_THRESHOLD = 30\n",
            "# flag for drop_single_value_columns function\n",
            "# Should always be True, otherwise it is messing up with the correlation coefficient.\n",
            "DROP_SINGLE = True\n",
            "# threshold for drop_correlated_columns function\n",
            "DROP_CORR_THRESHOLD = 0.9\n",
            "\n",
            "### Feature processing ###\n",
            "# flag for build_poly function\n",
            "BUILD_POLY = False\n",
            "# degree for build_poly function\n",
            "DEGREE = 2\n",
            "# flag for build_log function\n",
            "BUILD_LOG = False\n",
            "# flag for build_x\n",
            "BUILD_RATIOS = False\n",
            "# flag for standardize function\n",
            "STANDARDIZE = True\n",
            "\n",
            "NUM_FOLDS = 5\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Dropping single valued columns...\n",
                  "Building polynomial with degree = 2...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66351\n",
                  "Test loss: 0.66577\n",
                  "Train accuracy: 0.65875\n",
                  "Train f1_score: 0.31755\n",
                  "Test accuracy: 0.65763\n",
                  "Test f1_score: 0.31277\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66351\n",
                  "Test loss: 0.66536\n",
                  "Train accuracy: 0.65733\n",
                  "Train f1_score: 0.31729\n",
                  "Test accuracy: 0.65514\n",
                  "Test f1_score: 0.31042\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66330\n",
                  "Test loss: 0.66553\n",
                  "Train accuracy: 0.65877\n",
                  "Train f1_score: 0.31655\n",
                  "Test accuracy: 0.65548\n",
                  "Test f1_score: 0.31712\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66383\n",
                  "Test loss: 0.66392\n",
                  "Train accuracy: 0.65740\n",
                  "Train f1_score: 0.31571\n",
                  "Test accuracy: 0.65822\n",
                  "Test f1_score: 0.31724\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66330\n",
                  "Test loss: 0.66640\n",
                  "Train accuracy: 0.65775\n",
                  "Train f1_score: 0.31512\n",
                  "Test accuracy: 0.65446\n",
                  "Test f1_score: 0.31739\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.658001 ± 0.000636\n",
                  "f1_score : 0.316445 ± 0.000919\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.656184 ± 0.001469\n",
                  "f1_score : 0.314989 ± 0.002870\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67337\n",
                  "Test loss: 0.67415\n",
                  "Train accuracy: 0.63119\n",
                  "Train f1_score: 0.29786\n",
                  "Test accuracy: 0.63093\n",
                  "Test f1_score: 0.29379\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67331\n",
                  "Test loss: 0.67314\n",
                  "Train accuracy: 0.62925\n",
                  "Train f1_score: 0.29801\n",
                  "Test accuracy: 0.62901\n",
                  "Test f1_score: 0.29259\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67241\n",
                  "Test loss: 0.67378\n",
                  "Train accuracy: 0.62971\n",
                  "Train f1_score: 0.29705\n",
                  "Test accuracy: 0.62628\n",
                  "Test f1_score: 0.29801\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67332\n",
                  "Test loss: 0.67340\n",
                  "Train accuracy: 0.63056\n",
                  "Train f1_score: 0.29705\n",
                  "Test accuracy: 0.63181\n",
                  "Test f1_score: 0.29912\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67286\n",
                  "Test loss: 0.67474\n",
                  "Train accuracy: 0.63096\n",
                  "Train f1_score: 0.29650\n",
                  "Test accuracy: 0.62700\n",
                  "Test f1_score: 0.29850\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.630334 ± 0.000742\n",
                  "f1_score : 0.297293 ± 0.000560\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.629006 ± 0.002146\n",
                  "f1_score : 0.296400 ± 0.002673\n"
               ]
            }
         ],
         "source": [
            "results = []\n",
            "\n",
            "BUILD_POLY = True\n",
            "DEGREE = 2  # when we use degree 3 the kernel crashes\n",
            "\n",
            "results = execute_pipeline(\n",
            "    x_train,\n",
            "    x_test,\n",
            "    y_train,\n",
            "    DROP_NAN_THRESHOLD,\n",
            "    DROP_CORR_THRESHOLD,\n",
            "    CAT_NUM_THRESHOLD,\n",
            "    DROP_SINGLE,\n",
            "    BUILD_RATIOS,\n",
            "    BUILD_LOG,\n",
            "    BUILD_POLY,\n",
            "    DEGREE,\n",
            "    STANDARDIZE,\n",
            "    NUM_FOLDS,\n",
            "    results,\n",
            ")\n",
            "\n",
            "with open(\"../results/results_poly.csv\", \"w\") as csvfile:\n",
            "    writer = csv.DictWriter(\n",
            "        csvfile,\n",
            "        fieldnames=[\n",
            "            \"Drop Threshold\",\n",
            "            \"Drop corr thresh.\",\n",
            "            \"Imputation\",\n",
            "            \"Standardization\",\n",
            "            \"Build Poly\",\n",
            "            \"Degree\",\n",
            "            \"Build Log\",\n",
            "            \"Build Ratios\",\n",
            "            \"Model\",\n",
            "            \"Initial W\",\n",
            "            \"Max Iters\",\n",
            "            \"Gamma\",\n",
            "            \"Lambda\",\n",
            "            \"CV F1\",\n",
            "            \"CV Accuracy\",\n",
            "        ],\n",
            "    )\n",
            "\n",
            "    writer.writeheader()\n",
            "    for result in results:\n",
            "        writer.writerow(result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "results_poly = []\n",
            "with open(\"../results/results_poly.csv\", \"r\") as csvfile:\n",
            "    reader = csv.DictReader(csvfile)\n",
            "    for row in reader:\n",
            "        results_poly.append(row)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Results for build poly with degree 2, Logistic Regression: \n",
                  "0.3149890620184429\n",
                  "Results for build poly with degree 2, Reg Logistic Regression: \n",
                  "0.29639980107081965\n"
               ]
            }
         ],
         "source": [
            "print(\"Results for build poly with degree 2, Logistic Regression: \")\n",
            "print(results_poly[0][\"CV F1\"])\n",
            "print(\"Results for build poly with degree 2, Reg Logistic Regression: \")\n",
            "print(results_poly[1][\"CV F1\"])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Experiment using BUILD LOG"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [],
         "source": [
            "#### BASELINE ####\n",
            "\n",
            "### Column dropping and imputation ###\n",
            "# threshold for drop_columns function\n",
            "DROP_NAN_THRESHOLD = 1  # 1 = keep everything, 0 = drop everything that contains nan\n",
            "# threshold for categorical/numerical (categorical are imputated with median, numerical with mean)\n",
            "CAT_NUM_THRESHOLD = 30\n",
            "# flag for drop_single_value_columns function\n",
            "# Should always be True, otherwise it is messing up with the correlation coefficient.\n",
            "DROP_SINGLE = True\n",
            "# threshold for drop_correlated_columns function\n",
            "DROP_CORR_THRESHOLD = 0.9\n",
            "\n",
            "### Feature processing ###\n",
            "# flag for build_poly function\n",
            "BUILD_POLY = False\n",
            "# degree for build_poly function\n",
            "DEGREE = 2\n",
            "# flag for build_log function\n",
            "BUILD_LOG = False\n",
            "# flag for build_x\n",
            "BUILD_RATIOS = False\n",
            "# flag for standardize function\n",
            "STANDARDIZE = True\n",
            "\n",
            "NUM_FOLDS = 5\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Dropping single valued columns...\n",
                  "Building log...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67492\n",
                  "Test loss: 0.67719\n",
                  "Train accuracy: 0.61004\n",
                  "Train f1_score: 0.25374\n",
                  "Test accuracy: 0.60530\n",
                  "Test f1_score: 0.24461\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67424\n",
                  "Test loss: 0.67542\n",
                  "Train accuracy: 0.61505\n",
                  "Train f1_score: 0.25763\n",
                  "Test accuracy: 0.61638\n",
                  "Test f1_score: 0.25294\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67443\n",
                  "Test loss: 0.67566\n",
                  "Train accuracy: 0.61277\n",
                  "Train f1_score: 0.25554\n",
                  "Test accuracy: 0.60867\n",
                  "Test f1_score: 0.25339\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67706\n",
                  "Test loss: 0.67873\n",
                  "Train accuracy: 0.59908\n",
                  "Train f1_score: 0.24234\n",
                  "Test accuracy: 0.59448\n",
                  "Test f1_score: 0.24190\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67514\n",
                  "Test loss: 0.67742\n",
                  "Train accuracy: 0.61023\n",
                  "Train f1_score: 0.25063\n",
                  "Test accuracy: 0.60509\n",
                  "Test f1_score: 0.25537\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.609436 ± 0.005493\n",
                  "f1_score : 0.251973 ± 0.005338\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.605982 ± 0.007054\n",
                  "f1_score : 0.249641 ± 0.005345\n",
                  "Fold 1/5\n",
                  "Train loss: 0.71360\n",
                  "Test loss: 0.71463\n",
                  "Train accuracy: 0.50132\n",
                  "Train f1_score: 0.14526\n",
                  "Test accuracy: 0.50217\n",
                  "Test f1_score: 0.14207\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.71267\n",
                  "Test loss: 0.71224\n",
                  "Train accuracy: 0.50327\n",
                  "Train f1_score: 0.14722\n",
                  "Test accuracy: 0.50475\n",
                  "Test f1_score: 0.14329\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.71278\n",
                  "Test loss: 0.71345\n",
                  "Train accuracy: 0.50501\n",
                  "Train f1_score: 0.14631\n",
                  "Test accuracy: 0.50328\n",
                  "Test f1_score: 0.14660\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.71580\n",
                  "Test loss: 0.71695\n",
                  "Train accuracy: 0.49947\n",
                  "Train f1_score: 0.14010\n",
                  "Test accuracy: 0.49582\n",
                  "Test f1_score: 0.13923\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.71359\n",
                  "Test loss: 0.71524\n",
                  "Train accuracy: 0.50402\n",
                  "Train f1_score: 0.14466\n",
                  "Test accuracy: 0.50161\n",
                  "Test f1_score: 0.14907\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.502617 ± 0.001985\n",
                  "f1_score : 0.144711 ± 0.002465\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.501525 ± 0.003049\n",
                  "f1_score : 0.144052 ± 0.003449\n"
               ]
            }
         ],
         "source": [
            "results = []\n",
            "\n",
            "BUILD_LOG = True\n",
            "\n",
            "results = execute_pipeline(\n",
            "    x_train,\n",
            "    x_test,\n",
            "    y_train,\n",
            "    DROP_NAN_THRESHOLD,\n",
            "    DROP_CORR_THRESHOLD,\n",
            "    CAT_NUM_THRESHOLD,\n",
            "    DROP_SINGLE,\n",
            "    BUILD_RATIOS,\n",
            "    BUILD_LOG,\n",
            "    BUILD_POLY,\n",
            "    DEGREE,\n",
            "    STANDARDIZE,\n",
            "    NUM_FOLDS,\n",
            "    results,\n",
            ")\n",
            "\n",
            "with open(\"../results/results_log.csv\", \"w\") as csvfile:\n",
            "    writer = csv.DictWriter(\n",
            "        csvfile,\n",
            "        fieldnames=[\n",
            "            \"Drop Threshold\",\n",
            "            \"Drop corr thresh.\",\n",
            "            \"Imputation\",\n",
            "            \"Standardization\",\n",
            "            \"Build Poly\",\n",
            "            \"Degree\",\n",
            "            \"Build Log\",\n",
            "            \"Build Ratios\",\n",
            "            \"Model\",\n",
            "            \"Initial W\",\n",
            "            \"Max Iters\",\n",
            "            \"Gamma\",\n",
            "            \"Lambda\",\n",
            "            \"CV F1\",\n",
            "            \"CV Accuracy\",\n",
            "        ],\n",
            "    )\n",
            "\n",
            "    writer.writeheader()\n",
            "    for result in results:\n",
            "        writer.writerow(result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [],
         "source": [
            "results_log = []\n",
            "with open(\"../results/results_log.csv\", \"r\") as csvfile:\n",
            "    reader = csv.DictReader(csvfile)\n",
            "    for row in reader:\n",
            "        results_log.append(row)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Results for build log, Logistic Regression: \n",
                  "0.24964105408875517\n",
                  "Results for build log, Reg Logistic Regression: \n",
                  "0.14405154926770522\n"
               ]
            }
         ],
         "source": [
            "print(\"Results for build log, Logistic Regression: \")\n",
            "print(results_log[0][\"CV F1\"])\n",
            "print(\"Results for build log, Reg Logistic Regression: \")\n",
            "print(results_log[1][\"CV F1\"])\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Experiment using BUILD RATIOS"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "#### BASELINE ####\n",
            "\n",
            "### Column dropping and imputation ###\n",
            "# threshold for drop_columns function\n",
            "DROP_NAN_THRESHOLD = 1  # 1 = keep everything, 0 = drop everything that contains nan\n",
            "# threshold for categorical/numerical (categorical are imputated with median, numerical with mean)\n",
            "CAT_NUM_THRESHOLD = 30\n",
            "# flag for drop_single_value_columns function\n",
            "# Should always be True, otherwise it is messing up with the correlation coefficient.\n",
            "DROP_SINGLE = True\n",
            "# threshold for drop_correlated_columns function\n",
            "DROP_CORR_THRESHOLD = 0.9\n",
            "\n",
            "### Feature processing ###\n",
            "# flag for build_poly function\n",
            "BUILD_POLY = False\n",
            "# degree for build_poly function\n",
            "DEGREE = 2\n",
            "# flag for build_log function\n",
            "BUILD_LOG = False\n",
            "# flag for build_x\n",
            "BUILD_RATIOS = False\n",
            "# flag for standardize function\n",
            "STANDARDIZE = True\n",
            "\n",
            "NUM_FOLDS = 5\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Dropping single valued columns...\n",
                  "Building ratios...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 1.14464\n",
                  "Test loss: 1.15645\n",
                  "Train accuracy: 0.06569\n",
                  "Train f1_score: 0.33307\n",
                  "Test accuracy: 0.06453\n",
                  "Test f1_score: 0.32926\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 1.15013\n",
                  "Test loss: 1.15796\n",
                  "Train accuracy: 0.06594\n",
                  "Train f1_score: 0.33468\n",
                  "Test accuracy: 0.06453\n",
                  "Test f1_score: 0.32911\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 1.16565\n",
                  "Test loss: 1.25769\n",
                  "Train accuracy: 0.06453\n",
                  "Train f1_score: 0.33589\n",
                  "Test accuracy: 0.06435\n",
                  "Test f1_score: 0.33094\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 1.12160\n",
                  "Test loss: 1.09560\n",
                  "Train accuracy: 0.06606\n",
                  "Train f1_score: 0.33055\n",
                  "Test accuracy: 0.06671\n",
                  "Test f1_score: 0.33491\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 1.11553\n",
                  "Test loss: 1.14193\n",
                  "Train accuracy: 0.06618\n",
                  "Train f1_score: 0.33135\n",
                  "Test accuracy: 0.06755\n",
                  "Test f1_score: 0.33153\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.065681 ± 0.000598\n",
                  "f1_score : 0.333110 ± 0.001993\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.065534 ± 0.001331\n",
                  "f1_score : 0.331152 ± 0.002101\n",
                  "Fold 1/5\n",
                  "Train loss: 1.35648\n",
                  "Test loss: 1.35750\n",
                  "Train accuracy: 0.05601\n",
                  "Train f1_score: 0.33607\n",
                  "Test accuracy: 0.05518\n",
                  "Test f1_score: 0.33349\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 1.35602\n",
                  "Test loss: 1.36406\n",
                  "Train accuracy: 0.05605\n",
                  "Train f1_score: 0.33689\n",
                  "Test accuracy: 0.05502\n",
                  "Test f1_score: 0.33133\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 1.36451\n",
                  "Test loss: 1.45971\n",
                  "Train accuracy: 0.05468\n",
                  "Train f1_score: 0.33615\n",
                  "Test accuracy: 0.05489\n",
                  "Test f1_score: 0.33439\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 1.33927\n",
                  "Test loss: 1.28963\n",
                  "Train accuracy: 0.05676\n",
                  "Train f1_score: 0.33456\n",
                  "Test accuracy: 0.05755\n",
                  "Test f1_score: 0.34158\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 1.34152\n",
                  "Test loss: 1.32847\n",
                  "Train accuracy: 0.05675\n",
                  "Train f1_score: 0.33574\n",
                  "Test accuracy: 0.05780\n",
                  "Test f1_score: 0.33671\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.056050 ± 0.000758\n",
                  "f1_score : 0.335884 ± 0.000761\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.056087 ± 0.001302\n",
                  "f1_score : 0.335497 ± 0.003495\n"
               ]
            }
         ],
         "source": [
            "results = []\n",
            "\n",
            "BUILD_RATIOS = True\n",
            "\n",
            "results = execute_pipeline(\n",
            "    x_train,\n",
            "    x_test,\n",
            "    y_train,\n",
            "    DROP_NAN_THRESHOLD,\n",
            "    DROP_CORR_THRESHOLD,\n",
            "    CAT_NUM_THRESHOLD,\n",
            "    DROP_SINGLE,\n",
            "    BUILD_RATIOS,\n",
            "    BUILD_LOG,\n",
            "    BUILD_POLY,\n",
            "    DEGREE,\n",
            "    STANDARDIZE,\n",
            "    NUM_FOLDS,\n",
            "    results,\n",
            ")\n",
            "\n",
            "with open(\"../results/results_ratios.csv\", \"w\") as csvfile:\n",
            "    writer = csv.DictWriter(\n",
            "        csvfile,\n",
            "        fieldnames=[\n",
            "            \"Drop Threshold\",\n",
            "            \"Drop corr thresh.\",\n",
            "            \"Imputation\",\n",
            "            \"Standardization\",\n",
            "            \"Build Poly\",\n",
            "            \"Degree\",\n",
            "            \"Build Log\",\n",
            "            \"Build Ratios\",\n",
            "            \"Model\",\n",
            "            \"Initial W\",\n",
            "            \"Max Iters\",\n",
            "            \"Gamma\",\n",
            "            \"Lambda\",\n",
            "            \"CV F1\",\n",
            "            \"CV Accuracy\",\n",
            "        ],\n",
            "    )\n",
            "\n",
            "    writer.writeheader()\n",
            "    for result in results:\n",
            "        writer.writerow(result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [],
         "source": [
            "results_ratios = []\n",
            "with open(\"../results/results_ratios.csv\", \"r\") as csvfile:\n",
            "    reader = csv.DictReader(csvfile)\n",
            "    for row in reader:\n",
            "        results_ratios.append(row)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Results for build ratios, Logistic Regression: \n",
                  "0.33115178907719345\n",
                  "0.0655340027732488\n",
                  "Results for build ratios, Reg Logistic Regression: \n",
                  "0.33549740021554086\n",
                  "0.05608667164429274\n"
               ]
            }
         ],
         "source": [
            "print(\"Results for build ratios, Logistic Regression: \")\n",
            "print(results_ratios[0][\"CV F1\"])\n",
            "print(results_ratios[0][\"CV Accuracy\"])\n",
            "print(\"Results for build ratios, Reg Logistic Regression: \")\n",
            "print(results_ratios[1][\"CV F1\"])\n",
            "print(results_ratios[1][\"CV Accuracy\"])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.9.18"
      },
      "vscode": {
         "interpreter": {
            "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
