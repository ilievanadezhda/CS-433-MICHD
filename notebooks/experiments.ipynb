{
   "cells": [
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Experiment pipeline"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "%load_ext autoreload\n",
            "%autoreload 2\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "import sys\n",
            "\n",
            "sys.path.append(\"../\")\n",
            "# add ../ to path"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "import numpy as np\n",
            "from helpers import load_csv_data\n",
            "from feature_processing import (\n",
            "    drop_columns,\n",
            "    drop_correlated_columns,\n",
            "    drop_single_value_columns,\n",
            "    median_imputation,\n",
            "    mean_imputation,\n",
            "    standardize,\n",
            "    build_poly,\n",
            "    build_k_indices,\n",
            "    build_log,\n",
            "    build_ratios,\n",
            ")\n",
            "from cross_validation import (\n",
            "    predict_mse,\n",
            "    predict_logistic,\n",
            "    accuracy,\n",
            "    f1_score,\n",
            "    print_results,\n",
            "    cross_validation,\n",
            ")\n",
            "from implementations import (\n",
            "    mean_squared_error_gd,\n",
            "    mean_squared_error_sgd,\n",
            "    least_squares,\n",
            "    ridge_regression,\n",
            "    logistic_regression,\n",
            "    reg_logistic_regression,\n",
            ")\n",
            "from implementations_utils import compute_loss_mse, compute_loss_logistic\n",
            "import csv\n",
            "from pipeline import execute_pipeline"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Loading data...\n",
                  "Data loaded...\n"
               ]
            }
         ],
         "source": [
            "print(\"Loading data...\")\n",
            "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"../../data/\")\n",
            "print(\"Data loaded...\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "x_train.shape = (328135, 321)\n",
                  "x_test.shape = (109379, 321)\n",
                  "y_train.shape = (328135,)\n",
                  "train_ids.shape = (328135,)\n",
                  "test_ids.shape = (109379,)\n"
               ]
            }
         ],
         "source": [
            "print(\"x_train.shape =\", x_train.shape)\n",
            "print(\"x_test.shape =\", x_test.shape)\n",
            "print(\"y_train.shape =\", y_train.shape)\n",
            "print(\"train_ids.shape =\", train_ids.shape)\n",
            "print(\"test_ids.shape =\", test_ids.shape)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "# replace -1 with 0 in y_train\n",
            "y_train[np.where(y_train == -1)] = 0"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []\n",
            "# Example\n",
            "# new_result = {\n",
            "#     \"Drop Threshold\": 0.5,\n",
            "#     \"Drop corr thresh.\": 0.6,\n",
            "#     \"Imputation\": \"mean\",\n",
            "#     \"Standardization\": \"z-score\",\n",
            "#     \"Build Poly\": True,\n",
            "#     \"Build Log\": False,\n",
            "#     \"Build Ratios\": True,\n",
            "#     \"Model\": \"Logistic\",\n",
            "#     \"Initial W\": 0.5,\n",
            "#     \"Max Iters\": 100,\n",
            "#     \"Gamma\": 0.01,\n",
            "#     \"Lambda\": 0.1,\n",
            "#     \"CV F1\": 0.9,\n",
            "#     \"CV Accuracy\": 95\n",
            "# }\n",
            "# results.append(new_result)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Experiments using different drop NaN threshold"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "#### BASELINE ####\n",
            "\n",
            "### Column dropping and imputation ###\n",
            "# threshold for drop_columns function\n",
            "DROP_NAN_THRESHOLD = 0.9  # 1 = keep everything, 0 = drop everything that contains nan\n",
            "# threshold for categorical/numerical (categorical are imputated with median, numerical with mean)\n",
            "CAT_NUM_THRESHOLD = 90\n",
            "# flag for drop_single_value_columns function\n",
            "# Should always be True, otherwise it is messing up with the correlation coefficient.\n",
            "DROP_SINGLE = True\n",
            "# threshold for drop_correlated_columns function\n",
            "DROP_CORR_THRESHOLD = 0.8\n",
            "\n",
            "### Feature processing ###\n",
            "# flag for build_poly function\n",
            "BUILD_POLY = False\n",
            "# degree for build_poly function\n",
            "DEGREE = 2\n",
            "# flag for build_log function\n",
            "BUILD_LOG = True\n",
            "# flag for build_x\n",
            "BUILD_RATIOS = True\n",
            "# flag for standardize function\n",
            "STANDARDIZE = True\n",
            "\n",
            "NUM_FOLDS = 5\n",
            "\n",
            "GAMMA = 0.5\n",
            "MAX_ITERS = 300\n",
            "LAMBDA = 0.1"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.0...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67452\n",
                  "Test loss: 0.67480\n",
                  "Train accuracy: 0.61024\n",
                  "Train f1_score: 0.28764\n",
                  "Test accuracy: 0.61060\n",
                  "Test f1_score: 0.28343\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67456\n",
                  "Test loss: 0.67457\n",
                  "Train accuracy: 0.60903\n",
                  "Train f1_score: 0.28751\n",
                  "Test accuracy: 0.60900\n",
                  "Test f1_score: 0.28268\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67455\n",
                  "Test loss: 0.67467\n",
                  "Train accuracy: 0.60862\n",
                  "Train f1_score: 0.28531\n",
                  "Test accuracy: 0.60663\n",
                  "Test f1_score: 0.28803\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67468\n",
                  "Test loss: 0.67413\n",
                  "Train accuracy: 0.60989\n",
                  "Train f1_score: 0.28649\n",
                  "Test accuracy: 0.61136\n",
                  "Test f1_score: 0.28854\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67434\n",
                  "Test loss: 0.67551\n",
                  "Train accuracy: 0.60960\n",
                  "Train f1_score: 0.28579\n",
                  "Test accuracy: 0.60722\n",
                  "Test f1_score: 0.28838\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.609476 ± 0.000583\n",
                  "f1_score : 0.286549 ± 0.000922\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.608963 ± 0.001842\n",
                  "f1_score : 0.286213 ± 0.002595\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67649\n",
                  "Test loss: 0.67657\n",
                  "Train accuracy: 0.60459\n",
                  "Train f1_score: 0.28378\n",
                  "Test accuracy: 0.60559\n",
                  "Test f1_score: 0.28016\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67654\n",
                  "Test loss: 0.67644\n",
                  "Train accuracy: 0.60418\n",
                  "Train f1_score: 0.28399\n",
                  "Test accuracy: 0.60480\n",
                  "Test f1_score: 0.27928\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67649\n",
                  "Test loss: 0.67667\n",
                  "Train accuracy: 0.60470\n",
                  "Train f1_score: 0.28190\n",
                  "Test accuracy: 0.60286\n",
                  "Test f1_score: 0.28518\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67664\n",
                  "Test loss: 0.67612\n",
                  "Train accuracy: 0.60442\n",
                  "Train f1_score: 0.28251\n",
                  "Test accuracy: 0.60652\n",
                  "Test f1_score: 0.28526\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67631\n",
                  "Test loss: 0.67712\n",
                  "Train accuracy: 0.60488\n",
                  "Train f1_score: 0.28254\n",
                  "Test accuracy: 0.60251\n",
                  "Test f1_score: 0.28426\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.604552 ± 0.000241\n",
                  "f1_score : 0.282942 ± 0.000804\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.604455 ± 0.001548\n",
                  "f1_score : 0.282826 ± 0.002577\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.1...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67064\n",
                  "Test loss: 0.67152\n",
                  "Train accuracy: 0.62613\n",
                  "Train f1_score: 0.29748\n",
                  "Test accuracy: 0.62547\n",
                  "Test f1_score: 0.29287\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67071\n",
                  "Test loss: 0.67122\n",
                  "Train accuracy: 0.62427\n",
                  "Train f1_score: 0.29692\n",
                  "Test accuracy: 0.62409\n",
                  "Test f1_score: 0.29182\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67068\n",
                  "Test loss: 0.67137\n",
                  "Train accuracy: 0.62526\n",
                  "Train f1_score: 0.29573\n",
                  "Test accuracy: 0.62166\n",
                  "Test f1_score: 0.29721\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67106\n",
                  "Test loss: 0.66982\n",
                  "Train accuracy: 0.62463\n",
                  "Train f1_score: 0.29581\n",
                  "Test accuracy: 0.62764\n",
                  "Test f1_score: 0.29845\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67057\n",
                  "Test loss: 0.67180\n",
                  "Train accuracy: 0.62571\n",
                  "Train f1_score: 0.29549\n",
                  "Test accuracy: 0.62447\n",
                  "Test f1_score: 0.29908\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.625200 ± 0.000680\n",
                  "f1_score : 0.296285 ± 0.000774\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.624667 ± 0.001942\n",
                  "f1_score : 0.295888 ± 0.002970\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67212\n",
                  "Test loss: 0.67250\n",
                  "Train accuracy: 0.62154\n",
                  "Train f1_score: 0.29562\n",
                  "Test accuracy: 0.62195\n",
                  "Test f1_score: 0.29179\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67218\n",
                  "Test loss: 0.67237\n",
                  "Train accuracy: 0.62037\n",
                  "Train f1_score: 0.29571\n",
                  "Test accuracy: 0.61999\n",
                  "Test f1_score: 0.28999\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67213\n",
                  "Test loss: 0.67260\n",
                  "Train accuracy: 0.62136\n",
                  "Train f1_score: 0.29413\n",
                  "Test accuracy: 0.61924\n",
                  "Test f1_score: 0.29631\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67246\n",
                  "Test loss: 0.67153\n",
                  "Train accuracy: 0.62050\n",
                  "Train f1_score: 0.29431\n",
                  "Test accuracy: 0.62206\n",
                  "Test f1_score: 0.29671\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67203\n",
                  "Test loss: 0.67283\n",
                  "Train accuracy: 0.62133\n",
                  "Train f1_score: 0.29388\n",
                  "Test accuracy: 0.62045\n",
                  "Test f1_score: 0.29772\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.621021 ± 0.000485\n",
                  "f1_score : 0.294731 ± 0.000777\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.620738 ± 0.001106\n",
                  "f1_score : 0.294505 ± 0.003040\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.2...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66972\n",
                  "Test loss: 0.67080\n",
                  "Train accuracy: 0.62413\n",
                  "Train f1_score: 0.29869\n",
                  "Test accuracy: 0.62357\n",
                  "Test f1_score: 0.29417\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66983\n",
                  "Test loss: 0.67035\n",
                  "Train accuracy: 0.62288\n",
                  "Train f1_score: 0.29838\n",
                  "Test accuracy: 0.62253\n",
                  "Test f1_score: 0.29296\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66984\n",
                  "Test loss: 0.67038\n",
                  "Train accuracy: 0.62374\n",
                  "Train f1_score: 0.29709\n",
                  "Test accuracy: 0.62138\n",
                  "Test f1_score: 0.29887\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67022\n",
                  "Test loss: 0.66879\n",
                  "Train accuracy: 0.62320\n",
                  "Train f1_score: 0.29692\n",
                  "Test accuracy: 0.62621\n",
                  "Test f1_score: 0.30021\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66964\n",
                  "Test loss: 0.67113\n",
                  "Train accuracy: 0.62418\n",
                  "Train f1_score: 0.29673\n",
                  "Test accuracy: 0.62188\n",
                  "Test f1_score: 0.30049\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.623626 ± 0.000511\n",
                  "f1_score : 0.297559 ± 0.000808\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.623112 ± 0.001712\n",
                  "f1_score : 0.297341 ± 0.003156\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67129\n",
                  "Test loss: 0.67177\n",
                  "Train accuracy: 0.62049\n",
                  "Train f1_score: 0.29697\n",
                  "Test accuracy: 0.62051\n",
                  "Test f1_score: 0.29245\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67137\n",
                  "Test loss: 0.67158\n",
                  "Train accuracy: 0.61945\n",
                  "Train f1_score: 0.29683\n",
                  "Test accuracy: 0.61898\n",
                  "Test f1_score: 0.29138\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67136\n",
                  "Test loss: 0.67173\n",
                  "Train accuracy: 0.62036\n",
                  "Train f1_score: 0.29529\n",
                  "Test accuracy: 0.61882\n",
                  "Test f1_score: 0.29730\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67169\n",
                  "Test loss: 0.67064\n",
                  "Train accuracy: 0.61923\n",
                  "Train f1_score: 0.29505\n",
                  "Test accuracy: 0.62227\n",
                  "Test f1_score: 0.29909\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67119\n",
                  "Test loss: 0.67214\n",
                  "Train accuracy: 0.62014\n",
                  "Train f1_score: 0.29508\n",
                  "Test accuracy: 0.61833\n",
                  "Test f1_score: 0.29873\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.619934 ± 0.000501\n",
                  "f1_score : 0.295845 ± 0.000868\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.619781 ± 0.001444\n",
                  "f1_score : 0.295792 ± 0.003238\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.30000000000000004...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66972\n",
                  "Test loss: 0.67081\n",
                  "Train accuracy: 0.62416\n",
                  "Train f1_score: 0.29874\n",
                  "Test accuracy: 0.62343\n",
                  "Test f1_score: 0.29402\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66983\n",
                  "Test loss: 0.67035\n",
                  "Train accuracy: 0.62290\n",
                  "Train f1_score: 0.29837\n",
                  "Test accuracy: 0.62247\n",
                  "Test f1_score: 0.29288\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66984\n",
                  "Test loss: 0.67040\n",
                  "Train accuracy: 0.62368\n",
                  "Train f1_score: 0.29706\n",
                  "Test accuracy: 0.62160\n",
                  "Test f1_score: 0.29900\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67022\n",
                  "Test loss: 0.66879\n",
                  "Train accuracy: 0.62321\n",
                  "Train f1_score: 0.29688\n",
                  "Test accuracy: 0.62622\n",
                  "Test f1_score: 0.30018\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66964\n",
                  "Test loss: 0.67113\n",
                  "Train accuracy: 0.62421\n",
                  "Train f1_score: 0.29672\n",
                  "Test accuracy: 0.62170\n",
                  "Test f1_score: 0.30035\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.623631 ± 0.000517\n",
                  "f1_score : 0.297554 ± 0.000833\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.623085 ± 0.001700\n",
                  "f1_score : 0.297286 ± 0.003188\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67129\n",
                  "Test loss: 0.67179\n",
                  "Train accuracy: 0.62027\n",
                  "Train f1_score: 0.29690\n",
                  "Test accuracy: 0.62010\n",
                  "Test f1_score: 0.29227\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67138\n",
                  "Test loss: 0.67159\n",
                  "Train accuracy: 0.61930\n",
                  "Train f1_score: 0.29686\n",
                  "Test accuracy: 0.61885\n",
                  "Test f1_score: 0.29143\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67136\n",
                  "Test loss: 0.67173\n",
                  "Train accuracy: 0.62037\n",
                  "Train f1_score: 0.29529\n",
                  "Test accuracy: 0.61872\n",
                  "Test f1_score: 0.29721\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67169\n",
                  "Test loss: 0.67064\n",
                  "Train accuracy: 0.61918\n",
                  "Train f1_score: 0.29504\n",
                  "Test accuracy: 0.62203\n",
                  "Test f1_score: 0.29892\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67119\n",
                  "Test loss: 0.67214\n",
                  "Train accuracy: 0.62006\n",
                  "Train f1_score: 0.29506\n",
                  "Test accuracy: 0.61836\n",
                  "Test f1_score: 0.29878\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.619836 ± 0.000499\n",
                  "f1_score : 0.295829 ± 0.000863\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.619611 ± 0.001344\n",
                  "f1_score : 0.295722 ± 0.003231\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.4...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66968\n",
                  "Test loss: 0.67080\n",
                  "Train accuracy: 0.62437\n",
                  "Train f1_score: 0.29874\n",
                  "Test accuracy: 0.62406\n",
                  "Test f1_score: 0.29424\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66978\n",
                  "Test loss: 0.67034\n",
                  "Train accuracy: 0.62341\n",
                  "Train f1_score: 0.29869\n",
                  "Test accuracy: 0.62230\n",
                  "Test f1_score: 0.29275\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66978\n",
                  "Test loss: 0.67045\n",
                  "Train accuracy: 0.62409\n",
                  "Train f1_score: 0.29737\n",
                  "Test accuracy: 0.62205\n",
                  "Test f1_score: 0.29908\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67018\n",
                  "Test loss: 0.66876\n",
                  "Train accuracy: 0.62375\n",
                  "Train f1_score: 0.29734\n",
                  "Test accuracy: 0.62659\n",
                  "Test f1_score: 0.30075\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66959\n",
                  "Test loss: 0.67112\n",
                  "Train accuracy: 0.62466\n",
                  "Train f1_score: 0.29702\n",
                  "Test accuracy: 0.62227\n",
                  "Test f1_score: 0.30067\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.624057 ± 0.000441\n",
                  "f1_score : 0.297833 ± 0.000732\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.623454 ± 0.001725\n",
                  "f1_score : 0.297499 ± 0.003357\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67124\n",
                  "Test loss: 0.67177\n",
                  "Train accuracy: 0.61989\n",
                  "Train f1_score: 0.29676\n",
                  "Test accuracy: 0.62061\n",
                  "Test f1_score: 0.29251\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67133\n",
                  "Test loss: 0.67156\n",
                  "Train accuracy: 0.61889\n",
                  "Train f1_score: 0.29667\n",
                  "Test accuracy: 0.61811\n",
                  "Test f1_score: 0.29095\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67130\n",
                  "Test loss: 0.67174\n",
                  "Train accuracy: 0.62011\n",
                  "Train f1_score: 0.29537\n",
                  "Test accuracy: 0.61827\n",
                  "Test f1_score: 0.29724\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67165\n",
                  "Test loss: 0.67058\n",
                  "Train accuracy: 0.61884\n",
                  "Train f1_score: 0.29494\n",
                  "Test accuracy: 0.62171\n",
                  "Test f1_score: 0.29894\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67114\n",
                  "Test loss: 0.67211\n",
                  "Train accuracy: 0.61998\n",
                  "Train f1_score: 0.29511\n",
                  "Test accuracy: 0.61781\n",
                  "Test f1_score: 0.29848\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.619543 ± 0.000558\n",
                  "f1_score : 0.295768 ± 0.000784\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.619303 ± 0.001564\n",
                  "f1_score : 0.295625 ± 0.003265\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.5...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66964\n",
                  "Test loss: 0.67081\n",
                  "Train accuracy: 0.62469\n",
                  "Train f1_score: 0.29876\n",
                  "Test accuracy: 0.62515\n",
                  "Test f1_score: 0.29464\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66975\n",
                  "Test loss: 0.67033\n",
                  "Train accuracy: 0.62398\n",
                  "Train f1_score: 0.29906\n",
                  "Test accuracy: 0.62272\n",
                  "Test f1_score: 0.29302\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66974\n",
                  "Test loss: 0.67047\n",
                  "Train accuracy: 0.62480\n",
                  "Train f1_score: 0.29770\n",
                  "Test accuracy: 0.62238\n",
                  "Test f1_score: 0.29923\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67015\n",
                  "Test loss: 0.66878\n",
                  "Train accuracy: 0.62414\n",
                  "Train f1_score: 0.29751\n",
                  "Test accuracy: 0.62720\n",
                  "Test f1_score: 0.30093\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66956\n",
                  "Test loss: 0.67109\n",
                  "Train accuracy: 0.62513\n",
                  "Train f1_score: 0.29720\n",
                  "Test accuracy: 0.62234\n",
                  "Test f1_score: 0.30067\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.624548 ± 0.000426\n",
                  "f1_score : 0.298044 ± 0.000729\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.623957 ± 0.001928\n",
                  "f1_score : 0.297698 ± 0.003252\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67119\n",
                  "Test loss: 0.67176\n",
                  "Train accuracy: 0.62039\n",
                  "Train f1_score: 0.29706\n",
                  "Test accuracy: 0.62064\n",
                  "Test f1_score: 0.29228\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67129\n",
                  "Test loss: 0.67154\n",
                  "Train accuracy: 0.61929\n",
                  "Train f1_score: 0.29697\n",
                  "Test accuracy: 0.61894\n",
                  "Test f1_score: 0.29132\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67125\n",
                  "Test loss: 0.67173\n",
                  "Train accuracy: 0.62043\n",
                  "Train f1_score: 0.29547\n",
                  "Test accuracy: 0.61836\n",
                  "Test f1_score: 0.29780\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67161\n",
                  "Test loss: 0.67055\n",
                  "Train accuracy: 0.61935\n",
                  "Train f1_score: 0.29533\n",
                  "Test accuracy: 0.62229\n",
                  "Test f1_score: 0.29906\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67111\n",
                  "Test loss: 0.67206\n",
                  "Train accuracy: 0.62019\n",
                  "Train f1_score: 0.29511\n",
                  "Test accuracy: 0.61857\n",
                  "Test f1_score: 0.29882\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.619930 ± 0.000504\n",
                  "f1_score : 0.295988 ± 0.000848\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.619760 ± 0.001499\n",
                  "f1_score : 0.295858 ± 0.003353\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.6000000000000001...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66936\n",
                  "Test loss: 0.67054\n",
                  "Train accuracy: 0.62848\n",
                  "Train f1_score: 0.30047\n",
                  "Test accuracy: 0.62880\n",
                  "Test f1_score: 0.29672\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66946\n",
                  "Test loss: 0.67011\n",
                  "Train accuracy: 0.62771\n",
                  "Train f1_score: 0.30078\n",
                  "Test accuracy: 0.62630\n",
                  "Test f1_score: 0.29435\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66947\n",
                  "Test loss: 0.67017\n",
                  "Train accuracy: 0.62829\n",
                  "Train f1_score: 0.29934\n",
                  "Test accuracy: 0.62596\n",
                  "Test f1_score: 0.30072\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66984\n",
                  "Test loss: 0.66859\n",
                  "Train accuracy: 0.62807\n",
                  "Train f1_score: 0.29917\n",
                  "Test accuracy: 0.63094\n",
                  "Test f1_score: 0.30262\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66927\n",
                  "Test loss: 0.67089\n",
                  "Train accuracy: 0.62885\n",
                  "Train f1_score: 0.29903\n",
                  "Test accuracy: 0.62602\n",
                  "Test f1_score: 0.30190\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.628280 ± 0.000386\n",
                  "f1_score : 0.299757 ± 0.000722\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.627604 ± 0.001974\n",
                  "f1_score : 0.299260 ± 0.003194\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67107\n",
                  "Test loss: 0.67168\n",
                  "Train accuracy: 0.62225\n",
                  "Train f1_score: 0.29802\n",
                  "Test accuracy: 0.62202\n",
                  "Test f1_score: 0.29324\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67117\n",
                  "Test loss: 0.67144\n",
                  "Train accuracy: 0.62133\n",
                  "Train f1_score: 0.29803\n",
                  "Test accuracy: 0.62090\n",
                  "Test f1_score: 0.29235\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67115\n",
                  "Test loss: 0.67161\n",
                  "Train accuracy: 0.62256\n",
                  "Train f1_score: 0.29674\n",
                  "Test accuracy: 0.62020\n",
                  "Test f1_score: 0.29862\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67148\n",
                  "Test loss: 0.67045\n",
                  "Train accuracy: 0.62135\n",
                  "Train f1_score: 0.29636\n",
                  "Test accuracy: 0.62476\n",
                  "Test f1_score: 0.30048\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67098\n",
                  "Test loss: 0.67198\n",
                  "Train accuracy: 0.62235\n",
                  "Train f1_score: 0.29637\n",
                  "Test accuracy: 0.62031\n",
                  "Test f1_score: 0.29970\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.621969 ± 0.000522\n",
                  "f1_score : 0.297104 ± 0.000761\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.621637 ± 0.001688\n",
                  "f1_score : 0.296876 ± 0.003399\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.7000000000000001...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66928\n",
                  "Test loss: 0.67049\n",
                  "Train accuracy: 0.62999\n",
                  "Train f1_score: 0.30113\n",
                  "Test accuracy: 0.62979\n",
                  "Test f1_score: 0.29650\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66939\n",
                  "Test loss: 0.67005\n",
                  "Train accuracy: 0.62893\n",
                  "Train f1_score: 0.30106\n",
                  "Test accuracy: 0.62816\n",
                  "Test f1_score: 0.29514\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66937\n",
                  "Test loss: 0.67019\n",
                  "Train accuracy: 0.62995\n",
                  "Train f1_score: 0.29976\n",
                  "Test accuracy: 0.62723\n",
                  "Test f1_score: 0.30123\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66978\n",
                  "Test loss: 0.66851\n",
                  "Train accuracy: 0.62936\n",
                  "Train f1_score: 0.29973\n",
                  "Test accuracy: 0.63186\n",
                  "Test f1_score: 0.30282\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66919\n",
                  "Test loss: 0.67081\n",
                  "Train accuracy: 0.63027\n",
                  "Train f1_score: 0.29956\n",
                  "Test accuracy: 0.62785\n",
                  "Test f1_score: 0.30274\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629700 ± 0.000486\n",
                  "f1_score : 0.300249 ± 0.000696\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628976 ± 0.001671\n",
                  "f1_score : 0.299686 ± 0.003235\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67100\n",
                  "Test loss: 0.67162\n",
                  "Train accuracy: 0.62373\n",
                  "Train f1_score: 0.29859\n",
                  "Test accuracy: 0.62342\n",
                  "Test f1_score: 0.29405\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67110\n",
                  "Test loss: 0.67138\n",
                  "Train accuracy: 0.62313\n",
                  "Train f1_score: 0.29868\n",
                  "Test accuracy: 0.62238\n",
                  "Test f1_score: 0.29315\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67107\n",
                  "Test loss: 0.67157\n",
                  "Train accuracy: 0.62423\n",
                  "Train f1_score: 0.29742\n",
                  "Test accuracy: 0.62148\n",
                  "Test f1_score: 0.29909\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67142\n",
                  "Test loss: 0.67040\n",
                  "Train accuracy: 0.62281\n",
                  "Train f1_score: 0.29707\n",
                  "Test accuracy: 0.62628\n",
                  "Test f1_score: 0.30109\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67091\n",
                  "Test loss: 0.67192\n",
                  "Train accuracy: 0.62387\n",
                  "Train f1_score: 0.29706\n",
                  "Test accuracy: 0.62209\n",
                  "Test f1_score: 0.30018\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.623554 ± 0.000513\n",
                  "f1_score : 0.297764 ± 0.000722\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.623131 ± 0.001695\n",
                  "f1_score : 0.297512 ± 0.003269\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.8...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66926\n",
                  "Test loss: 0.67048\n",
                  "Train accuracy: 0.63008\n",
                  "Train f1_score: 0.30113\n",
                  "Test accuracy: 0.62986\n",
                  "Test f1_score: 0.29663\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66938\n",
                  "Test loss: 0.67002\n",
                  "Train accuracy: 0.62904\n",
                  "Train f1_score: 0.30109\n",
                  "Test accuracy: 0.62826\n",
                  "Test f1_score: 0.29524\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66935\n",
                  "Test loss: 0.67019\n",
                  "Train accuracy: 0.63025\n",
                  "Train f1_score: 0.29991\n",
                  "Test accuracy: 0.62723\n",
                  "Test f1_score: 0.30115\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66975\n",
                  "Test loss: 0.66853\n",
                  "Train accuracy: 0.62969\n",
                  "Train f1_score: 0.29993\n",
                  "Test accuracy: 0.63178\n",
                  "Test f1_score: 0.30270\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66917\n",
                  "Test loss: 0.67082\n",
                  "Train accuracy: 0.63034\n",
                  "Train f1_score: 0.29946\n",
                  "Test accuracy: 0.62814\n",
                  "Test f1_score: 0.30290\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629879 ± 0.000474\n",
                  "f1_score : 0.300306 ± 0.000679\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.629055 ± 0.001606\n",
                  "f1_score : 0.299723 ± 0.003184\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67098\n",
                  "Test loss: 0.67160\n",
                  "Train accuracy: 0.62387\n",
                  "Train f1_score: 0.29867\n",
                  "Test accuracy: 0.62365\n",
                  "Test f1_score: 0.29413\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67109\n",
                  "Test loss: 0.67134\n",
                  "Train accuracy: 0.62312\n",
                  "Train f1_score: 0.29866\n",
                  "Test accuracy: 0.62241\n",
                  "Test f1_score: 0.29297\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67105\n",
                  "Test loss: 0.67157\n",
                  "Train accuracy: 0.62432\n",
                  "Train f1_score: 0.29737\n",
                  "Test accuracy: 0.62174\n",
                  "Test f1_score: 0.29911\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67139\n",
                  "Test loss: 0.67040\n",
                  "Train accuracy: 0.62307\n",
                  "Train f1_score: 0.29723\n",
                  "Test accuracy: 0.62643\n",
                  "Test f1_score: 0.30106\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67089\n",
                  "Test loss: 0.67192\n",
                  "Train accuracy: 0.62399\n",
                  "Train f1_score: 0.29701\n",
                  "Test accuracy: 0.62223\n",
                  "Test f1_score: 0.30025\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.623675 ± 0.000496\n",
                  "f1_score : 0.297788 ± 0.000724\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.623292 ± 0.001692\n",
                  "f1_score : 0.297506 ± 0.003308\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.9...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66921\n",
                  "Test loss: 0.67050\n",
                  "Train accuracy: 0.63067\n",
                  "Train f1_score: 0.30164\n",
                  "Test accuracy: 0.62962\n",
                  "Test f1_score: 0.29641\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66934\n",
                  "Test loss: 0.66998\n",
                  "Train accuracy: 0.62922\n",
                  "Train f1_score: 0.30117\n",
                  "Test accuracy: 0.62912\n",
                  "Test f1_score: 0.29588\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66929\n",
                  "Test loss: 0.67021\n",
                  "Train accuracy: 0.63022\n",
                  "Train f1_score: 0.30001\n",
                  "Test accuracy: 0.62787\n",
                  "Test f1_score: 0.30175\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66969\n",
                  "Test loss: 0.66858\n",
                  "Train accuracy: 0.63001\n",
                  "Train f1_score: 0.30009\n",
                  "Test accuracy: 0.63155\n",
                  "Test f1_score: 0.30241\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66911\n",
                  "Test loss: 0.67087\n",
                  "Train accuracy: 0.63055\n",
                  "Train f1_score: 0.29950\n",
                  "Test accuracy: 0.62817\n",
                  "Test f1_score: 0.30312\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.630134 ± 0.000516\n",
                  "f1_score : 0.300483 ± 0.000795\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.629265 ± 0.001307\n",
                  "f1_score : 0.299913 ± 0.003112\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67095\n",
                  "Test loss: 0.67161\n",
                  "Train accuracy: 0.62439\n",
                  "Train f1_score: 0.29894\n",
                  "Test accuracy: 0.62442\n",
                  "Test f1_score: 0.29472\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67106\n",
                  "Test loss: 0.67131\n",
                  "Train accuracy: 0.62358\n",
                  "Train f1_score: 0.29900\n",
                  "Test accuracy: 0.62339\n",
                  "Test f1_score: 0.29371\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67101\n",
                  "Test loss: 0.67157\n",
                  "Train accuracy: 0.62465\n",
                  "Train f1_score: 0.29757\n",
                  "Test accuracy: 0.62179\n",
                  "Test f1_score: 0.29926\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67135\n",
                  "Test loss: 0.67041\n",
                  "Train accuracy: 0.62378\n",
                  "Train f1_score: 0.29765\n",
                  "Test accuracy: 0.62650\n",
                  "Test f1_score: 0.30086\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67085\n",
                  "Test loss: 0.67193\n",
                  "Train accuracy: 0.62428\n",
                  "Train f1_score: 0.29720\n",
                  "Test accuracy: 0.62287\n",
                  "Test f1_score: 0.30049\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.624134 ± 0.000398\n",
                  "f1_score : 0.298072 ± 0.000750\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.623792 ± 0.001596\n",
                  "f1_score : 0.297807 ± 0.002997\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 1.0...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66826\n",
                  "Test loss: 0.67004\n",
                  "Train accuracy: 0.63552\n",
                  "Train f1_score: 0.30401\n",
                  "Test accuracy: 0.63413\n",
                  "Test f1_score: 0.29815\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66845\n",
                  "Test loss: 0.66926\n",
                  "Train accuracy: 0.63366\n",
                  "Train f1_score: 0.30324\n",
                  "Test accuracy: 0.63367\n",
                  "Test f1_score: 0.29818\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66837\n",
                  "Test loss: 0.66965\n",
                  "Train accuracy: 0.63484\n",
                  "Train f1_score: 0.30214\n",
                  "Test accuracy: 0.63207\n",
                  "Test f1_score: 0.30347\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66866\n",
                  "Test loss: 0.66845\n",
                  "Train accuracy: 0.63530\n",
                  "Train f1_score: 0.30267\n",
                  "Test accuracy: 0.63555\n",
                  "Test f1_score: 0.30443\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66818\n",
                  "Test loss: 0.67042\n",
                  "Train accuracy: 0.63515\n",
                  "Train f1_score: 0.30178\n",
                  "Test accuracy: 0.63172\n",
                  "Test f1_score: 0.30455\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.634893 ± 0.000653\n",
                  "f1_score : 0.302769 ± 0.000793\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.633428 ± 0.001399\n",
                  "f1_score : 0.301754 ± 0.002956\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67025\n",
                  "Test loss: 0.67115\n",
                  "Train accuracy: 0.62914\n",
                  "Train f1_score: 0.30135\n",
                  "Test accuracy: 0.62901\n",
                  "Test f1_score: 0.29692\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67041\n",
                  "Test loss: 0.67072\n",
                  "Train accuracy: 0.62756\n",
                  "Train f1_score: 0.30086\n",
                  "Test accuracy: 0.62778\n",
                  "Test f1_score: 0.29586\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67032\n",
                  "Test loss: 0.67110\n",
                  "Train accuracy: 0.62904\n",
                  "Train f1_score: 0.29990\n",
                  "Test accuracy: 0.62593\n",
                  "Test f1_score: 0.30042\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67062\n",
                  "Test loss: 0.67005\n",
                  "Train accuracy: 0.62811\n",
                  "Train f1_score: 0.29965\n",
                  "Test accuracy: 0.63020\n",
                  "Test f1_score: 0.30231\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67016\n",
                  "Test loss: 0.67147\n",
                  "Train accuracy: 0.62884\n",
                  "Train f1_score: 0.29942\n",
                  "Test accuracy: 0.62639\n",
                  "Test f1_score: 0.30294\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.628539 ± 0.000608\n",
                  "f1_score : 0.300235 ± 0.000741\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.627860 ± 0.001592\n",
                  "f1_score : 0.299691 ± 0.002840\n"
               ]
            }
         ],
         "source": [
            "# Test different drop thresholds, 0 to 1 with 0.1 step\n",
            "thresholds = np.arange(0, 1.1, 0.1)\n",
            "\n",
            "for threshold in thresholds:\n",
            "    DROP_NAN_THRESHOLD = threshold\n",
            "    results = execute_pipeline(\n",
            "        x_train,\n",
            "        x_test,\n",
            "        y_train,\n",
            "        DROP_NAN_THRESHOLD,\n",
            "        DROP_CORR_THRESHOLD,\n",
            "        CAT_NUM_THRESHOLD,\n",
            "        DROP_SINGLE,\n",
            "        BUILD_RATIOS,\n",
            "        BUILD_LOG,\n",
            "        BUILD_POLY,\n",
            "        DEGREE,\n",
            "        STANDARDIZE,\n",
            "        NUM_FOLDS,\n",
            "        GAMMA,\n",
            "        MAX_ITERS,\n",
            "        LAMBDA,\n",
            "        results,\n",
            "    )"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Saving to csv...\n"
               ]
            }
         ],
         "source": [
            "print(\"Saving to csv...\")\n",
            "\n",
            "with open(\"../results/results_drop_nan.csv\", \"w\") as csvfile:\n",
            "    writer = csv.DictWriter(\n",
            "        csvfile,\n",
            "        fieldnames=[\n",
            "            \"Drop Threshold\",\n",
            "            \"Drop corr thresh.\",\n",
            "            \"Imputation\",\n",
            "            \"Standardization\",\n",
            "            \"Build Poly\",\n",
            "            \"Degree\",\n",
            "            \"Build Log\",\n",
            "            \"Build Ratios\",\n",
            "            \"Model\",\n",
            "            \"Initial W\",\n",
            "            \"Max Iters\",\n",
            "            \"Gamma\",\n",
            "            \"Lambda\",\n",
            "            \"CV F1 std\",\n",
            "            \"CV Accuracy std\",\n",
            "            \"CV F1\",\n",
            "            \"CV Accuracy\",\n",
            "        ],\n",
            "    )\n",
            "\n",
            "    writer.writeheader()\n",
            "    for result in results:\n",
            "        writer.writerow(result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [],
         "source": [
            "results_drop_nan = []\n",
            "with open(\"../results/results_drop_nan.csv\", \"r\") as csvfile:\n",
            "    reader = csv.DictReader(csvfile)\n",
            "    for row in reader:\n",
            "        results_drop_nan.append(row)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Best result for Logistic Regression: \n",
                  "0.3017536017318743+/-0.0029558990866196816\n",
                  "0.6334283145656514+/-0.001399176317764829\n",
                  "With Drop Threshold: \n",
                  "1.0\n",
                  "Best result for Reg Logistic Regression:\n",
                  "0.299691008421669+/-0.002840396345990438\n",
                  "0.6278604842519085+/-0.0015924191815075736\n",
                  "With Drop Threshold: \n",
                  "1.0\n"
               ]
            }
         ],
         "source": [
            "# determine the best results for Logistic Regression drop nan threshold and for Reg Logistic Regression drop nan threshold\n",
            "best_result_logistic = max(\n",
            "    results_drop_nan,\n",
            "    key=lambda x: float(x[\"CV F1\"]) if x[\"Model\"] == \"Logistic_Regression\" else 0.0,\n",
            ")\n",
            "best_result_reg_logistic = max(\n",
            "    results_drop_nan,\n",
            "    key=lambda x: float(x[\"CV F1\"]) if x[\"Model\"] == \"Reg_Logistic_Regression\" else 0.0,\n",
            ")\n",
            "\n",
            "print(\"Best result for Logistic Regression: \")\n",
            "print(best_result_logistic[\"CV F1\"] + \"+/-\" + best_result_logistic[\"CV F1 std\"])\n",
            "print(\n",
            "    best_result_logistic[\"CV Accuracy\"]\n",
            "    + \"+/-\"\n",
            "    + best_result_logistic[\"CV Accuracy std\"]\n",
            ")\n",
            "print(\"With Drop Threshold: \")\n",
            "print(best_result_logistic[\"Drop Threshold\"])\n",
            "\n",
            "\n",
            "print(\"Best result for Reg Logistic Regression:\")\n",
            "print(best_result_reg_logistic[\"CV F1\"] + \"+/-\" + best_result_reg_logistic[\"CV F1 std\"])\n",
            "print(\n",
            "    best_result_reg_logistic[\"CV Accuracy\"]\n",
            "    + \"+/-\"\n",
            "    + best_result_reg_logistic[\"CV Accuracy std\"]\n",
            ")\n",
            "print(\"With Drop Threshold: \")\n",
            "print(best_result_reg_logistic[\"Drop Threshold\"])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Experiments using different CAT_NUM_THRESHOLD = 200, choice made from graph from EDA"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [],
         "source": [
            "#### BASELINE ####\n",
            "\n",
            "### Column dropping and imputation ###\n",
            "# threshold for drop_columns function\n",
            "DROP_NAN_THRESHOLD = 1  # 1 = keep everything, 0 = drop everything that contains nan\n",
            "# threshold for categorical/numerical (categorical are imputated with median, numerical with mean)\n",
            "CAT_NUM_THRESHOLD = 30\n",
            "# flag for drop_single_value_columns function\n",
            "# Should always be True, otherwise it is messing up with the correlation coefficient.\n",
            "DROP_SINGLE = True\n",
            "# threshold for drop_correlated_columns function\n",
            "DROP_CORR_THRESHOLD = 0.9\n",
            "\n",
            "### Feature processing ###\n",
            "# flag for build_poly function\n",
            "BUILD_POLY = False\n",
            "# degree for build_poly function\n",
            "DEGREE = 2\n",
            "# flag for build_log function\n",
            "BUILD_LOG = False\n",
            "# flag for build_x\n",
            "BUILD_RATIOS = False\n",
            "# flag for standardize function\n",
            "STANDARDIZE = True\n",
            "\n",
            "NUM_FOLDS = 5\n",
            "\n",
            "GAMMA = 0.5\n",
            "MAX_ITERS = 100\n",
            "LAMBDA = 0.1"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66826\n",
                  "Test loss: 0.67004\n",
                  "Train accuracy: 0.63552\n",
                  "Train f1_score: 0.30401\n",
                  "Test accuracy: 0.63413\n",
                  "Test f1_score: 0.29815\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66845\n",
                  "Test loss: 0.66926\n",
                  "Train accuracy: 0.63366\n",
                  "Train f1_score: 0.30324\n",
                  "Test accuracy: 0.63367\n",
                  "Test f1_score: 0.29818\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66837\n",
                  "Test loss: 0.66965\n",
                  "Train accuracy: 0.63484\n",
                  "Train f1_score: 0.30214\n",
                  "Test accuracy: 0.63207\n",
                  "Test f1_score: 0.30347\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66866\n",
                  "Test loss: 0.66845\n",
                  "Train accuracy: 0.63530\n",
                  "Train f1_score: 0.30267\n",
                  "Test accuracy: 0.63555\n",
                  "Test f1_score: 0.30443\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66818\n",
                  "Test loss: 0.67042\n",
                  "Train accuracy: 0.63515\n",
                  "Train f1_score: 0.30178\n",
                  "Test accuracy: 0.63172\n",
                  "Test f1_score: 0.30455\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.634893 ± 0.000653\n",
                  "f1_score : 0.302769 ± 0.000793\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.633428 ± 0.001399\n",
                  "f1_score : 0.301754 ± 0.002956\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67025\n",
                  "Test loss: 0.67115\n",
                  "Train accuracy: 0.62914\n",
                  "Train f1_score: 0.30135\n",
                  "Test accuracy: 0.62901\n",
                  "Test f1_score: 0.29692\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67041\n",
                  "Test loss: 0.67072\n",
                  "Train accuracy: 0.62756\n",
                  "Train f1_score: 0.30086\n",
                  "Test accuracy: 0.62778\n",
                  "Test f1_score: 0.29586\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67032\n",
                  "Test loss: 0.67110\n",
                  "Train accuracy: 0.62904\n",
                  "Train f1_score: 0.29990\n",
                  "Test accuracy: 0.62593\n",
                  "Test f1_score: 0.30042\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67062\n",
                  "Test loss: 0.67005\n",
                  "Train accuracy: 0.62811\n",
                  "Train f1_score: 0.29965\n",
                  "Test accuracy: 0.63020\n",
                  "Test f1_score: 0.30231\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67016\n",
                  "Test loss: 0.67147\n",
                  "Train accuracy: 0.62884\n",
                  "Train f1_score: 0.29942\n",
                  "Test accuracy: 0.62639\n",
                  "Test f1_score: 0.30294\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.628539 ± 0.000608\n",
                  "f1_score : 0.300235 ± 0.000741\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.627860 ± 0.001592\n",
                  "f1_score : 0.299691 ± 0.002840\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66826\n",
                  "Test loss: 0.67004\n",
                  "Train accuracy: 0.63569\n",
                  "Train f1_score: 0.30412\n",
                  "Test accuracy: 0.63427\n",
                  "Test f1_score: 0.29815\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66845\n",
                  "Test loss: 0.66928\n",
                  "Train accuracy: 0.63364\n",
                  "Train f1_score: 0.30336\n",
                  "Test accuracy: 0.63300\n",
                  "Test f1_score: 0.29763\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66838\n",
                  "Test loss: 0.66965\n",
                  "Train accuracy: 0.63475\n",
                  "Train f1_score: 0.30207\n",
                  "Test accuracy: 0.63215\n",
                  "Test f1_score: 0.30371\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66867\n",
                  "Test loss: 0.66845\n",
                  "Train accuracy: 0.63515\n",
                  "Train f1_score: 0.30262\n",
                  "Test accuracy: 0.63594\n",
                  "Test f1_score: 0.30490\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66819\n",
                  "Test loss: 0.67042\n",
                  "Train accuracy: 0.63498\n",
                  "Train f1_score: 0.30169\n",
                  "Test accuracy: 0.63174\n",
                  "Test f1_score: 0.30460\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.634842 ± 0.000679\n",
                  "f1_score : 0.302771 ± 0.000877\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.633419 ± 0.001530\n",
                  "f1_score : 0.301797 ± 0.003220\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67024\n",
                  "Test loss: 0.67114\n",
                  "Train accuracy: 0.62919\n",
                  "Train f1_score: 0.30131\n",
                  "Test accuracy: 0.62875\n",
                  "Test f1_score: 0.29669\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67039\n",
                  "Test loss: 0.67072\n",
                  "Train accuracy: 0.62819\n",
                  "Train f1_score: 0.30120\n",
                  "Test accuracy: 0.62831\n",
                  "Test f1_score: 0.29596\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67032\n",
                  "Test loss: 0.67107\n",
                  "Train accuracy: 0.62915\n",
                  "Train f1_score: 0.29984\n",
                  "Test accuracy: 0.62586\n",
                  "Test f1_score: 0.30050\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67061\n",
                  "Test loss: 0.67003\n",
                  "Train accuracy: 0.62842\n",
                  "Train f1_score: 0.29966\n",
                  "Test accuracy: 0.63053\n",
                  "Test f1_score: 0.30263\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67014\n",
                  "Test loss: 0.67147\n",
                  "Train accuracy: 0.62917\n",
                  "Train f1_score: 0.29956\n",
                  "Test accuracy: 0.62678\n",
                  "Test f1_score: 0.30301\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.628824 ± 0.000432\n",
                  "f1_score : 0.300313 ± 0.000775\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628046 ± 0.001621\n",
                  "f1_score : 0.299756 ± 0.002939\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66825\n",
                  "Test loss: 0.67003\n",
                  "Train accuracy: 0.63565\n",
                  "Train f1_score: 0.30406\n",
                  "Test accuracy: 0.63416\n",
                  "Test f1_score: 0.29813\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66845\n",
                  "Test loss: 0.66926\n",
                  "Train accuracy: 0.63368\n",
                  "Train f1_score: 0.30330\n",
                  "Test accuracy: 0.63334\n",
                  "Test f1_score: 0.29790\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66837\n",
                  "Test loss: 0.66965\n",
                  "Train accuracy: 0.63483\n",
                  "Train f1_score: 0.30212\n",
                  "Test accuracy: 0.63198\n",
                  "Test f1_score: 0.30350\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66866\n",
                  "Test loss: 0.66845\n",
                  "Train accuracy: 0.63539\n",
                  "Train f1_score: 0.30270\n",
                  "Test accuracy: 0.63600\n",
                  "Test f1_score: 0.30481\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66818\n",
                  "Test loss: 0.67042\n",
                  "Train accuracy: 0.63499\n",
                  "Train f1_score: 0.30170\n",
                  "Test accuracy: 0.63183\n",
                  "Test f1_score: 0.30481\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.634907 ± 0.000680\n",
                  "f1_score : 0.302777 ± 0.000841\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.633462 ± 0.001538\n",
                  "f1_score : 0.301830 ± 0.003153\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67025\n",
                  "Test loss: 0.67115\n",
                  "Train accuracy: 0.62918\n",
                  "Train f1_score: 0.30130\n",
                  "Test accuracy: 0.62864\n",
                  "Test f1_score: 0.29631\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67041\n",
                  "Test loss: 0.67073\n",
                  "Train accuracy: 0.62801\n",
                  "Train f1_score: 0.30109\n",
                  "Test accuracy: 0.62858\n",
                  "Test f1_score: 0.29635\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67033\n",
                  "Test loss: 0.67107\n",
                  "Train accuracy: 0.62906\n",
                  "Train f1_score: 0.29979\n",
                  "Test accuracy: 0.62561\n",
                  "Test f1_score: 0.30040\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67062\n",
                  "Test loss: 0.67006\n",
                  "Train accuracy: 0.62825\n",
                  "Train f1_score: 0.29961\n",
                  "Test accuracy: 0.63073\n",
                  "Test f1_score: 0.30282\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67016\n",
                  "Test loss: 0.67149\n",
                  "Train accuracy: 0.62902\n",
                  "Train f1_score: 0.29948\n",
                  "Test accuracy: 0.62653\n",
                  "Test f1_score: 0.30274\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.628704 ± 0.000479\n",
                  "f1_score : 0.300254 ± 0.000779\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628019 ± 0.001794\n",
                  "f1_score : 0.299724 ± 0.002904\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66826\n",
                  "Test loss: 0.67004\n",
                  "Train accuracy: 0.63576\n",
                  "Train f1_score: 0.30414\n",
                  "Test accuracy: 0.63407\n",
                  "Test f1_score: 0.29811\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66845\n",
                  "Test loss: 0.66926\n",
                  "Train accuracy: 0.63370\n",
                  "Train f1_score: 0.30341\n",
                  "Test accuracy: 0.63329\n",
                  "Test f1_score: 0.29792\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66837\n",
                  "Test loss: 0.66966\n",
                  "Train accuracy: 0.63480\n",
                  "Train f1_score: 0.30210\n",
                  "Test accuracy: 0.63213\n",
                  "Test f1_score: 0.30362\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66866\n",
                  "Test loss: 0.66845\n",
                  "Train accuracy: 0.63538\n",
                  "Train f1_score: 0.30273\n",
                  "Test accuracy: 0.63599\n",
                  "Test f1_score: 0.30480\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66818\n",
                  "Test loss: 0.67043\n",
                  "Train accuracy: 0.63509\n",
                  "Train f1_score: 0.30179\n",
                  "Test accuracy: 0.63190\n",
                  "Test f1_score: 0.30485\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.634946 ± 0.000699\n",
                  "f1_score : 0.302831 ± 0.000857\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.633477 ± 0.001481\n",
                  "f1_score : 0.301863 ± 0.003172\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67025\n",
                  "Test loss: 0.67115\n",
                  "Train accuracy: 0.62906\n",
                  "Train f1_score: 0.30116\n",
                  "Test accuracy: 0.62889\n",
                  "Test f1_score: 0.29665\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67041\n",
                  "Test loss: 0.67074\n",
                  "Train accuracy: 0.62786\n",
                  "Train f1_score: 0.30089\n",
                  "Test accuracy: 0.62860\n",
                  "Test f1_score: 0.29620\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67033\n",
                  "Test loss: 0.67106\n",
                  "Train accuracy: 0.62903\n",
                  "Train f1_score: 0.29978\n",
                  "Test accuracy: 0.62570\n",
                  "Test f1_score: 0.30037\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67062\n",
                  "Test loss: 0.67006\n",
                  "Train accuracy: 0.62816\n",
                  "Train f1_score: 0.29940\n",
                  "Test accuracy: 0.63113\n",
                  "Test f1_score: 0.30305\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67016\n",
                  "Test loss: 0.67149\n",
                  "Train accuracy: 0.62914\n",
                  "Train f1_score: 0.29950\n",
                  "Test accuracy: 0.62671\n",
                  "Test f1_score: 0.30285\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.628652 ± 0.000531\n",
                  "f1_score : 0.300146 ± 0.000731\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628205 ± 0.001879\n",
                  "f1_score : 0.299822 ± 0.002934\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66826\n",
                  "Test loss: 0.67004\n",
                  "Train accuracy: 0.63576\n",
                  "Train f1_score: 0.30414\n",
                  "Test accuracy: 0.63407\n",
                  "Test f1_score: 0.29811\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66845\n",
                  "Test loss: 0.66926\n",
                  "Train accuracy: 0.63370\n",
                  "Train f1_score: 0.30341\n",
                  "Test accuracy: 0.63329\n",
                  "Test f1_score: 0.29792\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66837\n",
                  "Test loss: 0.66966\n",
                  "Train accuracy: 0.63480\n",
                  "Train f1_score: 0.30210\n",
                  "Test accuracy: 0.63213\n",
                  "Test f1_score: 0.30362\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66866\n",
                  "Test loss: 0.66845\n",
                  "Train accuracy: 0.63538\n",
                  "Train f1_score: 0.30273\n",
                  "Test accuracy: 0.63599\n",
                  "Test f1_score: 0.30480\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66818\n",
                  "Test loss: 0.67043\n",
                  "Train accuracy: 0.63509\n",
                  "Train f1_score: 0.30179\n",
                  "Test accuracy: 0.63190\n",
                  "Test f1_score: 0.30485\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.634946 ± 0.000699\n",
                  "f1_score : 0.302831 ± 0.000857\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.633477 ± 0.001481\n",
                  "f1_score : 0.301863 ± 0.003172\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67025\n",
                  "Test loss: 0.67115\n",
                  "Train accuracy: 0.62906\n",
                  "Train f1_score: 0.30116\n",
                  "Test accuracy: 0.62889\n",
                  "Test f1_score: 0.29665\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67041\n",
                  "Test loss: 0.67074\n",
                  "Train accuracy: 0.62786\n",
                  "Train f1_score: 0.30089\n",
                  "Test accuracy: 0.62860\n",
                  "Test f1_score: 0.29620\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67033\n",
                  "Test loss: 0.67106\n",
                  "Train accuracy: 0.62903\n",
                  "Train f1_score: 0.29978\n",
                  "Test accuracy: 0.62570\n",
                  "Test f1_score: 0.30037\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67062\n",
                  "Test loss: 0.67006\n",
                  "Train accuracy: 0.62816\n",
                  "Train f1_score: 0.29940\n",
                  "Test accuracy: 0.63113\n",
                  "Test f1_score: 0.30305\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67016\n",
                  "Test loss: 0.67149\n",
                  "Train accuracy: 0.62914\n",
                  "Train f1_score: 0.29950\n",
                  "Test accuracy: 0.62671\n",
                  "Test f1_score: 0.30285\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.628652 ± 0.000531\n",
                  "f1_score : 0.300146 ± 0.000731\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628205 ± 0.001879\n",
                  "f1_score : 0.299822 ± 0.002934\n"
               ]
            }
         ],
         "source": [
            "results = []\n",
            "\n",
            "cat_thresholds = [30, 50, 100, 200, 300]\n",
            "\n",
            "for cat_threshold in cat_thresholds:\n",
            "    CAT_NUM_THRESHOLD = cat_threshold\n",
            "    results = execute_pipeline(\n",
            "        x_train,\n",
            "        x_test,\n",
            "        y_train,\n",
            "        DROP_NAN_THRESHOLD,\n",
            "        DROP_CORR_THRESHOLD,\n",
            "        CAT_NUM_THRESHOLD,\n",
            "        DROP_SINGLE,\n",
            "        BUILD_RATIOS,\n",
            "        BUILD_LOG,\n",
            "        BUILD_POLY,\n",
            "        DEGREE,\n",
            "        STANDARDIZE,\n",
            "        NUM_FOLDS,\n",
            "        GAMMA,\n",
            "        MAX_ITERS,\n",
            "        LAMBDA,\n",
            "        results,\n",
            "    )\n",
            "\n",
            "with open(\"../results/results_cat_threshold.csv\", \"w\") as csvfile:\n",
            "    writer = csv.DictWriter(\n",
            "        csvfile,\n",
            "        fieldnames=[\n",
            "            \"Drop Threshold\",\n",
            "            \"Drop corr thresh.\",\n",
            "            \"Imputation\",\n",
            "            \"Standardization\",\n",
            "            \"Build Poly\",\n",
            "            \"Degree\",\n",
            "            \"Build Log\",\n",
            "            \"Build Ratios\",\n",
            "            \"Model\",\n",
            "            \"Initial W\",\n",
            "            \"Max Iters\",\n",
            "            \"Gamma\",\n",
            "            \"Lambda\",\n",
            "            \"CV F1 std\",\n",
            "            \"CV Accuracy std\",\n",
            "            \"CV F1\",\n",
            "            \"CV Accuracy\",\n",
            "        ],\n",
            "    )\n",
            "\n",
            "    writer.writeheader()\n",
            "    for result in results:\n",
            "        writer.writerow(result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {},
         "outputs": [],
         "source": [
            "results_cat_threshold = []\n",
            "with open(\"../results/results_cat_threshold.csv\", \"r\") as csvfile:\n",
            "    reader = csv.DictReader(csvfile)\n",
            "    for row in reader:\n",
            "        results_cat_threshold.append(row)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Best result for Logistic Regression: \n",
                  "0.30186279074049305+/-0.0031723432697801472\n",
                  "0.6334770749843814+/-0.0014811541535213306\n",
                  "With CAT Threshold: \n",
                  "200\n",
                  "Best result for Reg Logistic Regression:\n",
                  "0.2998218405540042+/-0.0029338138186970606\n",
                  "0.6282048547091897+/-0.0018794220153454323\n",
                  "With CAT Threshold: \n",
                  "200\n"
               ]
            }
         ],
         "source": [
            "# determine the best results for Logistic Regression drop nan threshold and for Reg Logistic Regression drop nan threshold\n",
            "best_result_logistic = max(\n",
            "    results_cat_threshold,\n",
            "    key=lambda x: float(x[\"CV F1\"]) if x[\"Model\"] == \"Logistic_Regression\" else 0.0,\n",
            ")\n",
            "best_result_reg_logistic = max(\n",
            "    results_cat_threshold,\n",
            "    key=lambda x: float(x[\"CV F1\"]) if x[\"Model\"] == \"Reg_Logistic_Regression\" else 0.0,\n",
            ")\n",
            "\n",
            "print(\"Best result for Logistic Regression: \")\n",
            "print(best_result_logistic[\"CV F1\"] + \"+/-\" + best_result_logistic[\"CV F1 std\"])\n",
            "print(\n",
            "    best_result_logistic[\"CV Accuracy\"]\n",
            "    + \"+/-\"\n",
            "    + best_result_logistic[\"CV Accuracy std\"]\n",
            ")\n",
            "print(\"With CAT Threshold: \")\n",
            "print(best_result_logistic[\"Imputation\"])\n",
            "\n",
            "\n",
            "print(\"Best result for Reg Logistic Regression:\")\n",
            "print(best_result_reg_logistic[\"CV F1\"] + \"+/-\" + best_result_reg_logistic[\"CV F1 std\"])\n",
            "print(\n",
            "    best_result_reg_logistic[\"CV Accuracy\"]\n",
            "    + \"+/-\"\n",
            "    + best_result_reg_logistic[\"CV Accuracy std\"]\n",
            ")\n",
            "print(\"With CAT Threshold: \")\n",
            "print(best_result_reg_logistic[\"Imputation\"])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Experiment using different drop correlation values"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 22,
         "metadata": {},
         "outputs": [],
         "source": [
            "#### BASELINE ####\n",
            "\n",
            "### Column dropping and imputation ###\n",
            "# threshold for drop_columns function\n",
            "DROP_NAN_THRESHOLD = 1  # 1 = keep everything, 0 = drop everything that contains nan\n",
            "# threshold for categorical/numerical (categorical are imputated with median, numerical with mean)\n",
            "CAT_NUM_THRESHOLD = 30\n",
            "# flag for drop_single_value_columns function\n",
            "# Should always be True, otherwise it is messing up with the correlation coefficient.\n",
            "DROP_SINGLE = True\n",
            "# threshold for drop_correlated_columns function\n",
            "DROP_CORR_THRESHOLD = 0.9\n",
            "\n",
            "### Feature processing ###\n",
            "# flag for build_poly function\n",
            "BUILD_POLY = False\n",
            "# degree for build_poly function\n",
            "DEGREE = 2\n",
            "# flag for build_log function\n",
            "BUILD_LOG = False\n",
            "# flag for build_x\n",
            "BUILD_RATIOS = False\n",
            "# flag for standardize function\n",
            "STANDARDIZE = True\n",
            "\n",
            "NUM_FOLDS = 5\n",
            "\n",
            "GAMMA = 0.5\n",
            "MAX_ITERS = 100\n",
            "LAMBDA = 0.1"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 23,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66828\n",
                  "Test loss: 0.67003\n",
                  "Train accuracy: 0.63549\n",
                  "Train f1_score: 0.30404\n",
                  "Test accuracy: 0.63385\n",
                  "Test f1_score: 0.29812\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66848\n",
                  "Test loss: 0.66923\n",
                  "Train accuracy: 0.63343\n",
                  "Train f1_score: 0.30323\n",
                  "Test accuracy: 0.63321\n",
                  "Test f1_score: 0.29808\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66840\n",
                  "Test loss: 0.66962\n",
                  "Train accuracy: 0.63441\n",
                  "Train f1_score: 0.30191\n",
                  "Test accuracy: 0.63209\n",
                  "Test f1_score: 0.30368\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66868\n",
                  "Test loss: 0.66847\n",
                  "Train accuracy: 0.63519\n",
                  "Train f1_score: 0.30269\n",
                  "Test accuracy: 0.63532\n",
                  "Test f1_score: 0.30425\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66819\n",
                  "Test loss: 0.67045\n",
                  "Train accuracy: 0.63496\n",
                  "Train f1_score: 0.30181\n",
                  "Test accuracy: 0.63137\n",
                  "Test f1_score: 0.30423\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.634695 ± 0.000725\n",
                  "f1_score : 0.302737 ± 0.000833\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.633169 ± 0.001378\n",
                  "f1_score : 0.301670 ± 0.002925\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67026\n",
                  "Test loss: 0.67115\n",
                  "Train accuracy: 0.62909\n",
                  "Train f1_score: 0.30133\n",
                  "Test accuracy: 0.62886\n",
                  "Test f1_score: 0.29683\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67042\n",
                  "Test loss: 0.67072\n",
                  "Train accuracy: 0.62745\n",
                  "Train f1_score: 0.30081\n",
                  "Test accuracy: 0.62765\n",
                  "Test f1_score: 0.29595\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67033\n",
                  "Test loss: 0.67110\n",
                  "Train accuracy: 0.62916\n",
                  "Train f1_score: 0.29988\n",
                  "Test accuracy: 0.62598\n",
                  "Test f1_score: 0.30060\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67062\n",
                  "Test loss: 0.67004\n",
                  "Train accuracy: 0.62823\n",
                  "Train f1_score: 0.29969\n",
                  "Test accuracy: 0.63012\n",
                  "Test f1_score: 0.30247\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67016\n",
                  "Test loss: 0.67147\n",
                  "Train accuracy: 0.62899\n",
                  "Train f1_score: 0.29958\n",
                  "Test accuracy: 0.62671\n",
                  "Test f1_score: 0.30296\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.628583 ± 0.000656\n",
                  "f1_score : 0.300258 ± 0.000689\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.627864 ± 0.001485\n",
                  "f1_score : 0.299766 ± 0.002877\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66826\n",
                  "Test loss: 0.67004\n",
                  "Train accuracy: 0.63552\n",
                  "Train f1_score: 0.30401\n",
                  "Test accuracy: 0.63413\n",
                  "Test f1_score: 0.29815\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66845\n",
                  "Test loss: 0.66926\n",
                  "Train accuracy: 0.63366\n",
                  "Train f1_score: 0.30324\n",
                  "Test accuracy: 0.63367\n",
                  "Test f1_score: 0.29818\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66837\n",
                  "Test loss: 0.66965\n",
                  "Train accuracy: 0.63484\n",
                  "Train f1_score: 0.30214\n",
                  "Test accuracy: 0.63207\n",
                  "Test f1_score: 0.30347\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66866\n",
                  "Test loss: 0.66845\n",
                  "Train accuracy: 0.63530\n",
                  "Train f1_score: 0.30267\n",
                  "Test accuracy: 0.63555\n",
                  "Test f1_score: 0.30443\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66818\n",
                  "Test loss: 0.67042\n",
                  "Train accuracy: 0.63515\n",
                  "Train f1_score: 0.30178\n",
                  "Test accuracy: 0.63172\n",
                  "Test f1_score: 0.30455\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.634893 ± 0.000653\n",
                  "f1_score : 0.302769 ± 0.000793\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.633428 ± 0.001399\n",
                  "f1_score : 0.301754 ± 0.002956\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67025\n",
                  "Test loss: 0.67115\n",
                  "Train accuracy: 0.62914\n",
                  "Train f1_score: 0.30135\n",
                  "Test accuracy: 0.62901\n",
                  "Test f1_score: 0.29692\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67041\n",
                  "Test loss: 0.67072\n",
                  "Train accuracy: 0.62756\n",
                  "Train f1_score: 0.30086\n",
                  "Test accuracy: 0.62778\n",
                  "Test f1_score: 0.29586\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67032\n",
                  "Test loss: 0.67110\n",
                  "Train accuracy: 0.62904\n",
                  "Train f1_score: 0.29990\n",
                  "Test accuracy: 0.62593\n",
                  "Test f1_score: 0.30042\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67062\n",
                  "Test loss: 0.67005\n",
                  "Train accuracy: 0.62811\n",
                  "Train f1_score: 0.29965\n",
                  "Test accuracy: 0.63020\n",
                  "Test f1_score: 0.30231\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67016\n",
                  "Test loss: 0.67147\n",
                  "Train accuracy: 0.62884\n",
                  "Train f1_score: 0.29942\n",
                  "Test accuracy: 0.62639\n",
                  "Test f1_score: 0.30294\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.628539 ± 0.000608\n",
                  "f1_score : 0.300235 ± 0.000741\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.627860 ± 0.001592\n",
                  "f1_score : 0.299691 ± 0.002840\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66825\n",
                  "Test loss: 0.67004\n",
                  "Train accuracy: 0.63561\n",
                  "Train f1_score: 0.30405\n",
                  "Test accuracy: 0.63421\n",
                  "Test f1_score: 0.29819\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66844\n",
                  "Test loss: 0.66927\n",
                  "Train accuracy: 0.63376\n",
                  "Train f1_score: 0.30340\n",
                  "Test accuracy: 0.63355\n",
                  "Test f1_score: 0.29806\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66836\n",
                  "Test loss: 0.66966\n",
                  "Train accuracy: 0.63491\n",
                  "Train f1_score: 0.30225\n",
                  "Test accuracy: 0.63216\n",
                  "Test f1_score: 0.30360\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66866\n",
                  "Test loss: 0.66845\n",
                  "Train accuracy: 0.63540\n",
                  "Train f1_score: 0.30277\n",
                  "Test accuracy: 0.63556\n",
                  "Test f1_score: 0.30431\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66817\n",
                  "Test loss: 0.67044\n",
                  "Train accuracy: 0.63515\n",
                  "Train f1_score: 0.30183\n",
                  "Test accuracy: 0.63168\n",
                  "Test f1_score: 0.30456\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.634967 ± 0.000647\n",
                  "f1_score : 0.302862 ± 0.000794\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.633431 ± 0.001403\n",
                  "f1_score : 0.301747 ± 0.002971\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67025\n",
                  "Test loss: 0.67115\n",
                  "Train accuracy: 0.62916\n",
                  "Train f1_score: 0.30135\n",
                  "Test accuracy: 0.62878\n",
                  "Test f1_score: 0.29683\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67041\n",
                  "Test loss: 0.67072\n",
                  "Train accuracy: 0.62759\n",
                  "Train f1_score: 0.30094\n",
                  "Test accuracy: 0.62788\n",
                  "Test f1_score: 0.29592\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67032\n",
                  "Test loss: 0.67111\n",
                  "Train accuracy: 0.62910\n",
                  "Train f1_score: 0.29995\n",
                  "Test accuracy: 0.62598\n",
                  "Test f1_score: 0.30044\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67062\n",
                  "Test loss: 0.67005\n",
                  "Train accuracy: 0.62813\n",
                  "Train f1_score: 0.29964\n",
                  "Test accuracy: 0.63011\n",
                  "Test f1_score: 0.30230\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67016\n",
                  "Test loss: 0.67147\n",
                  "Train accuracy: 0.62881\n",
                  "Train f1_score: 0.29945\n",
                  "Test accuracy: 0.62642\n",
                  "Test f1_score: 0.30296\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.628558 ± 0.000607\n",
                  "f1_score : 0.300268 ± 0.000744\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.627833 ± 0.001517\n",
                  "f1_score : 0.299692 ± 0.002845\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.68149\n",
                  "Test loss: 0.68248\n",
                  "Train accuracy: 0.63971\n",
                  "Train f1_score: 0.29663\n",
                  "Test accuracy: 0.63937\n",
                  "Test f1_score: 0.29333\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.68153\n",
                  "Test loss: 0.68096\n",
                  "Train accuracy: 0.63818\n",
                  "Train f1_score: 0.29699\n",
                  "Test accuracy: 0.63710\n",
                  "Test f1_score: 0.29043\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.68018\n",
                  "Test loss: 0.68224\n",
                  "Train accuracy: 0.63830\n",
                  "Train f1_score: 0.29538\n",
                  "Test accuracy: 0.63421\n",
                  "Test f1_score: 0.29547\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.68103\n",
                  "Test loss: 0.68154\n",
                  "Train accuracy: 0.63937\n",
                  "Train f1_score: 0.29549\n",
                  "Test accuracy: 0.64051\n",
                  "Test f1_score: 0.29819\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.68059\n",
                  "Test loss: 0.68370\n",
                  "Train accuracy: 0.63912\n",
                  "Train f1_score: 0.29507\n",
                  "Test accuracy: 0.63666\n",
                  "Test f1_score: 0.29750\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.638934 ± 0.000598\n",
                  "f1_score : 0.295910 ± 0.000753\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.637570 ± 0.002204\n",
                  "f1_score : 0.294985 ± 0.002840\n",
                  "Fold 1/5\n",
                  "Train loss: 0.69630\n",
                  "Test loss: 0.69599\n",
                  "Train accuracy: 0.66016\n",
                  "Train f1_score: 0.29550\n",
                  "Test accuracy: 0.66040\n",
                  "Test f1_score: 0.29232\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.69619\n",
                  "Test loss: 0.69467\n",
                  "Train accuracy: 0.65853\n",
                  "Train f1_score: 0.29568\n",
                  "Test accuracy: 0.65866\n",
                  "Test f1_score: 0.29037\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.69495\n",
                  "Test loss: 0.69696\n",
                  "Train accuracy: 0.65910\n",
                  "Train f1_score: 0.29463\n",
                  "Test accuracy: 0.65449\n",
                  "Test f1_score: 0.29245\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.69587\n",
                  "Test loss: 0.69613\n",
                  "Train accuracy: 0.66001\n",
                  "Train f1_score: 0.29427\n",
                  "Test accuracy: 0.66131\n",
                  "Test f1_score: 0.29699\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.69555\n",
                  "Test loss: 0.69791\n",
                  "Train accuracy: 0.65980\n",
                  "Train f1_score: 0.29391\n",
                  "Test accuracy: 0.65849\n",
                  "Test f1_score: 0.29712\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.659519 ± 0.000614\n",
                  "f1_score : 0.294800 ± 0.000690\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.658671 ± 0.002345\n",
                  "f1_score : 0.293849 ± 0.002721\n"
               ]
            }
         ],
         "source": [
            "results = []\n",
            "\n",
            "DROP_NAN_THRESHOLD = 1\n",
            "CAT_NUM_THRESHOLD = 30\n",
            "\n",
            "corr_thresholds = [0.85, 0.9, 0.95, 0.99]\n",
            "\n",
            "for corr_threshold in corr_thresholds:\n",
            "    DROP_CORR_THRESHOLD = corr_threshold\n",
            "    results = execute_pipeline(\n",
            "        x_train,\n",
            "        x_test,\n",
            "        y_train,\n",
            "        DROP_NAN_THRESHOLD,\n",
            "        DROP_CORR_THRESHOLD,\n",
            "        CAT_NUM_THRESHOLD,\n",
            "        DROP_SINGLE,\n",
            "        BUILD_RATIOS,\n",
            "        BUILD_LOG,\n",
            "        BUILD_POLY,\n",
            "        DEGREE,\n",
            "        STANDARDIZE,\n",
            "        NUM_FOLDS,\n",
            "        GAMMA,\n",
            "        MAX_ITERS,\n",
            "        LAMBDA,\n",
            "        results,\n",
            "    )\n",
            "\n",
            "with open(\"../results/results_corr_threshold.csv\", \"w\") as csvfile:\n",
            "    writer = csv.DictWriter(\n",
            "        csvfile,\n",
            "        fieldnames=[\n",
            "            \"Drop Threshold\",\n",
            "            \"Drop corr thresh.\",\n",
            "            \"Imputation\",\n",
            "            \"Standardization\",\n",
            "            \"Build Poly\",\n",
            "            \"Degree\",\n",
            "            \"Build Log\",\n",
            "            \"Build Ratios\",\n",
            "            \"Model\",\n",
            "            \"Initial W\",\n",
            "            \"Max Iters\",\n",
            "            \"Gamma\",\n",
            "            \"Lambda\",\n",
            "            \"CV F1 std\",\n",
            "            \"CV Accuracy std\",\n",
            "            \"CV F1\",\n",
            "            \"CV Accuracy\",\n",
            "        ],\n",
            "    )\n",
            "\n",
            "    writer.writeheader()\n",
            "    for result in results:\n",
            "        writer.writerow(result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "metadata": {},
         "outputs": [],
         "source": [
            "results_corr_threshold = []\n",
            "with open(\"../results/results_corr_threshold.csv\", \"r\") as csvfile:\n",
            "    reader = csv.DictReader(csvfile)\n",
            "    for row in reader:\n",
            "        results_corr_threshold.append(row)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Best result for Logistic Regression: \n",
                  "0.3017536017318743+/-0.0029558990866196816\n",
                  "0.6334283145656514+/-0.001399176317764829\n",
                  "With corr Threshold: \n",
                  "0.9\n",
                  "Best result for Reg Logistic Regression:\n",
                  "0.2997655939733219+/-0.002876811700852166\n",
                  "0.6278635317780792+/-0.001484817801258279\n",
                  "With corr Threshold: \n",
                  "0.85\n"
               ]
            }
         ],
         "source": [
            "# determine the best results for Logistic Regression drop nan threshold and for Reg Logistic Regression drop nan threshold\n",
            "best_result_logistic = max(\n",
            "    results_corr_threshold,\n",
            "    key=lambda x: float(x[\"CV F1\"]) if x[\"Model\"] == \"Logistic_Regression\" else 0.0,\n",
            ")\n",
            "best_result_reg_logistic = max(\n",
            "    results_corr_threshold,\n",
            "    key=lambda x: float(x[\"CV F1\"]) if x[\"Model\"] == \"Reg_Logistic_Regression\" else 0.0,\n",
            ")\n",
            "\n",
            "print(\"Best result for Logistic Regression: \")\n",
            "print(best_result_logistic[\"CV F1\"] + \"+/-\" + best_result_logistic[\"CV F1 std\"])\n",
            "print(\n",
            "    best_result_logistic[\"CV Accuracy\"]\n",
            "    + \"+/-\"\n",
            "    + best_result_logistic[\"CV Accuracy std\"]\n",
            ")\n",
            "print(\"With corr Threshold: \")\n",
            "print(best_result_logistic[\"Drop corr thresh.\"])\n",
            "\n",
            "\n",
            "print(\"Best result for Reg Logistic Regression:\")\n",
            "print(best_result_reg_logistic[\"CV F1\"] + \"+/-\" + best_result_reg_logistic[\"CV F1 std\"])\n",
            "print(\n",
            "    best_result_reg_logistic[\"CV Accuracy\"]\n",
            "    + \"+/-\"\n",
            "    + best_result_reg_logistic[\"CV Accuracy std\"]\n",
            ")\n",
            "print(\"With corr Threshold: \")\n",
            "print(best_result_reg_logistic[\"Drop corr thresh.\"])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "keep the corr threshold 0.9"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Experiment using BUILD POLY"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 27,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 28,
         "metadata": {},
         "outputs": [],
         "source": [
            "#### BASELINE ####\n",
            "\n",
            "### Column dropping and imputation ###\n",
            "# threshold for drop_columns function\n",
            "DROP_NAN_THRESHOLD = 1  # 1 = keep everything, 0 = drop everything that contains nan\n",
            "# threshold for categorical/numerical (categorical are imputated with median, numerical with mean)\n",
            "CAT_NUM_THRESHOLD = 30\n",
            "# flag for drop_single_value_columns function\n",
            "# Should always be True, otherwise it is messing up with the correlation coefficient.\n",
            "DROP_SINGLE = True\n",
            "# threshold for drop_correlated_columns function\n",
            "DROP_CORR_THRESHOLD = 0.9\n",
            "\n",
            "### Feature processing ###\n",
            "# flag for build_poly function\n",
            "BUILD_POLY = False\n",
            "# degree for build_poly function\n",
            "DEGREE = 2\n",
            "# flag for build_log function\n",
            "BUILD_LOG = False\n",
            "# flag for build_x\n",
            "BUILD_RATIOS = False\n",
            "# flag for standardize function\n",
            "STANDARDIZE = True\n",
            "\n",
            "NUM_FOLDS = 5\n",
            "\n",
            "GAMMA = 0.5\n",
            "MAX_ITERS = 100\n",
            "LAMBDA = 0.1"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 29,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Building polynomial with degree = 2...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66710\n",
                  "Test loss: 0.66911\n",
                  "Train accuracy: 0.64386\n",
                  "Train f1_score: 0.30857\n",
                  "Test accuracy: 0.64210\n",
                  "Test f1_score: 0.30232\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66715\n",
                  "Test loss: 0.66880\n",
                  "Train accuracy: 0.64264\n",
                  "Train f1_score: 0.30804\n",
                  "Test accuracy: 0.64195\n",
                  "Test f1_score: 0.30232\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66714\n",
                  "Test loss: 0.66919\n",
                  "Train accuracy: 0.64349\n",
                  "Train f1_score: 0.30690\n",
                  "Test accuracy: 0.64099\n",
                  "Test f1_score: 0.30847\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66750\n",
                  "Test loss: 0.66749\n",
                  "Train accuracy: 0.64270\n",
                  "Train f1_score: 0.30686\n",
                  "Test accuracy: 0.64280\n",
                  "Test f1_score: 0.30784\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66704\n",
                  "Test loss: 0.66981\n",
                  "Train accuracy: 0.64296\n",
                  "Train f1_score: 0.30593\n",
                  "Test accuracy: 0.63928\n",
                  "Test f1_score: 0.30872\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.643129 ± 0.000474\n",
                  "f1_score : 0.307260 ± 0.000936\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.641422 ± 0.001217\n",
                  "f1_score : 0.305934 ± 0.002965\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67007\n",
                  "Test loss: 0.67105\n",
                  "Train accuracy: 0.62950\n",
                  "Train f1_score: 0.30165\n",
                  "Test accuracy: 0.62919\n",
                  "Test f1_score: 0.29722\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67021\n",
                  "Test loss: 0.67065\n",
                  "Train accuracy: 0.62822\n",
                  "Train f1_score: 0.30136\n",
                  "Test accuracy: 0.62870\n",
                  "Test f1_score: 0.29654\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67014\n",
                  "Test loss: 0.67102\n",
                  "Train accuracy: 0.62945\n",
                  "Train f1_score: 0.30028\n",
                  "Test accuracy: 0.62552\n",
                  "Test f1_score: 0.30031\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67046\n",
                  "Test loss: 0.66998\n",
                  "Train accuracy: 0.62854\n",
                  "Train f1_score: 0.29977\n",
                  "Test accuracy: 0.63078\n",
                  "Test f1_score: 0.30281\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66999\n",
                  "Test loss: 0.67143\n",
                  "Train accuracy: 0.62940\n",
                  "Train f1_score: 0.29986\n",
                  "Test accuracy: 0.62695\n",
                  "Test f1_score: 0.30326\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629023 ± 0.000533\n",
                  "f1_score : 0.300583 ± 0.000778\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628229 ± 0.001823\n",
                  "f1_score : 0.300029 ± 0.002766\n"
               ]
            }
         ],
         "source": [
            "results = []\n",
            "\n",
            "DROP_NAN_THRESHOLD = 1\n",
            "CAT_NUM_THRESHOLD = 200\n",
            "BUILD_POLY = True\n",
            "\n",
            "DEGREE = 2  # when we use degree 3 the kernel crashes\n",
            "\n",
            "results = execute_pipeline(\n",
            "    x_train,\n",
            "    x_test,\n",
            "    y_train,\n",
            "    DROP_NAN_THRESHOLD,\n",
            "    DROP_CORR_THRESHOLD,\n",
            "    CAT_NUM_THRESHOLD,\n",
            "    DROP_SINGLE,\n",
            "    BUILD_RATIOS,\n",
            "    BUILD_LOG,\n",
            "    BUILD_POLY,\n",
            "    DEGREE,\n",
            "    STANDARDIZE,\n",
            "    NUM_FOLDS,\n",
            "    GAMMA,\n",
            "    MAX_ITERS,\n",
            "    LAMBDA,\n",
            "    results,\n",
            ")\n",
            "\n",
            "with open(\"../results/results_poly.csv\", \"w\") as csvfile:\n",
            "    writer = csv.DictWriter(\n",
            "        csvfile,\n",
            "        fieldnames=[\n",
            "            \"Drop Threshold\",\n",
            "            \"Drop corr thresh.\",\n",
            "            \"Imputation\",\n",
            "            \"Standardization\",\n",
            "            \"Build Poly\",\n",
            "            \"Degree\",\n",
            "            \"Build Log\",\n",
            "            \"Build Ratios\",\n",
            "            \"Model\",\n",
            "            \"Initial W\",\n",
            "            \"Max Iters\",\n",
            "            \"Gamma\",\n",
            "            \"Lambda\",\n",
            "            \"CV F1 std\",\n",
            "            \"CV Accuracy std\",\n",
            "            \"CV F1\",\n",
            "            \"CV Accuracy\",\n",
            "        ],\n",
            "    )\n",
            "\n",
            "    writer.writeheader()\n",
            "    for result in results:\n",
            "        writer.writerow(result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 30,
         "metadata": {},
         "outputs": [],
         "source": [
            "results_poly = []\n",
            "with open(\"../results/results_poly.csv\", \"r\") as csvfile:\n",
            "    reader = csv.DictReader(csvfile)\n",
            "    for row in reader:\n",
            "        results_poly.append(row)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Results for build poly with degree 2, Logistic Regression: \n",
                  "0.3059342053019788+/-0.002965275068657712\n",
                  "0.6414219757112164+/-0.0012173560626491924\n",
                  "Results for build poly with degree 2, Reg Logistic Regression: \n",
                  "0.3000286653491342+/-0.0027655394418345802\n",
                  "0.6282292349185548+/-0.0018229047245199273\n"
               ]
            }
         ],
         "source": [
            "print(\"Results for build poly with degree 2, Logistic Regression: \")\n",
            "print(results_poly[0][\"CV F1\"] + \"+/-\" + results_poly[0][\"CV F1 std\"])\n",
            "print(results_poly[0][\"CV Accuracy\"] + \"+/-\" + results_poly[0][\"CV Accuracy std\"])\n",
            "\n",
            "print(\"Results for build poly with degree 2, Reg Logistic Regression: \")\n",
            "print(results_poly[1][\"CV F1\"] + \"+/-\" + results_poly[1][\"CV F1 std\"])\n",
            "print(results_poly[1][\"CV Accuracy\"] + \"+/-\" + results_poly[1][\"CV Accuracy std\"])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Experiment using BUILD LOG"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 52,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 53,
         "metadata": {},
         "outputs": [],
         "source": [
            "#### BASELINE ####\n",
            "\n",
            "### Column dropping and imputation ###\n",
            "# threshold for drop_columns function\n",
            "DROP_NAN_THRESHOLD = 1  # 1 = keep everything, 0 = drop everything that contains nan\n",
            "# threshold for categorical/numerical (categorical are imputated with median, numerical with mean)\n",
            "CAT_NUM_THRESHOLD = 30\n",
            "# flag for drop_single_value_columns function\n",
            "# Should always be True, otherwise it is messing up with the correlation coefficient.\n",
            "DROP_SINGLE = True\n",
            "# threshold for drop_correlated_columns function\n",
            "DROP_CORR_THRESHOLD = 0.9\n",
            "\n",
            "### Feature processing ###\n",
            "# flag for build_poly function\n",
            "BUILD_POLY = False\n",
            "# degree for build_poly function\n",
            "DEGREE = 2\n",
            "# flag for build_log function\n",
            "BUILD_LOG = False\n",
            "# flag for build_x\n",
            "BUILD_RATIOS = False\n",
            "# flag for standardize function\n",
            "STANDARDIZE = True\n",
            "\n",
            "NUM_FOLDS = 5\n",
            "\n",
            "GAMMA = 0.5\n",
            "MAX_ITERS = 100\n",
            "LAMBDA = 0.1"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 54,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Building log...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66824\n",
                  "Test loss: 0.67002\n",
                  "Train accuracy: 0.63585\n",
                  "Train f1_score: 0.30419\n",
                  "Test accuracy: 0.63410\n",
                  "Test f1_score: 0.29813\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66843\n",
                  "Test loss: 0.66928\n",
                  "Train accuracy: 0.63384\n",
                  "Train f1_score: 0.30349\n",
                  "Test accuracy: 0.63321\n",
                  "Test f1_score: 0.29779\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66835\n",
                  "Test loss: 0.66968\n",
                  "Train accuracy: 0.63496\n",
                  "Train f1_score: 0.30205\n",
                  "Test accuracy: 0.63227\n",
                  "Test f1_score: 0.30382\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66864\n",
                  "Test loss: 0.66845\n",
                  "Train accuracy: 0.63529\n",
                  "Train f1_score: 0.30263\n",
                  "Test accuracy: 0.63582\n",
                  "Test f1_score: 0.30463\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66815\n",
                  "Test loss: 0.67046\n",
                  "Train accuracy: 0.63506\n",
                  "Train f1_score: 0.30179\n",
                  "Test accuracy: 0.63154\n",
                  "Test f1_score: 0.30476\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.635001 ± 0.000657\n",
                  "f1_score : 0.302829 ± 0.000895\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.633389 ± 0.001491\n",
                  "f1_score : 0.301827 ± 0.003174\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67025\n",
                  "Test loss: 0.67116\n",
                  "Train accuracy: 0.62894\n",
                  "Train f1_score: 0.30107\n",
                  "Test accuracy: 0.62834\n",
                  "Test f1_score: 0.29638\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67040\n",
                  "Test loss: 0.67075\n",
                  "Train accuracy: 0.62755\n",
                  "Train f1_score: 0.30071\n",
                  "Test accuracy: 0.62741\n",
                  "Test f1_score: 0.29541\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67032\n",
                  "Test loss: 0.67110\n",
                  "Train accuracy: 0.62890\n",
                  "Train f1_score: 0.29967\n",
                  "Test accuracy: 0.62579\n",
                  "Test f1_score: 0.30058\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67062\n",
                  "Test loss: 0.67004\n",
                  "Train accuracy: 0.62803\n",
                  "Train f1_score: 0.29939\n",
                  "Test accuracy: 0.63061\n",
                  "Test f1_score: 0.30291\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67015\n",
                  "Test loss: 0.67148\n",
                  "Train accuracy: 0.62874\n",
                  "Train f1_score: 0.29926\n",
                  "Test accuracy: 0.62660\n",
                  "Test f1_score: 0.30290\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.628432 ± 0.000550\n",
                  "f1_score : 0.300020 ± 0.000729\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.627751 ± 0.001660\n",
                  "f1_score : 0.299638 ± 0.003185\n"
               ]
            }
         ],
         "source": [
            "results = []\n",
            "\n",
            "BUILD_LOG = True\n",
            "CAT_NUM_THRESHOLD = 200\n",
            "DROP_CORR_THRESHOLD = 0.9\n",
            "DROP_NAN_THRESHOLD = 1\n",
            "\n",
            "results = execute_pipeline(\n",
            "    x_train,\n",
            "    x_test,\n",
            "    y_train,\n",
            "    DROP_NAN_THRESHOLD,\n",
            "    DROP_CORR_THRESHOLD,\n",
            "    CAT_NUM_THRESHOLD,\n",
            "    DROP_SINGLE,\n",
            "    BUILD_RATIOS,\n",
            "    BUILD_LOG,\n",
            "    BUILD_POLY,\n",
            "    DEGREE,\n",
            "    STANDARDIZE,\n",
            "    NUM_FOLDS,\n",
            "    GAMMA,\n",
            "    MAX_ITERS,\n",
            "    LAMBDA,\n",
            "    results,\n",
            ")\n",
            "\n",
            "with open(\"../results/results_log.csv\", \"w\") as csvfile:\n",
            "    writer = csv.DictWriter(\n",
            "        csvfile,\n",
            "        fieldnames=[\n",
            "            \"Drop Threshold\",\n",
            "            \"Drop corr thresh.\",\n",
            "            \"Imputation\",\n",
            "            \"Standardization\",\n",
            "            \"Build Poly\",\n",
            "            \"Degree\",\n",
            "            \"Build Log\",\n",
            "            \"Build Ratios\",\n",
            "            \"Model\",\n",
            "            \"Initial W\",\n",
            "            \"Max Iters\",\n",
            "            \"Gamma\",\n",
            "            \"Lambda\",\n",
            "            \"CV F1 std\",\n",
            "            \"CV Accuracy std\",\n",
            "            \"CV F1\",\n",
            "            \"CV Accuracy\",\n",
            "        ],\n",
            "    )\n",
            "\n",
            "    writer.writeheader()\n",
            "    for result in results:\n",
            "        writer.writerow(result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 55,
         "metadata": {},
         "outputs": [],
         "source": [
            "results_log = []\n",
            "with open(\"../results/results_log.csv\", \"r\") as csvfile:\n",
            "    reader = csv.DictReader(csvfile)\n",
            "    for row in reader:\n",
            "        results_log.append(row)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 56,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Results for build log, Logistic Regression: \n",
                  "0.30182729233722394+/-0.0031742020883959066\n",
                  "0.6333886967254332+/-0.0014914083696359283\n",
                  "Results for build log, Reg Logistic Regression: \n",
                  "0.29963755266459335+/-0.0031854647106852167\n",
                  "0.6277507733097658+/-0.001660233409478766\n"
               ]
            }
         ],
         "source": [
            "print(\"Results for build log, Logistic Regression: \")\n",
            "print(results_log[0][\"CV F1\"] + \"+/-\" + results_log[0][\"CV F1 std\"])\n",
            "print(results_log[0][\"CV Accuracy\"] + \"+/-\" + results_log[0][\"CV Accuracy std\"])\n",
            "print(\"Results for build log, Reg Logistic Regression: \")\n",
            "print(results_log[1][\"CV F1\"] + \"+/-\" + results_log[1][\"CV F1 std\"])\n",
            "print(results_log[1][\"CV Accuracy\"] + \"+/-\" + results_log[1][\"CV Accuracy std\"])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Experiment using BUILD RATIOS"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 46,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 48,
         "metadata": {},
         "outputs": [],
         "source": [
            "#### BASELINE ####\n",
            "\n",
            "### Column dropping and imputation ###\n",
            "# threshold for drop_columns function\n",
            "DROP_NAN_THRESHOLD = 1  # 1 = keep everything, 0 = drop everything that contains nan\n",
            "# threshold for categorical/numerical (categorical are imputated with median, numerical with mean)\n",
            "CAT_NUM_THRESHOLD = 30\n",
            "# flag for drop_single_value_columns function\n",
            "# Should always be True, otherwise it is messing up with the correlation coefficient.\n",
            "DROP_SINGLE = True\n",
            "# threshold for drop_correlated_columns function\n",
            "DROP_CORR_THRESHOLD = 0.9\n",
            "\n",
            "### Feature processing ###\n",
            "# flag for build_poly function\n",
            "BUILD_POLY = False\n",
            "# degree for build_poly function\n",
            "DEGREE = 2\n",
            "# flag for build_log function\n",
            "BUILD_LOG = False\n",
            "# flag for build_x\n",
            "BUILD_RATIOS = False\n",
            "# flag for standardize function\n",
            "STANDARDIZE = True\n",
            "\n",
            "NUM_FOLDS = 5\n",
            "\n",
            "GAMMA = 0.5\n",
            "MAX_ITERS = 100\n",
            "LAMBDA = 0.1"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 49,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Building ratios...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66824\n",
                  "Test loss: 0.67008\n",
                  "Train accuracy: 0.63566\n",
                  "Train f1_score: 0.30393\n",
                  "Test accuracy: 0.63413\n",
                  "Test f1_score: 0.29811\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66843\n",
                  "Test loss: 0.66934\n",
                  "Train accuracy: 0.63372\n",
                  "Train f1_score: 0.30332\n",
                  "Test accuracy: 0.63325\n",
                  "Test f1_score: 0.29777\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66837\n",
                  "Test loss: 0.66966\n",
                  "Train accuracy: 0.63484\n",
                  "Train f1_score: 0.30214\n",
                  "Test accuracy: 0.63219\n",
                  "Test f1_score: 0.30358\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66865\n",
                  "Test loss: 0.66846\n",
                  "Train accuracy: 0.63533\n",
                  "Train f1_score: 0.30263\n",
                  "Test accuracy: 0.63634\n",
                  "Test f1_score: 0.30505\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66817\n",
                  "Test loss: 0.67043\n",
                  "Train accuracy: 0.63515\n",
                  "Train f1_score: 0.30182\n",
                  "Test accuracy: 0.63155\n",
                  "Test f1_score: 0.30449\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.634939 ± 0.000666\n",
                  "f1_score : 0.302767 ± 0.000769\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.633492 ± 0.001674\n",
                  "f1_score : 0.301799 ± 0.003189\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67024\n",
                  "Test loss: 0.67117\n",
                  "Train accuracy: 0.62927\n",
                  "Train f1_score: 0.30122\n",
                  "Test accuracy: 0.62895\n",
                  "Test f1_score: 0.29701\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67040\n",
                  "Test loss: 0.67076\n",
                  "Train accuracy: 0.62791\n",
                  "Train f1_score: 0.30084\n",
                  "Test accuracy: 0.62843\n",
                  "Test f1_score: 0.29619\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67033\n",
                  "Test loss: 0.67107\n",
                  "Train accuracy: 0.62896\n",
                  "Train f1_score: 0.29970\n",
                  "Test accuracy: 0.62582\n",
                  "Test f1_score: 0.30032\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67062\n",
                  "Test loss: 0.67006\n",
                  "Train accuracy: 0.62827\n",
                  "Train f1_score: 0.29952\n",
                  "Test accuracy: 0.63091\n",
                  "Test f1_score: 0.30280\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67015\n",
                  "Test loss: 0.67149\n",
                  "Train accuracy: 0.62928\n",
                  "Train f1_score: 0.29968\n",
                  "Test accuracy: 0.62651\n",
                  "Test f1_score: 0.30246\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.628737 ± 0.000554\n",
                  "f1_score : 0.300194 ± 0.000699\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628126 ± 0.001814\n",
                  "f1_score : 0.299754 ± 0.002727\n"
               ]
            }
         ],
         "source": [
            "results = []\n",
            "\n",
            "BUILD_RATIOS = True\n",
            "CAT_NUM_THRESHOLD = 200\n",
            "DROP_NAN_THRESHOLD = 1\n",
            "DROP_CORR_THRESHOLD = 0.9\n",
            "results = execute_pipeline(\n",
            "    x_train,\n",
            "    x_test,\n",
            "    y_train,\n",
            "    DROP_NAN_THRESHOLD,\n",
            "    DROP_CORR_THRESHOLD,\n",
            "    CAT_NUM_THRESHOLD,\n",
            "    DROP_SINGLE,\n",
            "    BUILD_RATIOS,\n",
            "    BUILD_LOG,\n",
            "    BUILD_POLY,\n",
            "    DEGREE,\n",
            "    STANDARDIZE,\n",
            "    NUM_FOLDS,\n",
            "    GAMMA,\n",
            "    MAX_ITERS,\n",
            "    LAMBDA,\n",
            "    results,\n",
            ")\n",
            "\n",
            "with open(\"../results/results_ratios.csv\", \"w\") as csvfile:\n",
            "    writer = csv.DictWriter(\n",
            "        csvfile,\n",
            "        fieldnames=[\n",
            "            \"Drop Threshold\",\n",
            "            \"Drop corr thresh.\",\n",
            "            \"Imputation\",\n",
            "            \"Standardization\",\n",
            "            \"Build Poly\",\n",
            "            \"Degree\",\n",
            "            \"Build Log\",\n",
            "            \"Build Ratios\",\n",
            "            \"Model\",\n",
            "            \"Initial W\",\n",
            "            \"Max Iters\",\n",
            "            \"Gamma\",\n",
            "            \"Lambda\",\n",
            "            \"CV F1 std\",\n",
            "            \"CV Accuracy std\",\n",
            "            \"CV F1\",\n",
            "            \"CV Accuracy\",\n",
            "        ],\n",
            "    )\n",
            "\n",
            "    writer.writeheader()\n",
            "    for result in results:\n",
            "        writer.writerow(result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 50,
         "metadata": {},
         "outputs": [],
         "source": [
            "results_ratios = []\n",
            "with open(\"../results/results_ratios.csv\", \"r\") as csvfile:\n",
            "    reader = csv.DictReader(csvfile)\n",
            "    for row in reader:\n",
            "        results_ratios.append(row)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 51,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Results for build ratios, Logistic Regression: \n",
                  "0.30179929093616437+/-0.0031890864971147763\n",
                  "0.6334923126152345+/-0.0016739603814959311\n",
                  "Results for build ratios, Reg Logistic Regression: \n",
                  "0.2997544266217278+/-0.0027273148251637743\n",
                  "0.6281256190287533+/-0.001813751784724359\n"
               ]
            }
         ],
         "source": [
            "print(\"Results for build ratios, Logistic Regression: \")\n",
            "print(results_ratios[0][\"CV F1\"] + \"+/-\" + results_ratios[0][\"CV F1 std\"])\n",
            "print(results_ratios[0][\"CV Accuracy\"] + \"+/-\" + results_ratios[0][\"CV Accuracy std\"])\n",
            "print(\"Results for build ratios, Reg Logistic Regression: \")\n",
            "print(results_ratios[1][\"CV F1\"] + \"+/-\" + results_ratios[1][\"CV F1 std\"])\n",
            "print(results_ratios[1][\"CV Accuracy\"] + \"+/-\" + results_ratios[1][\"CV Accuracy std\"])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Ratio + Poly"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "#### BASELINE ####\n",
            "\n",
            "### Column dropping and imputation ###\n",
            "# threshold for drop_columns function\n",
            "DROP_NAN_THRESHOLD = 1  # 1 = keep everything, 0 = drop everything that contains nan\n",
            "# threshold for categorical/numerical (categorical are imputated with median, numerical with mean)\n",
            "CAT_NUM_THRESHOLD = 30\n",
            "# flag for drop_single_value_columns function\n",
            "# Should always be True, otherwise it is messing up with the correlation coefficient.\n",
            "DROP_SINGLE = True\n",
            "# threshold for drop_correlated_columns function\n",
            "DROP_CORR_THRESHOLD = 0.9\n",
            "\n",
            "### Feature processing ###\n",
            "# flag for build_poly function\n",
            "BUILD_POLY = False\n",
            "# degree for build_poly function\n",
            "DEGREE = 2\n",
            "# flag for build_log function\n",
            "BUILD_LOG = False\n",
            "# flag for build_x\n",
            "BUILD_RATIOS = False\n",
            "# flag for standardize function\n",
            "STANDARDIZE = True\n",
            "\n",
            "NUM_FOLDS = 5\n",
            "\n",
            "GAMMA = 0.5\n",
            "MAX_ITERS = 100\n",
            "LAMBDA = 0.1"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Building ratios...\n",
                  "Building polynomial with degree = 2...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66708\n",
                  "Test loss: 0.66919\n",
                  "Train accuracy: 0.64393\n",
                  "Train f1_score: 0.30851\n",
                  "Test accuracy: 0.64198\n",
                  "Test f1_score: 0.30238\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66712\n",
                  "Test loss: 0.66889\n",
                  "Train accuracy: 0.64263\n",
                  "Train f1_score: 0.30809\n",
                  "Test accuracy: 0.64141\n",
                  "Test f1_score: 0.30167\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66712\n",
                  "Test loss: 0.66929\n",
                  "Train accuracy: 0.64343\n",
                  "Train f1_score: 0.30688\n",
                  "Test accuracy: 0.64112\n",
                  "Test f1_score: 0.30860\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66749\n",
                  "Test loss: 0.66753\n",
                  "Train accuracy: 0.64262\n",
                  "Train f1_score: 0.30659\n",
                  "Test accuracy: 0.64256\n",
                  "Test f1_score: 0.30790\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66703\n",
                  "Test loss: 0.66984\n",
                  "Train accuracy: 0.64303\n",
                  "Train f1_score: 0.30601\n",
                  "Test accuracy: 0.63940\n",
                  "Test f1_score: 0.30863\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.643127 ± 0.000500\n",
                  "f1_score : 0.307214 ± 0.000937\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.641294 ± 0.001066\n",
                  "f1_score : 0.305834 ± 0.003130\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67006\n",
                  "Test loss: 0.67108\n",
                  "Train accuracy: 0.62961\n",
                  "Train f1_score: 0.30164\n",
                  "Test accuracy: 0.62954\n",
                  "Test f1_score: 0.29771\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67020\n",
                  "Test loss: 0.67067\n",
                  "Train accuracy: 0.62845\n",
                  "Train f1_score: 0.30144\n",
                  "Test accuracy: 0.62887\n",
                  "Test f1_score: 0.29672\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67013\n",
                  "Test loss: 0.67105\n",
                  "Train accuracy: 0.62936\n",
                  "Train f1_score: 0.30019\n",
                  "Test accuracy: 0.62572\n",
                  "Test f1_score: 0.30050\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67045\n",
                  "Test loss: 0.66998\n",
                  "Train accuracy: 0.62866\n",
                  "Train f1_score: 0.29989\n",
                  "Test accuracy: 0.63102\n",
                  "Test f1_score: 0.30294\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66998\n",
                  "Test loss: 0.67144\n",
                  "Train accuracy: 0.62925\n",
                  "Train f1_score: 0.29979\n",
                  "Test accuracy: 0.62646\n",
                  "Test f1_score: 0.30271\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629066 ± 0.000439\n",
                  "f1_score : 0.300590 ± 0.000789\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628324 ± 0.001965\n",
                  "f1_score : 0.300115 ± 0.002538\n"
               ]
            }
         ],
         "source": [
            "results = []\n",
            "\n",
            "BUILD_RATIOS = True\n",
            "BUILD_LOG = False\n",
            "BUILD_POLY = True\n",
            "CAT_NUM_THRESHOLD = 200\n",
            "DROP_NAN_THRESHOLD = 1\n",
            "DROP_CORR_THRESHOLD = 0.9\n",
            "results = execute_pipeline(\n",
            "    x_train,\n",
            "    x_test,\n",
            "    y_train,\n",
            "    DROP_NAN_THRESHOLD,\n",
            "    DROP_CORR_THRESHOLD,\n",
            "    CAT_NUM_THRESHOLD,\n",
            "    DROP_SINGLE,\n",
            "    BUILD_RATIOS,\n",
            "    BUILD_LOG,\n",
            "    BUILD_POLY,\n",
            "    DEGREE,\n",
            "    STANDARDIZE,\n",
            "    NUM_FOLDS,\n",
            "    GAMMA,\n",
            "    MAX_ITERS,\n",
            "    LAMBDA,\n",
            "    results,\n",
            ")\n",
            "\n",
            "with open(\"../results/results_ratio_poly.csv\", \"w\") as csvfile:\n",
            "    writer = csv.DictWriter(\n",
            "        csvfile,\n",
            "        fieldnames=[\n",
            "            \"Drop Threshold\",\n",
            "            \"Drop corr thresh.\",\n",
            "            \"Imputation\",\n",
            "            \"Standardization\",\n",
            "            \"Build Poly\",\n",
            "            \"Degree\",\n",
            "            \"Build Log\",\n",
            "            \"Build Ratios\",\n",
            "            \"Model\",\n",
            "            \"Initial W\",\n",
            "            \"Max Iters\",\n",
            "            \"Gamma\",\n",
            "            \"Lambda\",\n",
            "            \"CV F1 std\",\n",
            "            \"CV Accuracy std\",\n",
            "            \"CV F1\",\n",
            "            \"CV Accuracy\",\n",
            "        ],\n",
            "    )\n",
            "\n",
            "    writer.writeheader()\n",
            "    for result in results:\n",
            "        writer.writerow(result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "results_ratio_poly = []\n",
            "with open(\"../results/results_ratio_poly.csv\", \"r\") as csvfile:\n",
            "    reader = csv.DictReader(csvfile)\n",
            "    for row in reader:\n",
            "        results_ratio_poly.append(row)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Results for build ratios, Logistic Regression: \n",
                  "0.30583396906534166+/-0.0031304020342082855\n",
                  "0.6412939796120499+/-0.0010660854638806165\n",
                  "Results for build ratios, Reg Logistic Regression: \n",
                  "0.3001154604383235+/-0.0025379873578594316\n",
                  "0.6283237082298444+/-0.0019650046062295026\n"
               ]
            }
         ],
         "source": [
            "print(\"Results for build ratios, Logistic Regression: \")\n",
            "print(results_ratio_poly[0][\"CV F1\"] + \"+/-\" + results_ratio_poly[0][\"CV F1 std\"])\n",
            "print(\n",
            "    results_ratio_poly[0][\"CV Accuracy\"]\n",
            "    + \"+/-\"\n",
            "    + results_ratio_poly[0][\"CV Accuracy std\"]\n",
            ")\n",
            "print(\"Results for build ratios, Reg Logistic Regression: \")\n",
            "print(results_ratio_poly[1][\"CV F1\"] + \"+/-\" + results_ratio_poly[1][\"CV F1 std\"])\n",
            "print(\n",
            "    results_ratio_poly[1][\"CV Accuracy\"]\n",
            "    + \"+/-\"\n",
            "    + results_ratio_poly[1][\"CV Accuracy std\"]\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Not an improvement, we will use only poly fron now on"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Experiments using different gammas"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "#### BASELINE ####\n",
            "\n",
            "### Column dropping and imputation ###\n",
            "# threshold for drop_columns function\n",
            "DROP_NAN_THRESHOLD = 0.8  # 1 = keep everything, 0 = drop everything that contains nan\n",
            "# threshold for categorical/numerical (categorical are imputated with median, numerical with mean)\n",
            "CAT_NUM_THRESHOLD = 50\n",
            "# flag for drop_single_value_columns function\n",
            "# Should always be True, otherwise it is messing up with the correlation coefficient.\n",
            "DROP_SINGLE = True\n",
            "# threshold for drop_correlated_columns function\n",
            "DROP_CORR_THRESHOLD = 0.8\n",
            "\n",
            "### Feature processing ###\n",
            "# flag for build_poly function\n",
            "BUILD_POLY = False\n",
            "# degree for build_poly function\n",
            "DEGREE = 2\n",
            "# flag for build_log function\n",
            "BUILD_LOG = True\n",
            "# flag for build_x\n",
            "BUILD_RATIOS = True\n",
            "# flag for standardize function\n",
            "STANDARDIZE = True\n",
            "\n",
            "NUM_FOLDS = 5\n",
            "\n",
            "GAMMA = 0.5\n",
            "MAX_ITERS = 300\n",
            "LAMBDA = 0.1"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.8...\n",
                  "Building ratios...\n",
                  "Building log...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66929\n",
                  "Test loss: 0.67051\n",
                  "Train accuracy: 0.63034\n",
                  "Train f1_score: 0.30123\n",
                  "Test accuracy: 0.62959\n",
                  "Test f1_score: 0.29623\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66942\n",
                  "Test loss: 0.67002\n",
                  "Train accuracy: 0.62918\n",
                  "Train f1_score: 0.30135\n",
                  "Test accuracy: 0.62877\n",
                  "Test f1_score: 0.29568\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66939\n",
                  "Test loss: 0.67023\n",
                  "Train accuracy: 0.63021\n",
                  "Train f1_score: 0.29990\n",
                  "Test accuracy: 0.62761\n",
                  "Test f1_score: 0.30132\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66978\n",
                  "Test loss: 0.66862\n",
                  "Train accuracy: 0.62987\n",
                  "Train f1_score: 0.29998\n",
                  "Test accuracy: 0.63218\n",
                  "Test f1_score: 0.30329\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66921\n",
                  "Test loss: 0.67087\n",
                  "Train accuracy: 0.63076\n",
                  "Train f1_score: 0.29996\n",
                  "Test accuracy: 0.62810\n",
                  "Test f1_score: 0.30315\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.630075 ± 0.000530\n",
                  "f1_score : 0.300484 ± 0.000662\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.629247 ± 0.001610\n",
                  "f1_score : 0.299936 ± 0.003327\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67095\n",
                  "Test loss: 0.67157\n",
                  "Train accuracy: 0.62281\n",
                  "Train f1_score: 0.29844\n",
                  "Test accuracy: 0.62250\n",
                  "Test f1_score: 0.29387\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67105\n",
                  "Test loss: 0.67134\n",
                  "Train accuracy: 0.62174\n",
                  "Train f1_score: 0.29837\n",
                  "Test accuracy: 0.62104\n",
                  "Test f1_score: 0.29262\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67101\n",
                  "Test loss: 0.67160\n",
                  "Train accuracy: 0.62326\n",
                  "Train f1_score: 0.29703\n",
                  "Test accuracy: 0.61978\n",
                  "Test f1_score: 0.29819\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67136\n",
                  "Test loss: 0.67035\n",
                  "Train accuracy: 0.62205\n",
                  "Train f1_score: 0.29697\n",
                  "Test accuracy: 0.62473\n",
                  "Test f1_score: 0.29998\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67087\n",
                  "Test loss: 0.67185\n",
                  "Train accuracy: 0.62315\n",
                  "Train f1_score: 0.29680\n",
                  "Test accuracy: 0.62141\n",
                  "Test f1_score: 0.30035\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.622601 ± 0.000603\n",
                  "f1_score : 0.297522 ± 0.000724\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.621890 ± 0.001665\n",
                  "f1_score : 0.297001 ± 0.003178\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.8...\n",
                  "Building ratios...\n",
                  "Building log...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66926\n",
                  "Test loss: 0.67050\n",
                  "Train accuracy: 0.63024\n",
                  "Train f1_score: 0.30130\n",
                  "Test accuracy: 0.62936\n",
                  "Test f1_score: 0.29594\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66940\n",
                  "Test loss: 0.67001\n",
                  "Train accuracy: 0.62898\n",
                  "Train f1_score: 0.30131\n",
                  "Test accuracy: 0.62864\n",
                  "Test f1_score: 0.29570\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66936\n",
                  "Test loss: 0.67023\n",
                  "Train accuracy: 0.62983\n",
                  "Train f1_score: 0.29968\n",
                  "Test accuracy: 0.62733\n",
                  "Test f1_score: 0.30125\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66975\n",
                  "Test loss: 0.66859\n",
                  "Train accuracy: 0.62972\n",
                  "Train f1_score: 0.29990\n",
                  "Test accuracy: 0.63171\n",
                  "Test f1_score: 0.30302\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66917\n",
                  "Test loss: 0.67086\n",
                  "Train accuracy: 0.63046\n",
                  "Train f1_score: 0.29974\n",
                  "Test accuracy: 0.62808\n",
                  "Test f1_score: 0.30307\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629847 ± 0.000509\n",
                  "f1_score : 0.300386 ± 0.000756\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.629025 ± 0.001497\n",
                  "f1_score : 0.299793 ± 0.003313\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67095\n",
                  "Test loss: 0.67157\n",
                  "Train accuracy: 0.62282\n",
                  "Train f1_score: 0.29844\n",
                  "Test accuracy: 0.62250\n",
                  "Test f1_score: 0.29387\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67105\n",
                  "Test loss: 0.67134\n",
                  "Train accuracy: 0.62173\n",
                  "Train f1_score: 0.29837\n",
                  "Test accuracy: 0.62104\n",
                  "Test f1_score: 0.29262\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67101\n",
                  "Test loss: 0.67160\n",
                  "Train accuracy: 0.62326\n",
                  "Train f1_score: 0.29703\n",
                  "Test accuracy: 0.61978\n",
                  "Test f1_score: 0.29819\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67135\n",
                  "Test loss: 0.67035\n",
                  "Train accuracy: 0.62205\n",
                  "Train f1_score: 0.29697\n",
                  "Test accuracy: 0.62473\n",
                  "Test f1_score: 0.29998\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67087\n",
                  "Test loss: 0.67185\n",
                  "Train accuracy: 0.62315\n",
                  "Train f1_score: 0.29680\n",
                  "Test accuracy: 0.62141\n",
                  "Test f1_score: 0.30035\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.622604 ± 0.000606\n",
                  "f1_score : 0.297523 ± 0.000725\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.621890 ± 0.001665\n",
                  "f1_score : 0.297001 ± 0.003178\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.8...\n",
                  "Building ratios...\n",
                  "Building log...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66924\n",
                  "Test loss: 0.67049\n",
                  "Train accuracy: 0.63007\n",
                  "Train f1_score: 0.30126\n",
                  "Test accuracy: 0.62951\n",
                  "Test f1_score: 0.29610\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66938\n",
                  "Test loss: 0.66999\n",
                  "Train accuracy: 0.62877\n",
                  "Train f1_score: 0.30117\n",
                  "Test accuracy: 0.62813\n",
                  "Test f1_score: 0.29533\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66934\n",
                  "Test loss: 0.67024\n",
                  "Train accuracy: 0.62961\n",
                  "Train f1_score: 0.29958\n",
                  "Test accuracy: 0.62717\n",
                  "Test f1_score: 0.30131\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66973\n",
                  "Test loss: 0.66858\n",
                  "Train accuracy: 0.62963\n",
                  "Train f1_score: 0.29990\n",
                  "Test accuracy: 0.63166\n",
                  "Test f1_score: 0.30291\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66915\n",
                  "Test loss: 0.67085\n",
                  "Train accuracy: 0.63041\n",
                  "Train f1_score: 0.29969\n",
                  "Test accuracy: 0.62787\n",
                  "Test f1_score: 0.30299\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629697 ± 0.000550\n",
                  "f1_score : 0.300320 ± 0.000738\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628866 ± 0.001592\n",
                  "f1_score : 0.299727 ± 0.003340\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67095\n",
                  "Test loss: 0.67157\n",
                  "Train accuracy: 0.62282\n",
                  "Train f1_score: 0.29844\n",
                  "Test accuracy: 0.62250\n",
                  "Test f1_score: 0.29387\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67105\n",
                  "Test loss: 0.67134\n",
                  "Train accuracy: 0.62173\n",
                  "Train f1_score: 0.29837\n",
                  "Test accuracy: 0.62104\n",
                  "Test f1_score: 0.29262\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67101\n",
                  "Test loss: 0.67160\n",
                  "Train accuracy: 0.62326\n",
                  "Train f1_score: 0.29703\n",
                  "Test accuracy: 0.61978\n",
                  "Test f1_score: 0.29819\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67135\n",
                  "Test loss: 0.67035\n",
                  "Train accuracy: 0.62205\n",
                  "Train f1_score: 0.29697\n",
                  "Test accuracy: 0.62473\n",
                  "Test f1_score: 0.29998\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67087\n",
                  "Test loss: 0.67185\n",
                  "Train accuracy: 0.62315\n",
                  "Train f1_score: 0.29680\n",
                  "Test accuracy: 0.62141\n",
                  "Test f1_score: 0.30035\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.622604 ± 0.000606\n",
                  "f1_score : 0.297523 ± 0.000725\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.621890 ± 0.001665\n",
                  "f1_score : 0.297001 ± 0.003178\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.8...\n",
                  "Building ratios...\n",
                  "Building log...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66923\n",
                  "Test loss: 0.67049\n",
                  "Train accuracy: 0.62994\n",
                  "Train f1_score: 0.30130\n",
                  "Test accuracy: 0.62931\n",
                  "Test f1_score: 0.29607\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66937\n",
                  "Test loss: 0.66998\n",
                  "Train accuracy: 0.62867\n",
                  "Train f1_score: 0.30115\n",
                  "Test accuracy: 0.62811\n",
                  "Test f1_score: 0.29548\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66933\n",
                  "Test loss: 0.67024\n",
                  "Train accuracy: 0.62962\n",
                  "Train f1_score: 0.29963\n",
                  "Test accuracy: 0.62715\n",
                  "Test f1_score: 0.30142\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66972\n",
                  "Test loss: 0.66857\n",
                  "Train accuracy: 0.62938\n",
                  "Train f1_score: 0.29973\n",
                  "Test accuracy: 0.63160\n",
                  "Test f1_score: 0.30291\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66914\n",
                  "Test loss: 0.67085\n",
                  "Train accuracy: 0.63028\n",
                  "Train f1_score: 0.29958\n",
                  "Test accuracy: 0.62768\n",
                  "Test f1_score: 0.30276\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629576 ± 0.000547\n",
                  "f1_score : 0.300279 ± 0.000778\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628772 ± 0.001584\n",
                  "f1_score : 0.299731 ± 0.003276\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67095\n",
                  "Test loss: 0.67157\n",
                  "Train accuracy: 0.62282\n",
                  "Train f1_score: 0.29844\n",
                  "Test accuracy: 0.62250\n",
                  "Test f1_score: 0.29387\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67105\n",
                  "Test loss: 0.67134\n",
                  "Train accuracy: 0.62173\n",
                  "Train f1_score: 0.29837\n",
                  "Test accuracy: 0.62104\n",
                  "Test f1_score: 0.29262\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67101\n",
                  "Test loss: 0.67160\n",
                  "Train accuracy: 0.62326\n",
                  "Train f1_score: 0.29703\n",
                  "Test accuracy: 0.61978\n",
                  "Test f1_score: 0.29819\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67135\n",
                  "Test loss: 0.67035\n",
                  "Train accuracy: 0.62205\n",
                  "Train f1_score: 0.29697\n",
                  "Test accuracy: 0.62473\n",
                  "Test f1_score: 0.29998\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67087\n",
                  "Test loss: 0.67185\n",
                  "Train accuracy: 0.62315\n",
                  "Train f1_score: 0.29680\n",
                  "Test accuracy: 0.62141\n",
                  "Test f1_score: 0.30035\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.622604 ± 0.000606\n",
                  "f1_score : 0.297523 ± 0.000725\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.621890 ± 0.001665\n",
                  "f1_score : 0.297001 ± 0.003178\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 0.8...\n",
                  "Building ratios...\n",
                  "Building log...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66922\n",
                  "Test loss: 0.67049\n",
                  "Train accuracy: 0.62993\n",
                  "Train f1_score: 0.30122\n",
                  "Test accuracy: 0.62939\n",
                  "Test f1_score: 0.29608\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66936\n",
                  "Test loss: 0.66998\n",
                  "Train accuracy: 0.62870\n",
                  "Train f1_score: 0.30121\n",
                  "Test accuracy: 0.62799\n",
                  "Test f1_score: 0.29541\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66932\n",
                  "Test loss: 0.67023\n",
                  "Train accuracy: 0.62965\n",
                  "Train f1_score: 0.29962\n",
                  "Test accuracy: 0.62700\n",
                  "Test f1_score: 0.30138\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66971\n",
                  "Test loss: 0.66856\n",
                  "Train accuracy: 0.62939\n",
                  "Train f1_score: 0.29977\n",
                  "Test accuracy: 0.63165\n",
                  "Test f1_score: 0.30282\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66913\n",
                  "Test loss: 0.67085\n",
                  "Train accuracy: 0.63024\n",
                  "Train f1_score: 0.29964\n",
                  "Test accuracy: 0.62759\n",
                  "Test f1_score: 0.30267\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629582 ± 0.000526\n",
                  "f1_score : 0.300292 ± 0.000755\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628723 ± 0.001660\n",
                  "f1_score : 0.299671 ± 0.003253\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67095\n",
                  "Test loss: 0.67157\n",
                  "Train accuracy: 0.62282\n",
                  "Train f1_score: 0.29844\n",
                  "Test accuracy: 0.62250\n",
                  "Test f1_score: 0.29387\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67105\n",
                  "Test loss: 0.67134\n",
                  "Train accuracy: 0.62173\n",
                  "Train f1_score: 0.29837\n",
                  "Test accuracy: 0.62104\n",
                  "Test f1_score: 0.29262\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67101\n",
                  "Test loss: 0.67160\n",
                  "Train accuracy: 0.62326\n",
                  "Train f1_score: 0.29703\n",
                  "Test accuracy: 0.61978\n",
                  "Test f1_score: 0.29819\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67135\n",
                  "Test loss: 0.67035\n",
                  "Train accuracy: 0.62205\n",
                  "Train f1_score: 0.29697\n",
                  "Test accuracy: 0.62473\n",
                  "Test f1_score: 0.29998\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67087\n",
                  "Test loss: 0.67185\n",
                  "Train accuracy: 0.62315\n",
                  "Train f1_score: 0.29680\n",
                  "Test accuracy: 0.62141\n",
                  "Test f1_score: 0.30035\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.622604 ± 0.000606\n",
                  "f1_score : 0.297523 ± 0.000725\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.621890 ± 0.001665\n",
                  "f1_score : 0.297001 ± 0.003178\n"
               ]
            }
         ],
         "source": [
            "results = []\n",
            "\n",
            "NUM_FOLDS = 5\n",
            "\n",
            "GAMMA = 0.5\n",
            "MAX_ITERS = 100\n",
            "LAMBDA = 0.1\n",
            "\n",
            "gammas = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
            "\n",
            "for gamma in gammas:\n",
            "    GAMMA = gamma\n",
            "    results = execute_pipeline(\n",
            "        x_train,\n",
            "        x_test,\n",
            "        y_train,\n",
            "        DROP_NAN_THRESHOLD,\n",
            "        DROP_CORR_THRESHOLD,\n",
            "        CAT_NUM_THRESHOLD,\n",
            "        DROP_SINGLE,\n",
            "        BUILD_RATIOS,\n",
            "        BUILD_LOG,\n",
            "        BUILD_POLY,\n",
            "        DEGREE,\n",
            "        STANDARDIZE,\n",
            "        NUM_FOLDS,\n",
            "        GAMMA,\n",
            "        MAX_ITERS,\n",
            "        LAMBDA,\n",
            "        results,\n",
            "    )\n",
            "\n",
            "with open(\"../results/results_gammas.csv\", \"w\") as csvfile:\n",
            "    writer = csv.DictWriter(\n",
            "        csvfile,\n",
            "        fieldnames=[\n",
            "            \"Drop Threshold\",\n",
            "            \"Drop corr thresh.\",\n",
            "            \"Imputation\",\n",
            "            \"Standardization\",\n",
            "            \"Build Poly\",\n",
            "            \"Degree\",\n",
            "            \"Build Log\",\n",
            "            \"Build Ratios\",\n",
            "            \"Model\",\n",
            "            \"Initial W\",\n",
            "            \"Max Iters\",\n",
            "            \"Gamma\",\n",
            "            \"Lambda\",\n",
            "            \"CV F1 std\",\n",
            "            \"CV Accuracy std\",\n",
            "            \"CV F1\",\n",
            "            \"CV Accuracy\",\n",
            "        ],\n",
            "    )\n",
            "\n",
            "    writer.writeheader()\n",
            "    for result in results:\n",
            "        writer.writerow(result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "results_gammas = []\n",
            "with open(\"../results/results_gammas.csv\", \"r\") as csvfile:\n",
            "    reader = csv.DictReader(csvfile)\n",
            "    for row in reader:\n",
            "        results_gammas.append(row)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Best result for Logistic Regression: \n",
                  "0.2999355004950664+/-0.0033272054457835097\n",
                  "0.6292471086595456+/-0.0016098785955818435\n",
                  "With Gamma: \n",
                  "0.3\n",
                  "Best result for Reg Logistic Regression:\n",
                  "0.2970012121823249+/-0.003178373686757062\n",
                  "0.6218903804836424+/-0.0016646970488154891\n",
                  "With Gamma: \n",
                  "0.3\n"
               ]
            }
         ],
         "source": [
            "# determine the best results for Logistic Regression drop nan threshold and for Reg Logistic Regression drop nan threshold\n",
            "best_result_logistic = max(\n",
            "    results_gammas,\n",
            "    key=lambda x: float(x[\"CV F1\"]) if x[\"Model\"] == \"Logistic_Regression\" else 0.0,\n",
            ")\n",
            "best_result_reg_logistic = max(\n",
            "    results_gammas,\n",
            "    key=lambda x: float(x[\"CV F1\"]) if x[\"Model\"] == \"Reg_Logistic_Regression\" else 0.0,\n",
            ")\n",
            "\n",
            "print(\"Best result for Logistic Regression: \")\n",
            "print(best_result_logistic[\"CV F1\"] + \"+/-\" + best_result_logistic[\"CV F1 std\"])\n",
            "print(\n",
            "    best_result_logistic[\"CV Accuracy\"]\n",
            "    + \"+/-\"\n",
            "    + best_result_logistic[\"CV Accuracy std\"]\n",
            ")\n",
            "print(\"With Gamma: \")\n",
            "print(best_result_logistic[\"Gamma\"])\n",
            "\n",
            "\n",
            "print(\"Best result for Reg Logistic Regression:\")\n",
            "print(best_result_reg_logistic[\"CV F1\"] + \"+/-\" + best_result_reg_logistic[\"CV F1 std\"])\n",
            "print(\n",
            "    best_result_reg_logistic[\"CV Accuracy\"]\n",
            "    + \"+/-\"\n",
            "    + best_result_reg_logistic[\"CV Accuracy std\"]\n",
            ")\n",
            "print(\"With Gamma: \")\n",
            "print(best_result_reg_logistic[\"Gamma\"])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Gamma does not change"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Different MAX ITERS"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [],
         "source": [
            "results = []"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "#### BASELINE ####\n",
            "\n",
            "### Column dropping and imputation ###\n",
            "# threshold for drop_columns function\n",
            "DROP_NAN_THRESHOLD = 0.8  # 1 = keep everything, 0 = drop everything that contains nan\n",
            "# threshold for categorical/numerical (categorical are imputated with median, numerical with mean)\n",
            "CAT_NUM_THRESHOLD = 50\n",
            "# flag for drop_single_value_columns function\n",
            "# Should always be True, otherwise it is messing up with the correlation coefficient.\n",
            "DROP_SINGLE = True\n",
            "# threshold for drop_correlated_columns function\n",
            "DROP_CORR_THRESHOLD = 0.8\n",
            "\n",
            "### Feature processing ###\n",
            "# flag for build_poly function\n",
            "BUILD_POLY = False\n",
            "# degree for build_poly function\n",
            "DEGREE = 2\n",
            "# flag for build_log function\n",
            "BUILD_LOG = True\n",
            "# flag for build_x\n",
            "BUILD_RATIOS = True\n",
            "# flag for standardize function\n",
            "STANDARDIZE = True\n",
            "\n",
            "NUM_FOLDS = 5\n",
            "\n",
            "GAMMA = 0.5\n",
            "MAX_ITERS = 300\n",
            "LAMBDA = 0.1"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Building polynomial with degree = 2...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66903\n",
                  "Test loss: 0.67029\n",
                  "Train accuracy: 0.63177\n",
                  "Train f1_score: 0.30253\n",
                  "Test accuracy: 0.63152\n",
                  "Test f1_score: 0.29789\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66918\n",
                  "Test loss: 0.66970\n",
                  "Train accuracy: 0.63027\n",
                  "Train f1_score: 0.30215\n",
                  "Test accuracy: 0.63052\n",
                  "Test f1_score: 0.29708\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66912\n",
                  "Test loss: 0.67021\n",
                  "Train accuracy: 0.63123\n",
                  "Train f1_score: 0.30093\n",
                  "Test accuracy: 0.62823\n",
                  "Test f1_score: 0.30164\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66945\n",
                  "Test loss: 0.66898\n",
                  "Train accuracy: 0.63102\n",
                  "Train f1_score: 0.30093\n",
                  "Test accuracy: 0.63180\n",
                  "Test f1_score: 0.30303\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66895\n",
                  "Test loss: 0.67080\n",
                  "Train accuracy: 0.63167\n",
                  "Train f1_score: 0.30090\n",
                  "Test accuracy: 0.62866\n",
                  "Test f1_score: 0.30411\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.631194 ± 0.000537\n",
                  "f1_score : 0.301490 ± 0.000706\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.630146 ± 0.001459\n",
                  "f1_score : 0.300750 ± 0.002790\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67045\n",
                  "Test loss: 0.67134\n",
                  "Train accuracy: 0.62790\n",
                  "Train f1_score: 0.30058\n",
                  "Test accuracy: 0.62793\n",
                  "Test f1_score: 0.29643\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67059\n",
                  "Test loss: 0.67094\n",
                  "Train accuracy: 0.62644\n",
                  "Train f1_score: 0.30025\n",
                  "Test accuracy: 0.62720\n",
                  "Test f1_score: 0.29570\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67051\n",
                  "Test loss: 0.67134\n",
                  "Train accuracy: 0.62782\n",
                  "Train f1_score: 0.29925\n",
                  "Test accuracy: 0.62485\n",
                  "Test f1_score: 0.30017\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67082\n",
                  "Test loss: 0.67032\n",
                  "Train accuracy: 0.62742\n",
                  "Train f1_score: 0.29926\n",
                  "Test accuracy: 0.62927\n",
                  "Test f1_score: 0.30211\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.67036\n",
                  "Test loss: 0.67172\n",
                  "Train accuracy: 0.62786\n",
                  "Train f1_score: 0.29903\n",
                  "Test accuracy: 0.62563\n",
                  "Test f1_score: 0.30243\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.627490 ± 0.000552\n",
                  "f1_score : 0.299673 ± 0.000619\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.626974 ± 0.001584\n",
                  "f1_score : 0.299368 ± 0.002815\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Building polynomial with degree = 2...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66744\n",
                  "Test loss: 0.66935\n",
                  "Train accuracy: 0.63957\n",
                  "Train f1_score: 0.30648\n",
                  "Test accuracy: 0.63768\n",
                  "Test f1_score: 0.30044\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66752\n",
                  "Test loss: 0.66886\n",
                  "Train accuracy: 0.63874\n",
                  "Train f1_score: 0.30666\n",
                  "Test accuracy: 0.63730\n",
                  "Test f1_score: 0.30039\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66751\n",
                  "Test loss: 0.66916\n",
                  "Train accuracy: 0.63952\n",
                  "Train f1_score: 0.30521\n",
                  "Test accuracy: 0.63681\n",
                  "Test f1_score: 0.30658\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66788\n",
                  "Test loss: 0.66765\n",
                  "Train accuracy: 0.63875\n",
                  "Train f1_score: 0.30499\n",
                  "Test accuracy: 0.63965\n",
                  "Test f1_score: 0.30727\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66737\n",
                  "Test loss: 0.66987\n",
                  "Train accuracy: 0.63912\n",
                  "Train f1_score: 0.30422\n",
                  "Test accuracy: 0.63622\n",
                  "Test f1_score: 0.30788\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.639141 ± 0.000357\n",
                  "f1_score : 0.305511 ± 0.000925\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.637530 ± 0.001165\n",
                  "f1_score : 0.304511 ± 0.003372\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67007\n",
                  "Test loss: 0.67105\n",
                  "Train accuracy: 0.62949\n",
                  "Train f1_score: 0.30164\n",
                  "Test accuracy: 0.62919\n",
                  "Test f1_score: 0.29722\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67021\n",
                  "Test loss: 0.67065\n",
                  "Train accuracy: 0.62823\n",
                  "Train f1_score: 0.30137\n",
                  "Test accuracy: 0.62874\n",
                  "Test f1_score: 0.29660\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67014\n",
                  "Test loss: 0.67102\n",
                  "Train accuracy: 0.62944\n",
                  "Train f1_score: 0.30027\n",
                  "Test accuracy: 0.62552\n",
                  "Test f1_score: 0.30031\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67046\n",
                  "Test loss: 0.66998\n",
                  "Train accuracy: 0.62855\n",
                  "Train f1_score: 0.29977\n",
                  "Test accuracy: 0.63076\n",
                  "Test f1_score: 0.30280\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66999\n",
                  "Test loss: 0.67143\n",
                  "Train accuracy: 0.62940\n",
                  "Train f1_score: 0.29986\n",
                  "Test accuracy: 0.62694\n",
                  "Test f1_score: 0.30325\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629021 ± 0.000527\n",
                  "f1_score : 0.300582 ± 0.000776\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628229 ± 0.001822\n",
                  "f1_score : 0.300037 ± 0.002747\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Building polynomial with degree = 2...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66710\n",
                  "Test loss: 0.66911\n",
                  "Train accuracy: 0.64386\n",
                  "Train f1_score: 0.30857\n",
                  "Test accuracy: 0.64210\n",
                  "Test f1_score: 0.30232\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66715\n",
                  "Test loss: 0.66880\n",
                  "Train accuracy: 0.64264\n",
                  "Train f1_score: 0.30804\n",
                  "Test accuracy: 0.64195\n",
                  "Test f1_score: 0.30232\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66714\n",
                  "Test loss: 0.66919\n",
                  "Train accuracy: 0.64349\n",
                  "Train f1_score: 0.30690\n",
                  "Test accuracy: 0.64099\n",
                  "Test f1_score: 0.30847\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66750\n",
                  "Test loss: 0.66749\n",
                  "Train accuracy: 0.64270\n",
                  "Train f1_score: 0.30686\n",
                  "Test accuracy: 0.64280\n",
                  "Test f1_score: 0.30784\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66704\n",
                  "Test loss: 0.66981\n",
                  "Train accuracy: 0.64296\n",
                  "Train f1_score: 0.30593\n",
                  "Test accuracy: 0.63928\n",
                  "Test f1_score: 0.30872\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.643129 ± 0.000474\n",
                  "f1_score : 0.307260 ± 0.000936\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.641422 ± 0.001217\n",
                  "f1_score : 0.305934 ± 0.002965\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67007\n",
                  "Test loss: 0.67105\n",
                  "Train accuracy: 0.62950\n",
                  "Train f1_score: 0.30165\n",
                  "Test accuracy: 0.62919\n",
                  "Test f1_score: 0.29722\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67021\n",
                  "Test loss: 0.67065\n",
                  "Train accuracy: 0.62822\n",
                  "Train f1_score: 0.30136\n",
                  "Test accuracy: 0.62870\n",
                  "Test f1_score: 0.29654\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67014\n",
                  "Test loss: 0.67102\n",
                  "Train accuracy: 0.62945\n",
                  "Train f1_score: 0.30028\n",
                  "Test accuracy: 0.62552\n",
                  "Test f1_score: 0.30031\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67046\n",
                  "Test loss: 0.66998\n",
                  "Train accuracy: 0.62854\n",
                  "Train f1_score: 0.29977\n",
                  "Test accuracy: 0.63078\n",
                  "Test f1_score: 0.30281\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66999\n",
                  "Test loss: 0.67143\n",
                  "Train accuracy: 0.62940\n",
                  "Train f1_score: 0.29986\n",
                  "Test accuracy: 0.62695\n",
                  "Test f1_score: 0.30326\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629023 ± 0.000533\n",
                  "f1_score : 0.300583 ± 0.000778\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628229 ± 0.001823\n",
                  "f1_score : 0.300029 ± 0.002766\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Building polynomial with degree = 2...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66693\n",
                  "Test loss: 0.66903\n",
                  "Train accuracy: 0.64676\n",
                  "Train f1_score: 0.30955\n",
                  "Test accuracy: 0.64441\n",
                  "Test f1_score: 0.30299\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.66696\n",
                  "Test loss: 0.66892\n",
                  "Train accuracy: 0.64602\n",
                  "Train f1_score: 0.30933\n",
                  "Test accuracy: 0.64513\n",
                  "Test f1_score: 0.30325\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66695\n",
                  "Test loss: 0.66954\n",
                  "Train accuracy: 0.64670\n",
                  "Train f1_score: 0.30801\n",
                  "Test accuracy: 0.64385\n",
                  "Test f1_score: 0.30982\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66729\n",
                  "Test loss: 0.66760\n",
                  "Train accuracy: 0.64541\n",
                  "Train f1_score: 0.30756\n",
                  "Test accuracy: 0.64617\n",
                  "Test f1_score: 0.30958\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66688\n",
                  "Test loss: 0.67010\n",
                  "Train accuracy: 0.64597\n",
                  "Train f1_score: 0.30707\n",
                  "Test accuracy: 0.64219\n",
                  "Test f1_score: 0.30972\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.646173 ± 0.000503\n",
                  "f1_score : 0.308305 ± 0.000978\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.644351 ± 0.001329\n",
                  "f1_score : 0.307069 ± 0.003229\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67007\n",
                  "Test loss: 0.67105\n",
                  "Train accuracy: 0.62950\n",
                  "Train f1_score: 0.30165\n",
                  "Test accuracy: 0.62919\n",
                  "Test f1_score: 0.29722\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67021\n",
                  "Test loss: 0.67065\n",
                  "Train accuracy: 0.62822\n",
                  "Train f1_score: 0.30136\n",
                  "Test accuracy: 0.62870\n",
                  "Test f1_score: 0.29654\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67014\n",
                  "Test loss: 0.67102\n",
                  "Train accuracy: 0.62945\n",
                  "Train f1_score: 0.30028\n",
                  "Test accuracy: 0.62552\n",
                  "Test f1_score: 0.30031\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67046\n",
                  "Test loss: 0.66998\n",
                  "Train accuracy: 0.62854\n",
                  "Train f1_score: 0.29977\n",
                  "Test accuracy: 0.63078\n",
                  "Test f1_score: 0.30281\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66999\n",
                  "Test loss: 0.67143\n",
                  "Train accuracy: 0.62940\n",
                  "Train f1_score: 0.29986\n",
                  "Test accuracy: 0.62695\n",
                  "Test f1_score: 0.30326\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629023 ± 0.000533\n",
                  "f1_score : 0.300583 ± 0.000778\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628229 ± 0.001823\n",
                  "f1_score : 0.300029 ± 0.002766\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Building polynomial with degree = 2...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66682\n",
                  "Test loss: 0.66909\n",
                  "Train accuracy: 0.64906\n",
                  "Train f1_score: 0.31057\n",
                  "Test accuracy: 0.64649\n",
                  "Test f1_score: 0.30347\n",
                  "------------------------------\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/home/stef/Desktop/School/EPFL/CS-433 Machine Learning/ML_course/projects/project1/ML-Project-1/notebooks/../implementations_utils.py:82: RuntimeWarning: divide by zero encountered in log\n",
                  "  loss = np.mean(-y * np.log(p) - (1 - y) * np.log(1 - p))\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Fold 2/5\n",
                  "Train loss: 0.66681\n",
                  "Test loss: inf\n",
                  "Train accuracy: 0.64814\n",
                  "Train f1_score: 0.31011\n",
                  "Test accuracy: 0.64748\n",
                  "Test f1_score: 0.30457\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66679\n",
                  "Test loss: inf\n",
                  "Train accuracy: 0.64879\n",
                  "Train f1_score: 0.30879\n",
                  "Test accuracy: 0.64569\n",
                  "Test f1_score: 0.30999\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66712\n",
                  "Test loss: 0.66800\n",
                  "Train accuracy: 0.64793\n",
                  "Train f1_score: 0.30841\n",
                  "Test accuracy: 0.64859\n",
                  "Test f1_score: 0.31043\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66678\n",
                  "Test loss: inf\n",
                  "Train accuracy: 0.64750\n",
                  "Train f1_score: 0.30736\n",
                  "Test accuracy: 0.64376\n",
                  "Test f1_score: 0.31025\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.648284 ± 0.000570\n",
                  "f1_score : 0.309047 ± 0.001164\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.646402 ± 0.001639\n",
                  "f1_score : 0.307741 ± 0.003063\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67007\n",
                  "Test loss: 0.67105\n",
                  "Train accuracy: 0.62950\n",
                  "Train f1_score: 0.30165\n",
                  "Test accuracy: 0.62919\n",
                  "Test f1_score: 0.29722\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67021\n",
                  "Test loss: 0.67065\n",
                  "Train accuracy: 0.62822\n",
                  "Train f1_score: 0.30136\n",
                  "Test accuracy: 0.62870\n",
                  "Test f1_score: 0.29654\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67014\n",
                  "Test loss: 0.67102\n",
                  "Train accuracy: 0.62945\n",
                  "Train f1_score: 0.30028\n",
                  "Test accuracy: 0.62552\n",
                  "Test f1_score: 0.30031\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67046\n",
                  "Test loss: 0.66998\n",
                  "Train accuracy: 0.62854\n",
                  "Train f1_score: 0.29977\n",
                  "Test accuracy: 0.63078\n",
                  "Test f1_score: 0.30281\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66999\n",
                  "Test loss: 0.67143\n",
                  "Train accuracy: 0.62940\n",
                  "Train f1_score: 0.29986\n",
                  "Test accuracy: 0.62695\n",
                  "Test f1_score: 0.30326\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629023 ± 0.000533\n",
                  "f1_score : 0.300583 ± 0.000778\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628229 ± 0.001823\n",
                  "f1_score : 0.300029 ± 0.002766\n",
                  "Dropping columns with DROP_NAN_THRESHOLD = 1...\n",
                  "Building polynomial with degree = 2...\n",
                  "Dropping single valued columns...\n",
                  "Standardizing...\n",
                  "Fold 1/5\n",
                  "Train loss: 0.66672\n",
                  "Test loss: 0.66926\n",
                  "Train accuracy: 0.65019\n",
                  "Train f1_score: 0.31099\n",
                  "Test accuracy: 0.64772\n",
                  "Test f1_score: 0.30413\n",
                  "------------------------------\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/home/stef/Desktop/School/EPFL/CS-433 Machine Learning/ML_course/projects/project1/ML-Project-1/notebooks/../implementations_utils.py:82: RuntimeWarning: invalid value encountered in multiply\n",
                  "  loss = np.mean(-y * np.log(p) - (1 - y) * np.log(1 - p))\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Fold 2/5\n",
                  "Train loss: nan\n",
                  "Test loss: inf\n",
                  "Train accuracy: 0.64954\n",
                  "Train f1_score: 0.31064\n",
                  "Test accuracy: 0.64868\n",
                  "Test f1_score: 0.30508\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.66664\n",
                  "Test loss: inf\n",
                  "Train accuracy: 0.65012\n",
                  "Train f1_score: 0.30936\n",
                  "Test accuracy: 0.64690\n",
                  "Test f1_score: 0.31022\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.66694\n",
                  "Test loss: 0.66843\n",
                  "Train accuracy: 0.64957\n",
                  "Train f1_score: 0.30908\n",
                  "Test accuracy: 0.64999\n",
                  "Test f1_score: 0.31087\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66669\n",
                  "Test loss: inf\n",
                  "Train accuracy: 0.64805\n",
                  "Train f1_score: 0.30769\n",
                  "Test accuracy: 0.64429\n",
                  "Test f1_score: 0.31029\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.649495 ± 0.000770\n",
                  "f1_score : 0.309553 ± 0.001180\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.647517 ± 0.001913\n",
                  "f1_score : 0.308119 ± 0.002894\n",
                  "Fold 1/5\n",
                  "Train loss: 0.67007\n",
                  "Test loss: 0.67105\n",
                  "Train accuracy: 0.62950\n",
                  "Train f1_score: 0.30165\n",
                  "Test accuracy: 0.62919\n",
                  "Test f1_score: 0.29722\n",
                  "------------------------------\n",
                  "Fold 2/5\n",
                  "Train loss: 0.67021\n",
                  "Test loss: 0.67065\n",
                  "Train accuracy: 0.62822\n",
                  "Train f1_score: 0.30136\n",
                  "Test accuracy: 0.62870\n",
                  "Test f1_score: 0.29654\n",
                  "------------------------------\n",
                  "Fold 3/5\n",
                  "Train loss: 0.67014\n",
                  "Test loss: 0.67102\n",
                  "Train accuracy: 0.62945\n",
                  "Train f1_score: 0.30028\n",
                  "Test accuracy: 0.62552\n",
                  "Test f1_score: 0.30031\n",
                  "------------------------------\n",
                  "Fold 4/5\n",
                  "Train loss: 0.67046\n",
                  "Test loss: 0.66998\n",
                  "Train accuracy: 0.62854\n",
                  "Train f1_score: 0.29977\n",
                  "Test accuracy: 0.63078\n",
                  "Test f1_score: 0.30281\n",
                  "------------------------------\n",
                  "Fold 5/5\n",
                  "Train loss: 0.66999\n",
                  "Test loss: 0.67143\n",
                  "Train accuracy: 0.62940\n",
                  "Train f1_score: 0.29986\n",
                  "Test accuracy: 0.62695\n",
                  "Test f1_score: 0.30326\n",
                  "------------------------------\n",
                  "Train:\n",
                  "accuracy : 0.629023 ± 0.000533\n",
                  "f1_score : 0.300583 ± 0.000778\n",
                  "--------------------\n",
                  "Test:\n",
                  "accuracy : 0.628229 ± 0.001823\n",
                  "f1_score : 0.300029 ± 0.002766\n"
               ]
            }
         ],
         "source": [
            "results = []\n",
            "\n",
            "BUILD_RATIOS = False\n",
            "BUILD_LOG = False\n",
            "BUILD_POLY = True\n",
            "CAT_NUM_THRESHOLD = 200\n",
            "DROP_NAN_THRESHOLD = 1\n",
            "DROP_CORR_THRESHOLD = 0.9\n",
            "\n",
            "iters = [10, 50, 100, 200, 500, 1000]\n",
            "\n",
            "for iter in iters:\n",
            "    MAX_ITERS = iter\n",
            "    results = execute_pipeline(\n",
            "        x_train,\n",
            "        x_test,\n",
            "        y_train,\n",
            "        DROP_NAN_THRESHOLD,\n",
            "        DROP_CORR_THRESHOLD,\n",
            "        CAT_NUM_THRESHOLD,\n",
            "        DROP_SINGLE,\n",
            "        BUILD_RATIOS,\n",
            "        BUILD_LOG,\n",
            "        BUILD_POLY,\n",
            "        DEGREE,\n",
            "        STANDARDIZE,\n",
            "        NUM_FOLDS,\n",
            "        GAMMA,\n",
            "        MAX_ITERS,\n",
            "        LAMBDA,\n",
            "        results,\n",
            "    )\n",
            "\n",
            "with open(\"../results/results_max_iters.csv\", \"w\") as csvfile:\n",
            "    writer = csv.DictWriter(\n",
            "        csvfile,\n",
            "        fieldnames=[\n",
            "            \"Drop Threshold\",\n",
            "            \"Drop corr thresh.\",\n",
            "            \"Imputation\",\n",
            "            \"Standardization\",\n",
            "            \"Build Poly\",\n",
            "            \"Degree\",\n",
            "            \"Build Log\",\n",
            "            \"Build Ratios\",\n",
            "            \"Model\",\n",
            "            \"Initial W\",\n",
            "            \"Max Iters\",\n",
            "            \"Gamma\",\n",
            "            \"Lambda\",\n",
            "            \"CV F1 std\",\n",
            "            \"CV Accuracy std\",\n",
            "            \"CV F1\",\n",
            "            \"CV Accuracy\",\n",
            "        ],\n",
            "    )\n",
            "\n",
            "    writer.writeheader()\n",
            "    for result in results:\n",
            "        writer.writerow(result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "results_max_iters = []\n",
            "with open(\"../results/results_max_iters.csv\", \"r\") as csvfile:\n",
            "    reader = csv.DictReader(csvfile)\n",
            "    for row in reader:\n",
            "        results_max_iters.append(row)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Best result for Logistic Regression: \n",
                  "0.3081186569260702+/-0.0028942425950032307\n",
                  "0.6475170280524783+/-0.001913074692516863\n",
                  "With Max Iters: \n",
                  "1000\n",
                  "Best result for Reg Logistic Regression:\n",
                  "0.3000367444953675+/-0.0027472772246543036\n",
                  "0.6282292349185548+/-0.0018224461308472368\n",
                  "With Max Iters: \n",
                  "50\n"
               ]
            }
         ],
         "source": [
            "# determine the best results for Logistic Regression drop nan threshold and for Reg Logistic Regression drop nan threshold\n",
            "best_result_logistic = max(\n",
            "    results_max_iters,\n",
            "    key=lambda x: float(x[\"CV F1\"]) if x[\"Model\"] == \"Logistic_Regression\" else 0.0,\n",
            ")\n",
            "best_result_reg_logistic = max(\n",
            "    results_max_iters,\n",
            "    key=lambda x: float(x[\"CV F1\"]) if x[\"Model\"] == \"Reg_Logistic_Regression\" else 0.0,\n",
            ")\n",
            "\n",
            "print(\"Best result for Logistic Regression: \")\n",
            "print(best_result_logistic[\"CV F1\"] + \"+/-\" + best_result_logistic[\"CV F1 std\"])\n",
            "print(\n",
            "    best_result_logistic[\"CV Accuracy\"]\n",
            "    + \"+/-\"\n",
            "    + best_result_logistic[\"CV Accuracy std\"]\n",
            ")\n",
            "print(\"With Max Iters: \")\n",
            "print(best_result_logistic[\"Max Iters\"])\n",
            "\n",
            "\n",
            "print(\"Best result for Reg Logistic Regression:\")\n",
            "print(best_result_reg_logistic[\"CV F1\"] + \"+/-\" + best_result_reg_logistic[\"CV F1 std\"])\n",
            "print(\n",
            "    best_result_reg_logistic[\"CV Accuracy\"]\n",
            "    + \"+/-\"\n",
            "    + best_result_reg_logistic[\"CV Accuracy std\"]\n",
            ")\n",
            "print(\"With Max Iters: \")\n",
            "print(best_result_reg_logistic[\"Max Iters\"])"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.9.16"
      },
      "vscode": {
         "interpreter": {
            "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
